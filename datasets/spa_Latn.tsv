A.1	Finding value of $c$ such that the range of the rational function $f(x) = \frac{x^2 + x + c}{x^2 + 2x + c}$ does not contain $[-1, -\frac{1}{3}]$	I am comfortable when I am asked to calculate the range of a rational function, but how do we do the reverse? I came across this problem. If $$f(x)= \frac{x^2 + x + c}{x^2 + 2x + c}$$ then find the value of $c$ for which the range of $f(x)$ does not contain $[-1, -\frac{1}{3}]$.	Valo de $c$ de tal manera que el rango de la función racional $f(x) = \frac{x^2 + x + c}{x^2 + 2x + c}$ no contenga $[-1, -\frac{1}{3}]$	Me siento cómodo cuando me piden que calcule el rango de una función racional, pero ¿cómo hacemos lo contrario? Me encontré con este problema. Si $$f(x) = \frac{x^2 + x + c}{x^2 + 2x + c}$$ entonces encontrar el valor de $c$ para el cual el rango de $f(x)$ no contiene $[-1, -\frac{1}{3}]$.	functions
A.2	Solving differential equations of the form $f'(x)=f(x+1)$	How to solve differential equations of the following form:  $\frac{df}{dx} = f(x+1)$	Resolución de ecuaciones diferenciales de la forma $f'(x)=f(x+1)$	Cómo resolver ecuaciones diferenciales de la siguiente forma: $\frac{df}{dx} = f(x+1)$	ordinary-differential-equations
A.3	Approximation to $\sqrt{5}$ correct to an exactitude of $10^{-10}$	I am attempting to resolve the following problem:  Find an approximation to $\sqrt{5}$ correct to an exactitude of $10^{-10}$ using the bisection algorithm.  From what I understand, $\sqrt{5}$ has to be placed in function of $x$ but I am not sure where to go from there. Also, a function in Mathematica are given to do the calculations in which the function $f(x)$, $a$ and $b$ (from the interval $[a, b]$ where $f(a)$ and $f(b)$ have opposite signs), the tolerance and the number of iterations.	Aproximación a la corrección $\sqrt{5}$ con una exactitud de $10^{-10}$	Estoy tratando de resolver el siguiente problema: encontrar una aproximación a $\sqrt{5}$ correcta a una exactitud de $10^{-10}$ usando el algoritmo de bisección. Por lo que entiendo, $\sqrt{5}$ debe colocarse en función de $x$ pero no estoy seguro de dónde ir desde allí. También, se da una función en Matemáticas para hacer los cálculos en los que la función $f(x)$, $a$ y $b$ (desde el intervalo $[a, b]$ donde $f(a)$ y $f(b)$ tienen signos opuestos), la tolerancia y el número de iteraciones.	numerical-methods,algorithms,bisection
A.4	How to compute this combinatoric sum?	I have the sum $$\sum_{k=0}^{n} \binom{n}{k} k$$ I know the result is $n 2^{n-1}$ but I don't know how you get there. How does one even begin to simplify a sum like this that has binomial coefficients.	¿Cómo calcular esta suma combinatoria?	Tengo la suma $$\sum_{k=0}^{n} \binom{n}{k} k$$ Sé que el resultado es $n 2^{n-1}$ pero no sé cómo llegar allí. ¿Cómo se puede incluso empezar a simplificar una suma como esta que tiene coeficientes binomial.	combinatorics,number-theory,summation,proof-explanation
A.5	A family has two children. Given that one of the children is a boy, what is the probability that both children are boys?	A family has two children. Given that one of the children is a boy, what is the probability that both children are boys?  I was doing this question using conditional probability formula.  Suppose, (1) is the event, that the first child is a boy, and (2) is the event that the second child is a boy. Then the probability of the second child to be boy given that first child is a boys by formula, $P((2)|(1))=\frac{P((2) \cap (1))}{P((1))}=\frac{P((2))P((1))}{P((1))} = P((2))$ ...since second child to be boy doesn't depend on first child and vice versa. Please provide the detailed solution and correct me if I am wrong.	¿Cuál es la probabilidad de que ambos hijos sean niños, dado que uno de ellos es un niño?	Una familia tiene dos hijos. Dado que uno de los niños es un niño, ¿cuál es la probabilidad de que ambos niños sean niños? Estaba haciendo esta pregunta usando la fórmula de probabilidad condicional. Supongamos, (1) es el evento, que el primer niño es un niño, y (2) es el evento de que el segundo niño es un niño. Entonces la probabilidad del segundo niño es un niño dado que el primer niño es un niño por fórmula, $P((2)|(1))=\frac{P((2) \cap (1))}{P((1))}=\frac{P((2))P((1))}{P((1))} = P((2))$ ...ya que el segundo niño es un niño no depende del primer niño y viceversa. Por favor proporcione la solución detallada y corrija si estoy equivocado.	probability,proof-verification,conditional-probability
A.6	How to calculate mod of number with big exponent	I want to find $$ 5^{133} \mod 8. $$ I have noticed that $5^n \mod 8 = 5$ when $n$ is uneven and 1 otherwise, which would lead me to say that $5^{133} \mod 8 = 5$ But I don't know how to prove this. How can I prove that this is the case (or find another solution if it is not)?	Cómo calcular el mod de número con un gran exponente	Quiero encontrar $$ 5^{133} \mod 8. $$ He notado que $5^n \mod 8 = 5$ cuando $n$ es desigual y 1 de otra manera, lo que me llevaría a decir que $5^{133} \mod 8 = 5$ Pero no sé cómo probar esto. ¿Cómo puedo probar que este es el caso (o encontrar otra solución si no es)?	algebra-precalculus,arithmetic
A.7	Finding out the remainder of $\frac{11^\text{10}-1}{100}$ using modulus	If $11^\text{10}-1$ is divided by $100$, then solve for '$x$' of the below term $$11^\text{10}-1 = x \pmod{100}$$  Whatever I tried: $11^\text{2} \equiv 21 \pmod{100}$.....(1) $(11^\text{2})^\text{2} \equiv (21)^\text{2} \pmod{100}$ $11^\text{4} \equiv 441 \pmod{100}$ $11^\text{4} \equiv 41 \pmod{100}$ $(11^\text{4})^\text{2} \equiv (41)^\text{2} \pmod{100}$ $11^\text{8} \equiv 1681 \pmod{100}$ $11^\text{8} \equiv 81 \pmod{100}$ $11^\text{8} × 11^\text{2} \equiv (81×21) \pmod{100}$ ......{from (1)} $11^\text{10} \equiv 1701 \pmod{100} \implies 11^\text{10} \equiv 1 \pmod{100}$ Hence, $11^\text{10} -1 \equiv (1-1) \pmod{100} \implies 11^\text{10} - 1 \equiv 0 \pmod{100}$ and thus we get the value of $x$ and it is $x = 0$ and $11^\text{10}-1$ is divisible by $100$. But this approach take a long time for any competitive exam or any math contest without using calculator. Any easier process on how to determine the remainder of the above problem quickly? That will be very much helpful for me. Thanks in advance.	Identificación del resto de $\frac{11^\text{10}-1}{100}$ utilizando el módulo	Si $11^\text{10}-1$ es dividido por $100$, entonces resolver para '$x$' del término de abajo $$11^\text{10}-1 = x \pmod{100}$$ Lo que sea que haya intentado: $11^\text{2} \equiv 21 \pmod{100}$.....(1) $(11^\text{2})^\text{2} \equiv (21)^\text{2} \pmod{100}$ $11^\text{4} \equiv 441 \pmod{100}$ $11^\text{4} \equiv 41 \pmod{100}$ $(11^\text{4})^\text{2} \equiv (41)^\text{2} \pmod{100}$ $11^\text{10}-1$0 $11^\text{10}-1$1 $11^\text{10}-1$2 ......{de (1)} $11^\text{10}-1$3 Así que, $11^\text{10}-1$4 y así obtenemos el valor de $x$ y es $11^\text{10}-1$5 y $11^\text{10}-1$ es divisible por $100$. Pero este enfoque toma mucho tiempo para cualquier examen competitivo o cualquier concurso sin usar calculadora. ¿Algún proceso más fácil sobre cómo determinar el resto del problema matemático rápidamente? Eso me ayudará mucho.	elementary-number-theory,modular-arithmetic,divisibility,alternative-proof
A.8	finding value of $\lim_{n\rightarrow \infty}\sqrt[n]{\frac{(27)^n(n!)^3}{(3n)!}}$	Finding value of $\lim_{n\rightarrow \infty}\sqrt[n]{\frac{(27)^n(n!)^3}{(3n)!}}$ what i try $\displaystyle l=\lim_{n\rightarrow \infty}\bigg(\frac{(27)^n(n!)^3}{(3n)!}\bigg)^{\frac{1}{n}}$ $\displaystyle \ln(l)=\lim_{n\rightarrow \infty}\frac{1}{n}\bigg[n\ln(27)+3\ln(n!)-\ln((3n)!)\bigg]$ How do i solve it help me please	hallar el valor de $\lim_{n\rightarrow \infty}\sqrt[n]{\frac{(27)^n(n!)^3}{(3n)!}}$	Encontrar el valor de $\lim_{n\rightarrow \infty}\sqrt[n]{\frac{(27)^n(n!)^3}{(3n)!}}$ lo que intento $\displaystyle l=\lim_{n\rightarrow \infty}\bigg(\frac{(27)^n(n!)^3}{(3n)!}\bigg)^{\frac{1}{n}}$ $\displaystyle \ln(l)=\lim_{n\rightarrow \infty}\frac{1}{n}\bigg[n\ln(27)+3\ln(n!)-\ln((3n)!)\bigg]$ Cómo puedo resolverlo ayúdame por favor	limits
A.9	Simplifying this series	I need to write the series  $$\sum_{n=0}^N nx^n$$  in a form that does not involve the summation notation, for example $\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$. Does anyone have any idea how to do this? I've attempted multiple ways including using generating functions however no luck	Simplificando esta serie	Necesito escribir la serie $$\sum_{n=0}^N nx^n$$ en una forma que no involucre la notación de suma, por ejemplo $\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$. ¿Alguien tiene alguna idea de cómo hacer esto? He intentado varias formas incluyendo el uso de funciones de generación sin embargo ninguna suerte	sequences-and-series
A.10	Find the values of a>0 for which the improper integral $\int_{0}^{\infty}\frac{\sin x}{x^{a}} $ converges .	Find the values of a>0 for which the improper integral $\int_{0}^{\infty}\frac{\sin x}{x^{a}} $ converges .  Do  I have to expand integrand using series expansion??	Encuentra los valores de un>0 para los cuales converge la integral incorrecta $\int_{0}^{\infty}\frac{\sin x}{x^{a}} $ .	Encuentra los valores de un>0 para los cuales converge la integral incorrecta $\int_{0}^{\infty}\frac{\sin x}{x^{a}} $. ¿Tengo que expandir la integrand utilizando la expansión de serie?	improper-integrals
A.11	What's the cross product in 2 dimensions?	The math book i'm using states that the cross product for two vectors is defined over $R^3$: $$u = (a,b,c)$$ $$v = (d,e,f)$$ is: $$u \times v = \begin{vmatrix} \hat{i} & \hat{j} & \hat{k} \\ a & b & c \\ d & e & f \\ \end{vmatrix} $$ and the direction of the resultant is determined by curling fingers from vector v to u with thumb pointing in direction of the cross product of u x v.  Out of curiosity, what's the cross product if u and v are defined over $R^2$ instead of $R^3$ instead: $$u = (a,b)$$ $$v = (d,e)$$ Is there a "degenerate" case for the cross product of $R^2$ instead $R^3$?  like this is some type of 2x2 determinant instead? for instance if had a parameterization: $$\Phi(u,\ v) = (\ f(u),\ \ g(v)\ )$$ and needed to calculate in $R^2$: $$ D = \Bigg| \frac{\partial{\Phi}}{\partial{u}} \times \frac{\partial{\Phi}}{\partial{v}} \Bigg| $$ There are plenty of examples in the book for calculating the determinate D in $R^3$ but none at all for $R^2$ case. As in: $$ \iint_{V} f(x,y) dx\ dy = \iint_{Q} f(\Phi(u,v) \Bigg| \frac{\partial{\Phi}}{\partial{u}} \times \frac{\partial{\Phi}}{\partial{v}} \Bigg| $$ $$ \Phi(u,v)=(2u \cos v,\ \ u \sin v) $$	¿Cuál es el producto cruzado en 2 dimensiones?	El libro de matemáticas que estoy usando afirma que el producto cruzado para dos vectores se define sobre $R^3$: $$u = (a,b,c) $$v = (d,e,f) $$ es: $$u \times v = \begin{vmatrix} \Phi{i} & \hat{j} & \hat{k} \\ a & b & c \\ d & f \\ d & f {vmatrix} $$ y la dirección del resultado se determina curvando los dedos del vector vigg a u con el pulgar apuntando en la dirección cruzada de los ejemplos de u x v. Por despecho, ¿cuál es el producto cruzado si u y v se definen sobre $R^2$ en lugar de $R^3${u} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} {i} } {i} {i} {i} {i} } {i} {i} {i} } {i} {i} {i}i} {i}} {i} {i}i} {i}} {i}i} {i}} {i}i}} {i}i}} {i}i}} {i}i} {i}i}i} {i}i}i} {i}i}i}i} {i}i}i}i}i}i}i} (i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i	multivariable-calculus,vectors
A.12	Finding the roots of a complex number	I was solving practice problems for my upcoming midterm and however I got stuck with this question type. It is asking me to find all roots and then sketch it. $(1+i\sqrt{3})^{1/2}$ How do we proceed?	Encontrar las raíces de un número complejo	En el caso de la Comisión, la Comisión de Asuntos Exteriores ha decidido que la Comisión de Asuntos Exteriores de la Comunidad debe adoptar medidas para garantizar que las medidas adoptadas en el marco de la política de cohesión sean eficaces.	linear-algebra,complex-numbers,polar-coordinates
A.13	How to simplify expression $\int_a^b f(x)dx+\int_{f(a)}^{f(b)} f^{-1}(x)dx \ ?$	How to simplify expression $$\int_a^b f(x)dx+\int_{f(a)}^{f(b)} f^{-1}(x)dx \ ?$$ The answer is $bf(b)-af(a)$  but I am wondering how to get the answer.	Cómo simplificar la expresión $\int_a^b f(x)dx+\int_{f(a)}^{f(b)} f^{-1}(x)dx \ ?$	¿Cómo simplificar la expresión $$\int_a^b f(x) dx+\int_{f(a)}^{f(b)} f^{-1}(x) dx \ ?$$ La respuesta es $bf(b)-af(a)$ pero me pregunto cómo obtener la respuesta.	calculus
A.14	Help solving first-order differential equation	I have first-order differential equation $$y=xy'+ \frac{1}{2}(y')^{2}$$ Maybe, with this someone will find way to solve it $$\frac{1}{2}y'(2x+y')=y$$ I thought I can use $x^2+y=t$ for subtitution and when I derivate, I have $t'=2x+y'\\(t'-2x)t'=2t-2x^2$ which is acctualy the same as previous. I don't have idea how to start..	Ayuda para resolver la ecuación diferencial de primer orden	Tengo la ecuación diferencial de primer orden $$y=xy'+ \frac{1}{2}y')^{2}$$ Tal vez, con esto alguien encontrará una manera de resolverlo $$\frac{1}{2}y'(2x+y') = y$$ Pensé que podría usar $x^2+y=t$ para subtitulación y cuando derivo, tengo $t'=2x+y'\\(t'-2x)t'=2t-2x^2$ que es exactamente igual que el anterior. No tengo idea de cómo empezar..	ordinary-differential-equations
A.15	Derive the sum of $\sum_{i=1}^n ix^{i-1}$	For the series   $$1 + 2x + 3x^2 + 4x^3 + 5x^4 + ... + nx^{n-1}+... $$   and $x \ne 1, |x| < 1$. I need to find partial sums and finally, the sum $S_n$ of series. Here is what I've tried:   We can take a series $S_2 = 1 + x + x^2 + x^3 + x^4 + ...$ so that $\frac{d(S_2)}{dx} = S_1$ (source series). For the $|x| < 1$ the sum of $S_2$ (here is geometric progression): $\frac{1-x^n}{1-x} = \frac{1}{1-x}$ $S_1 = \frac{d(S_2)}{dx} = \frac{d(\frac{1}{1-x})}{dx} = \frac{1}{(1-x)^2}$  But this answer is incorrect. Where is my mistake? Thank you.	Derivar la suma de $\sum_{i=1}^n ix^{i-1}$	Para la serie $$1 + 2x + 3x^2 + 4x^3 + 5x^4 + ... + nx^{n-1}+... $$ y $x \ne 1, |x| < 1$. Necesito encontrar sumas parciales y finalmente, la suma $S_n$ de las series. Aquí es lo que he intentado: Podemos tomar una serie $S_2 = 1 + x + x^2 + x^3 + x^4 + ...$ para que $\frac{d(S_2)}{dx} = S_1$ (serie fuente). Para el $|x| < 1$ la suma de $S_2$ (aquí es la progresión geométrica): $\frac{1-x^n}{1-x} = \frac{1}{1-x}$ $S_1 = \frac{d(S_2)}{dx} = \frac{d(\frac{1}{1-x})}{dx} = \frac{1}{(1-x)^2}$ Pero esta respuesta es incorrecta. ¿Dónde está mi error?	sequences-and-series,convergence,summation,power-series
A.16	Finding $ \int_0^1\frac{\ln(1+x)\ln(1-x)}{1+x}dx$	Calculate   $$\int_0^1\frac{\ln(1+x)\ln(1-x)}{1+x}\,dx$$  My try :  Let : $$I(a,b)=\int_0^1\frac{\ln(1-ax)\ln(1+bx)}{1+x}\,dx$$ Then compute $\frac{d^2 I(a,b)}{dadb}$. I'm happy to see ideas in order to kill this integral.	Encontrar el $ \int_0^1\frac{\ln(1+x)\ln(1-x)}{1+x}dx$	Calcule $$\int_0^1\frac{\ln(1+x)\ln(1-x)}{1+x}\,dx$$ Mi intento: Deja: $$I(a,b)=\int_0^1\frac{\ln(1-ax)\ln(1+x}\,dx$$ Luego computa $\frac{d^2 I(a,b)}{dadb}$. Estoy feliz de ver ideas para matar esta integral.	integration,sequences-and-series,definite-integrals,closed-form
A.17	Calculate $\int _{x=0}^{\infty} \frac{\sin(x)}{x}$ with the function $\frac{e^{iz}}{z}$	I want to calculate $\int _{x=0}^{\infty} \frac{\sin(x)}{x}$ with the function $f(z) = \frac{e^{iz}}{z}$. I thought about using the closed path $\Gamma = \gamma _1 + \gamma _R + \gamma _2 + \gamma _{\epsilon}$, when: $\gamma_1 (t) = t, t \in [i\epsilon, iR]$ $\gamma_R (t) = Re^{it}, t \in [-\frac{\pi}{2}, \frac{\pi}{2}]$ $\gamma_2 (t) = t, t \in [-iR, -i\epsilon]$ $\gamma_{\epsilon} (t) = \epsilon e^{it}, t \in [-\frac{\pi}{2}, \frac{\pi}{2}]$ I use the fact that $\frac{\sin(x)}{x}$ is an even function and has an anti derivative, so the integral on a closed path is zero. I managed to show that $\int_{\gamma _{\epsilon}} f = -i\pi$ when $\epsilon \to 0$. However I am struggling to show that $\int_{\gamma _R} f = 0$ when $R \to \infty$ Help would be appreciated	Calcule $\int _{x=0}^{\infty} \frac{\sin(x)}{x}$ con la función $\frac{e^{iz}}{z}$	Quiero calcular $\int _{x=0}^{\infty} \frac{\sin(x)}{x}$ con la función $f(z) = \frac{e^{iz}}{z}$. pensé en usar el camino cerrado $\Gamma = \gamma _1 + \gamma _R + \gamma _2 + \gamma _{\epsilon}$, cuando: $\gamma_1 (t) = t, t \in [i\epsilon, iR]$ $\gamma_R (t) = Re^{it}, t \in [-\frac{\pi}{2}, \frac{\pi}{2}]$ $\gamma_2 (t) = t, t \in [-iR, -i\epsilon]$ $\gamma_{\epsilon} (t) = \epsilon e^{it}, t \in [-\frac{\pi}{2}, \frac{\pi}{2}]$ uso el hecho de que $\frac{\sin(x)}{x}$ es una función uniforme y tiene una derivada anti, por lo que la integral en un camino cerrado es cero. logré mostrar que $\int_{\gamma _{\epsilon}} f = -i\pi$ cuando $\int _{x=0}^{\infty} \frac{\sin(x)}{x}$0. Sin embargo, estoy luchando para mostrar que $\int _{x=0}^{\infty} \frac{\sin(x)}{x}$1 cuando $\int _{x=0}^{\infty} \frac{\sin(x)}{x}$2 Ayuda sería apreciado	complex-analysis,improper-integrals
A.18	Evaluate $\lim_{n \rightarrow \infty } \frac {[(n+1)(n+2)\cdots(n+n)]^{1/n}}{n}$	Evaluate $$\lim_{n \rightarrow \infty~} \dfrac {[(n+1)(n+2)\cdots(n+n)]^{\dfrac {1}{n}}}{n}$$ using Cesáro-Stolz theorem. I know there are many question like this, but i want to solve it using Cesáro-Stolz method and no others. I took log and applied Cesáro-Stolz, I get $$\log{2}+n\log\cfrac{n}{n+1}$$ Which gives me answer as $\frac{2}{e}$ . But answer is $\frac{4}{e}$. Could someone help?. Edit:  On taking log,  $$\lim_{n \to \infty} \frac{-n\log n + \sum\limits_{k=1}^{n} \log \left(k+n\right)}{n} \\= \lim_{n \to \infty} \left(-(n+1)\log (n+1) + \sum\limits_{k=1}^{n+1} \log \left(k+n\right)\right) - \left(-n\log n + \sum\limits_{k=1}^{n} \log \left(k+n\right)\right) \\ = \lim_{n \to \infty} \log \frac{2n+1}{n+1} - n\log \left(1+\frac{1}{n}\right) = \log 2 - 1$$ Which gives $2/e$	Evaluar el número $\lim_{n \rightarrow \infty } \frac {[(n+1)(n+2)\cdots(n+n)]^{1/n}}{n}$	Evaluar $$\lim_{n \rightarrow \infty~} \dfrac {[(n+1)(n+2)\cdots(n+n) ]^{\dfrac {1}{n}}}{n}$$ usando el teorema de Cesáro-Stolz. Sé que hay muchas preguntas como esta, pero quiero resolverlo usando el método de Cesáro-Stolz y no otras. Tomé log y aplicé el log de Stolz, obtuve $$\log{2}+n\log{n}\\c\n}+n\c\n}{n+1}$$ Que me da la respuesta como $\frac{2}{e}$ . Pero la respuesta es $\frac{4}{e}$. ¿Podría alguien ayudarme a editar: Al tomar log, $$\n \n_{n \n} \n_{n} \n_{n} \n_{n} \n_sum_{n} \n\n} \n\n} \n} \n} \n} \n} \n} \n} \n} \n} \n} \n} \n\n\n\n\n} \n\n\n} \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\	sequences-and-series
A.19	Greatest common factor of $ p^4-1$	I was asked to find the greatest common factor of $p^4-1$ for all primes > 5, First I got the value of $7^4 - 1$ which has divisors of $2^4* 3 *5*2$ and $11^4 - 1$ which has divisors $2^4 *3 * 5*61$ which has a GCF of $2^4*3*5$ I can prove that $p^4 - 1$ is divisible by 3 and 5 by casework and 8  by $(p^2+1)(p-1)(p+1)$ are even integers, but I don't know how to prove divisibility of $2^4$, I do not want to bash it since we must check about 7 numbers to prove its divisibility by assigning $16n + x$ where x <16	El factor común más grande de $ p^4-1$	Me pidieron que encuentre el factor común más grande de $p^4-1$ para todos los números primos > 5, Primero obtuve el valor de $7^4 - 1$ que tiene divisores de $2^4* 3 *5*2$ y $11^4 - 1$ que tiene divisores $2^4 *3 * 5*61$ que tiene un GCF de $2^4*3*5$ puedo probar que $p^4 - 1$ es divisible por 3 y 5 por el trabajo de caso y 8 por $(p^2+1)(p-1)(p+1)$ son números enteros, pero no sé cómo demostrar la divisibilidad de $2^4$, no quiero romperlo ya que debemos comprobar alrededor de 7 números para probar su divisibilidad asignando $p^4-1$0 donde x <16	divisibility,greatest-common-divisor
A.20	Calculate all $n \in \Bbb N \setminus \{41\}$ such that $\phi(n)=40$?	I'm looking for an $n \in \Bbb N$ for which $\phi(n) = 40$ where $\phi$ is a Euler-Totient Function   I already found one, namely, $n=41$ How the calculate the $n's$?	Calcular todos los $n \in \Bbb N \setminus \{41\}$ tales que $\phi(n)=40$?	Estoy buscando un $n \in \Bbb N$ para el cual $\phi(n) = 40$ donde $\phi$ es una función de Euler-Totient ya encontré uno, a saber, $n=41$ ¿Cómo calcular el $n's$?	totient-function
A.21	Finding the last two digits of $9^{9^{9^{…{^9}}}}$ (nine 9s)	I'm continuing on my journey learning about modular arithmetic and got confused with this question: Find the last two digits of $9^{9^{9^{…{^9}}}}$ (nine 9s). The phi function is supposed to be used in this problem and so far this is what I've got: $9^{9^{9^{…{^9}}}} ≡ x (\text{mod } 100)$ Where $0 ≤ x ≤ 100$ $9^{9^{9^{…{^9}}}} \text{ (nine 9s) }= 9^a$ In order to know $9^a (\text{mod } 100)$, we need to know $a (\text{mod } \phi(100))$ As $\phi(100)= 40$, we get $a = b (\text{mod } 40)$ $9^{9^{9^{…{^9}}}} \text{ (eight 9s) }= 9^b$ In order to know $9^b (\text{mod } 40)$, we need to know $b (\text{mod } \phi(40))$ As $\phi(40)= 16$, we get $b = c ( \text{mod }16)$ $9^{9^{9^{…{^9}}}}\text{ (seven 9s) }= 9^c $ In order to know $9^c (mod 16)$, we need to know $c (\text{mod } phi(16))$ as $\phi(16)= 8 $ we need to find $c (\text{mod } 8)$ As $9 = 1 (\text{mod } 8)$ $c = 1 (\text{mod } 8)$ I feel like I might have made a mistake somewhere along the way because I'm having a lot of trouble stitching it all back together in order to get a value for the last two digits. Could anyone please help me with this? Thank you!	Encontrar los dos últimos dígitos de $9^{9^{9^{…{^9}}}}$ (nueve 9s)	Estoy continuando en mi viaje aprendiendo sobre la aritmética modular y me confundí con esta pregunta: encontrar los dos últimos dígitos de $9^{9^{9^{…{^9}}}}$ (nueve 9s). La función phi se supone que se utiliza en este problema y hasta ahora esto es lo que tengo: $9^{9^{9^{…{^9}}}} ≡ x (\text{mod } 100)$ Donde $0 ≤ x ≤ 100$ $9^{9^{9^{…{^9}}}} \text{ (nine 9s) }= 9^a$ Para saber $9^a (\text{mod } 100)$, necesitamos saber $a (\text{mod } \phi(100))$ Como $\phi(100)= 40$, tenemos $a = b (\text{mod } 40)$ $9^{9^{9^{…{^9}}}} \text{ (eight 9s) }= 9^b$ Para saber $9^{9^{9^{…{^9}}}}$0, tenemos que saber $9^{9^{9^{…{^9}}}}$1 Como $9^{9^{9^{…{^9}}}}$2, tenemos $9^{9^{9^{…{^9}}}}$3 $9^{9^{9^{…{^9}}}}$4 Para saber $9^{9^{9^{…{^9}}}}$5, tenemos que saber $9^{9^{9^{…{^9}}}}$6 como $9^{9^{9^{…{^9}}}}$7 necesitamos encontrar $9^{9^{9^{…{^9}}}}$8 Como $9^{9^{9^{…{^9}}}}$9 $9^{9^{9^{…{^9}}}} ≡ x (\text{mod } 100)$0 siento que podría haber cometido un error en algún lugar en el camino porque estoy teniendo mucho problema de coser todo de nuevo para obtener un valor para los dos últimos dígitos. ¿Podría alguien ayudarme con esto por favor gracias!	number-theory,modular-arithmetic
A.22	Find number of d's that satisfies $d, d+1, d+2... = N$ for an $N$	I have a challenge about a cat in a trip where he can walk in the way of $d, d+1, d+2...$ and the sum of that should give $N$, given an $N$, how many ways of chosing $d$ are posible? Example: $N=30$ -> $Ans=3$ $d_1=4; d_2=6; d_3=8$  For $d_1: 4 + 5 + 6 + 7 + 8 = 30$ Edit: Another way to see it is: How many subsets in the sumation up to N are posible in the way $(\sum (d+n) - \sum(d-1))$=N	Encuentra el número de d que satisface $d, d+1, d+2... = N$ para un $N$	Tengo un reto sobre un gato en un viaje donde puede caminar en el camino de $d, d+1, d+2...$ y la suma de eso debería dar $N$, dado un $N$, ¿cuántas formas de elegir $d$ son posibles? Ejemplo: $N=30$ -> $Ans=3$ $d_1=4; d_2=6; d_3=8$ Para $d_1: 4 + 5 + 6 + 7 + 8 = 30$ Editar: Otra forma de verlo es: ¿Cuántos subconjuntos en la sumación hasta N son posibles en la forma $(\sum (d+n) - \sum(d-1))$=N	sequences-and-series,number-theory
A.23	How do i find the lcm	Qn: If the product of two integers is  $2^7 \cdot 3^8 \cdot 5^2 \cdot 7^{11}$ and their greatest common divisor is $2^3 \cdot 3^4 \cdot 5$, what is their least common multiple? I have issue with this question please help me solve it. I tried assuming that lcm is $x$ =. Then,        Gcd $\cdot x = 2^3  \cdot 3^4 \cdot 5x$. And, product factors /Gcd $x$	¿Cómo puedo encontrar el Icm?	Pn: Si el producto de dos números enteros es $2^7 \cdot 3^8 \cdot 5^2 \cdot 7^{11}$ y su mayor divisor común es $2^3 \cdot 3^4 \cdot 5$, ¿cuál es su múltiplo común menos común? Tengo un problema con esta pregunta por favor ayúdame a resolverlo. Traté de asumir que lcm es $x$ =.	prime-numbers,greatest-common-divisor,least-common-multiple
A.24	Is this the only way to evaluate $\sqrt{2i-1}?$	work out the $\sqrt{2i-1}?$ $2i-1=(a+bi)^2$ $a^2+2abi-b^2$ $a^2-b^2=-1$ $2ab=2$  $a^2=b^{-2}$ $b^{-2}-b^2=-1$ $-b^{4}+1=-1$ $b^4=2$ $b=\sqrt[4]{2}$ Can we solve $\sqrt{2i-1}$ in another way?	¿Es esta la única manera de evaluar el $\sqrt{2i-1}?$	¿Podemos resolver el $\sqrt{2i-1}?$1 de otra manera?	algebra-precalculus
A.25	What can be P(0), when $P(x^2+1)=(P(x))^2+1$ and P(x) is polynomial?	What can be $P(0)$, when $P(x^2+1)=(P(x))^2+1$ and $P(x)$ is polynomial? Let $P(0)=0$, then $P(1)=1$, $P(2)=2$, $P(5)=5$, $P(26)=26$, $P(677)=677$ ... and so on. Then $P(x)=x$, because all the points on $y=P(x)$ are $y=x$. If $P(0)=2$, then $P(x)=(x^2+1)^2+1$ for the same reason. But when $P(0)=3$, we have that $\lim_{x→∞}\log_xP(x)$ does not converge into an integer. So I think $P(x)$ cannot be a polynomial. Then what are the values of $P(0)$ that makes $P(x)$ polynomial?	¿Qué puede ser P ((0), cuando $P(x^2+1)=(P(x))^2+1$ y P ((x) es polinomio?	¿Qué puede ser $P(0)$, cuando $P(x^2+1)=(P(x))^2+1$ y $P(x)$ es polinomio? ¿Dejaremos $P(0)=0$, entonces $P(1)=1$, $P(2)=2$, $P(5)=5$, $P(26)=26$, $P(677)=677$ ... y así sucesivamente. Entonces $P(0)$0, porque todos los puntos en $P(0)$1 son $P(0)$2. Si $P(0)$3, entonces $P(0)$4 por la misma razón. Pero cuando $P(0)$5, tenemos que $P(0)$6 no converge en un número entero. Así que creo que $P(x)$ no puede ser un polinomio. Entonces, ¿cuáles son los valores de $P(0)$ que hace $P(x)$ polinomio?	polynomials
A.26	How to solve an indefinite integral using the Taylor series?	I am trying to show that the following integral is convergent but not absolutely.  $$\int_0^\infty\frac{\sin x}{x}dx.$$  My attempt:  I first obtained the taylor series of $\int_0^x\frac{sin x}{x}dx$ which is as follows:   $$x-\frac{x^3}{3 \times 3!}+\frac{x^5}{5\times5!}-\frac{x^7}{7 \times 7!}+\cdots = \sum_{n=0}^\infty (-1)^n\frac{x^{(2n+1)}}{(2n+1) \times (2n+1)!} $$  Now $\int_0^\infty\frac{\sin x}{x}dx=\lim_{x\to \infty} \sum_{n=0}^\infty (-1)^n\frac{x^{(2n+1)}}{(2n+1) \times (2n+1)!}$ and I got stuck here! What is the next step?	¿Cómo resolver una integral indefinida usando la serie Taylor?	Estoy tratando de mostrar que la siguiente integral es convergente pero no absolutamente. $$\int_0^\infty\frac{\sin x}{x}dx.$$ Mi intento: primero obtuve la serie de Taylor de $\int_0^x\frac{sin x}{x}dx$ que es la siguiente: $$x-\frac{x^3}{3 \times 3!}+\frac{x^5}{5\times5!}-\frac{x^7}{7 \times 7!}+\cdots = \sum_{n=0}^infty (-1) \n\frac{x^{((2n+1)}}{2n+1) \times (2n+1)!} $$ $\int_0^\infty\frac{\sin x}{x}dx=\lim_{x\to \infty} \sum_{n=0}^\infty (-1)^n\frac{x^{(2n+1)}}{(2n+1) \times (2n+1)!}$ y me quedé atascado aquí! Ahora ¿cuál es el siguiente paso?	real-analysis,calculus,integration,taylor-expansion,riemann-integration
A.27	What is the value of $e^{3i \pi /2}$?	When solving for the value, we know that $e^{\pi i}=-1$ . I am confused as to what is the right answer when you evaluate this.I am getting two possible answers: $e^{3\pi i/2}$ = $(e^{\pi i})^{3/2}$ so this could be $(\sqrt{-1})^3=i^3=-i$ or it could be $\sqrt{(-1)^3}=\sqrt{-1}=i$. Which one is the correct answer, and where am I going wrong? Thanks.	¿Cuál es el valor de $e^{3i \pi /2}$?	Cuando se resuelve el valor, sabemos que $e^{\pi i}=-1$. Estoy confundido en cuanto a cuál es la respuesta correcta cuando se evalúa esto. Estoy recibiendo dos posibles respuestas: $e^{3\pi i/2}$ = $(e^{\pi i})^{3/2}$ así que esto podría ser $(\sqrt{-1})^3=i^3=-i$ o podría ser $\sqrt{(-1)^3}=\sqrt{-1}=i$.	complex-numbers,exponentiation
A.28	If $\sin(18^\circ)=\frac{a + \sqrt{b}}{c}$, then what is $a+b+c$?	If $\sin(18)=\frac{a + \sqrt{b}}{c}$ in the simplest form, then what is $a+b+c$? $$ $$ Attempt: $\sin(18)$ in a right triangle with sides $x$ (in front of corner with angle $18$ degrees), $y$, and hypotenuse $z$, is actually just $\frac{x}{z}$, then $x = a + \sqrt{b}, z = c$. We can find $y$ as $$ y = \sqrt{c^{2}- (a + \sqrt{b})^{2}} $$ so we have  $$ \cos(18) = \frac{y}{z} = \frac{\sqrt{c^{2}- (a + \sqrt{b})^{2}}}{c}$$ I also found out that $$b = (c \sin(18) - a)^{2} = c^{2} \sin^{2}(18) - 2ac \sin(18) + a^{2}$$ I got no clue after this.  The solution says that $$ \sin(18) = \frac{-1 + \sqrt{5}}{4} $$ I gotta intuition that we must find $A,B,C$ such that $$ A \sin(18)^{2} + B \sin(18) + C = 0 $$  then $\sin(18)$ is a root iof $Ax^{2} + Bx + C$, and $a = -B, b = B^{2} - 4AC, c = 2A$.  Totally different. This question is not asking to prove that $sin(18)=(-1+\sqrt{5})/4$, that is just part of the solution.	Si $\sin(18^\circ)=\frac{a + \sqrt{b}}{c}$, entonces ¿qué es $a+b+c$?	Si $\sin(18)=\frac{a + \sqrt{b}}{c}$ en la forma más simple, entonces ¿qué es $a+b+c$? $$ $$ Intento: $\sin(18)$ en un triángulo rectángulo con lados $x$ (en frente de la esquina con ángulo $18$ grados), $y$, y la hipotenusa $z$, es en realidad sólo $\frac{x}{z}$, entonces $\sin(18)=\frac{a + \sqrt{b}}{c}$0. Podemos encontrar $y$ como $$ y = \sqrt{c^{2}- (a + \sqrt{b}) ^{2}} $$ así que tenemos $$ \cos(18) = \frac{y}{z} = \frac{c\sqrt{c^{2}- (a + \sqrt{b}) ^{2}}}{c}$$ También descubrí que $$b = (c {1} - a) {2} = c^2} {2} } } } (a + \sqrt{b} } } } } (a + \sqrt{c} } }) } (a) {1} } } (a) {2} } (a) {2} (a) {2} (a) } (a) {2} (a) } (a) {2} (a) } (a) {2} (a) } (a) {2} (a) } (a) {2} (a) {2} (a) } (a) {2} (a) } (a) {2} (a) {2} (a) } (a) {2} (a) } (a) {1} (a) {1} (a) } (a) {1} (a) {1} (b) } (a) {1} (a) {1} (b) } (a) {1} (a) {1} (a) } (a) {1} (b) {1} (b) } (a) {1} (a) {1} (a) {1} (b) } (a) {1} (a) {1} (a) {1} (b) } (a) {1} (a) {2} (b) {2} (a) } (b) {2} (a) {2} {2} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3} {3}} {3} {3}} {3} {3} {3}}} {3} {3}} {3}}} {3} {3} {3}}} {3} {3}}} {3} {3}} {3} {3}} {3} {3}} {3} {3} {3} {3}}} {3} {3}} {3} {3} {3}}} {3} {3}} {3} {3}}} {3} {3} {3} {3} {3} {3} {3}}}} {3} {3}} {3} {3}} {3} {3}} {3} {3}} {3} {3}}}}}} {3} {3} {3} {3}} {3} {3}}} {3}}} {3} {3} {3} {3}}} {3} {3} {3} {3}} {3}}}} {3} {3}} {3} {3} {3} {3}}} {3} {3}} {3} {3}}} {3}}}}} {3} {3}}} {3}}} {3} {3}}} {3} {3}}} {3} {3}} {3}} {3} {3}}}}}}} {3} {3}}}}} {3} {3}}} {3}}}} {3} {3}} {3} {3} {3} {3}}}}}}}} {3} {3}}}}} {3}}}}}} {3} {3}}}}} {3}}}} {3	algebra-precalculus,trigonometry,euclidean-geometry,contest-math
A.29	Dividing Complex Numbers by Infinity	My PreCalculus teacher recently reviewed the properties of limits with us before our test and stated that any real number divided by infinity equals zero. This got me thinking and I asked them whether a complex number (i.e. $3+2i$ or $-4i$) divided by infinity would equal zero.  This completely stumped them and I was unable to get an answer. After doing some theoretical calculation, knowing that $i=\sqrt{-1}$, I calculated that a complex number such as $\frac{5i}{\infty}=0$ since  $$\frac{5}{\infty}\cdot \frac{\sqrt{-1}}{\infty} = 0\cdot 0 = 0,$$  using properties utilized with real numbers that would state that $\frac{5x}{\infty} = 0$ since $$\frac{5}{\infty}\cdot \frac{x}{\infty} = 0\cdot 0 = 0.$$ Is this theoretical calculation correct or is there more to the concept than this?	Dividiendo los números complejos por infinito	Mi profesor de Precalculo recientemente revisó las propiedades de los límites con nosotros antes de nuestra prueba y declaró que cualquier número real dividido por infinito es igual a cero. Esto me hizo pensar y les pregunté si un número complejo (es decir, $3+2i$ o $-4i$) dividido por infinito sería igual a cero. Esto los sorprendió completamente y no pude obtener una respuesta. Después de hacer algún cálculo teórico, sabiendo que $i=\sqrt{-1}$, calculé que un número complejo como $\frac{5i}{\infty}=0$ desde $$\frac{5}{\infty}\c \frac{\sqrt{-1}}{\infty} = 0\c 0 = 0,5 usando propiedades utilizadas con números reales que indicarían que $\frac{5x}{\infty} = 0$\frac{5}{infty}\cdot \frac}{XX\cdot \frac}{XX} = 0\cdot = 0\cdot = 0\cdot = 0\cdot es este concepto teórico correcto o es que este cálculo es más que 0.5?	algebra-precalculus,limits,complex-numbers,infinity
A.30	Find $a^3+b^3+c^3-3abc$ (binomial theorem)	$$a=\sum_{n=0}^\infty\frac{x^{3n}}{(3n)!}\\b=\sum_{n=1}^\infty\frac{x^{3n-2}}{(3n-2)!}\\c=\sum_{n=1}^\infty\frac{x^{3n-1}}{(3n-1)!}$$Find $a^3+b^3+c^3-3abc$: $(a)\ 1$ $(b)\ 0$ $(c)-1$ $(d)-2$  Please help me solve this question. I added $a,b$ and $c$. It gives me the expansion of $e^x$. But i dont know how to use it.	Encuentra el $a^3+b^3+c^3-3abc$ (teorema binomial)	$$a=\sum_{n=0}^\infty\frac{x^{3n}}{(3n)!}\\b=\sum_{n=1}^\infty\frac{x^{3n-2}}{(3n-2)!}\\c=\sum_{n=1}^\infty\frac{x^{3n-1}}{(3n-1)!}$$Find $a^3+b^3+c^3-3abc$: $(a)\ 1$ $(b)\ 0$ $(c)-1$ $(d)-2$ Por favor ayúdame a resolver esta pregunta. Añadí $a,b$ y $c$. Me da la expansión de $e^x$. Pero no sé cómo usarlo.	binomial-theorem
A.32	Are definitions axioms?	I just want to ask a very elementary question. When we introduce a "definition" in a first order logical system. For example when we say  Define: $Empty(x) \iff \not \exists y (y \in x) $  Isn't that definition itself an "axiom", call it a definitional axiom. I'm asking this because the one place predicate symbol Empty() is actually new, it is not among the listed primitives of say Zermelo, which has only identity and membership as primitive symbols.  So when we are stating definitions are we in effect stating axioms? but instead of being about characterizing a primitive, they are definitional axioms giving a complete reference to a specified set of symbols in the system. Is that correct? Now if that is the case, then why we don't call it axiom when we state it, I mean why we don't say for example: Definitional axiom 1) $Empty(x) \iff \not \exists y (y \in x)$ Zuhair	¿Son las definiciones axiomas?	Quiero hacer una pregunta muy elemental. Cuando introducimos una "definición" en un sistema lógico de primer orden. Por ejemplo, cuando decimos Define: $Empty(x) \iff \not \exists y (y \in x) $ ¿No es esa definición en sí misma un "axioma", llámenlo un axioma de definición. Lo estoy preguntando porque el símbolo predicado de un lugar Empty() es en realidad nuevo, no está entre los primitivos enumerados de decir Zermelo, que sólo tiene identidad y pertenencia como símbolos primitivos. Así que cuando estamos diciendo definiciones estamos en efecto diciendo axiomas? pero en lugar de ser acerca de caracterizar un axioma primitivo, son axiomas de definición dando una referencia completa a un conjunto específico de símbolos en el sistema. ¿Es eso correcto? Ahora si ese es el caso, entonces no lo llamamos axioma cuando lo declaramos, entonces digo por qué no queremos decir por ejemplo: 1) Definición axioma $Empty(x) \iff \not \exists y (y \in x)$ Zuhair	terminology,definition,first-order-logic,axioms
A.33	Physical meaning and significance of third derivative of a function	Given a physical quantity represented by a function $f(t,x)$ what is (if there is any) the actual meaning of the third derivative of $f$, $\frac{\partial^3 f}{\partial t^3}$ or $\frac{\partial^3 f}{\partial x^3}$	Significado físico y significancia de la tercera derivada de una función	Dada una cantidad física representada por una función $f(t,x)$, cuál es (si existe) el significado real de la tercera derivada de $f$, $\frac{\partial^3 f}{\partial t^3}$ o $\frac{\partial^3 f}{\partial x^3}$	physics
A.34	Extending Knuth up-arrow/hyperoperations to non-positive values	So... I had the silly idea to extend Knuth's up-arrow notation so that it included zero and negative arrows. It is normally defined as $$\begin{align*} a \uparrow b & = a^b \\ a \uparrow^n b & = \underbrace{a \uparrow^{n - 1} (a \uparrow^{n - 1} (\dots(a \uparrow^{n - 1} a) \dots ))}_{b\text{ copies of } a} \end{align*}$$ so, basically the hyperoperation sequence starting from exponentiation. For now, I will only consider $a,b > 0$. If we try to go backwards from $a \uparrow b$, the "trivial" extension (letting down arrows represent negative up arrows, because why the heck not) is: $$\begin{align*} a \;b & = a \cdot b \\ a \downarrow b & = a + b \\ a \downarrow \downarrow b & = \text{see below} \end{align*} \\ \vdots$$ But I had trouble coming up with an expression for $a \downarrow \downarrow \downarrow b$. Maybe it doesn't exist. Alternatively, maybe there is a way of defining $a \; b$ (zero arrows) such that it does exist. So my question is: Is there an extension of Knuth's up-arrow notation such that $a \downarrow^n b$ exists for all $n \geq 3$?  Edit: Welp, I messed this question up. I initially thought $a \downarrow \downarrow b = a + 1$ was correct, but it is actually $b + 1$. So I thought I had an example of an extension when I did not. I have modified the question accordingly.  An extension would define $a \uparrow^n b$ for each $n \leq 0$ which satisfies the recursive definition of the notation.  Edit 2: Okay, turns out $a \downarrow \downarrow b = b + 1$ isn't correct either, as this would imply $a \downarrow b = a + b - 1$. For example, $4 \downarrow 3 = 4 \downarrow \downarrow (4 \downarrow \downarrow 4) = 4 \downarrow \downarrow (4 + 1) = (4 + 1) + 1 = 6 = 4 + 3 - 1$. But it is really close; perhaps we need an exception, such as $$\begin{align*} a \downarrow \downarrow b = \begin{cases}b + 1 & \text{if } a < b \\ b + 2 & \text{if } a = b \end{cases}\end{align*}.$$ The case $a > b$ does not show up when evaluating $a \downarrow b$, but it will be need to be defined if we try to extend further to $a \downarrow \downarrow \downarrow b$. For instance, we could abuse the fact that the case $a > b$ is allowed to be anything, and let $$a \downarrow \downarrow b = b + 1 + \left\lfloor \frac{a}{b} \right\rfloor,$$ but finding $a \downarrow \downarrow \downarrow b$ may be intractable as a result.	Extensión de las flechas/hiperoperaciones de Knuth hacia arriba a valores no positivos	Así que... tuve la tonta idea de extender la notación de flecha ascendente de Knuth para que incluyera copias de la flecha cero y negativa. Normalmente se define como $$\begin{align*} a \uparrow b & = a^b \\ a \uparrow^n b & = \underbrace{a \uparrow^n - 1} (a \uparrow^{n - 1} (\dots\a \uparrow^{n - 1} a) \dots }) {{b\text{{{text{text{text{text}} a} \{line}}1} así que básicamente la secuencia de hiperoperación que comienza de la exponenciación. Por ahora, sólo consideraré que si intentamos ir hacia abajo desde la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la expansión de la ex ex ex ex ex expansión de la ex ex ex expansión de la ex ex ex ex ex ex ex ex ex ex ex ex ex expansión de la ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex ex	hyperoperation,ackermann-function
A.35	When does a function NOT have an antiderivative?	I know this question may sound naïve but why can't we write $\int e^{x^2} dx$ as $\int e^{2x} dx$? The former does not have an antiderivative, while the latter has. In light of this question, what are sufficient conditions for a function NOT to have an antiderivative. That is, do we need careful examination of a function to say it does not have an antiderivative or is there any way that once you see the function, you can right away say it does not have an antiderivative?	¿Cuándo una función NO tiene un antiderivado?	Sé que esta pregunta puede sonar ingenuo pero ¿por qué no podemos escribir $\int e^{x^2} dx$ como $\int e^{2x} dx$? La primera no tiene un antiderivado, mientras que la segunda lo tiene. A la luz de esta pregunta, ¿cuáles son las condiciones suficientes para que una función NO tenga un antiderivado? Es decir, necesitamos un examen cuidadoso de una función para decir que no tiene un antiderivado o hay alguna manera de que una vez que ves la función, puedes decir inmediatamente que no tiene un antiderivado?	integration
A.36	Proof by contradiction, status of initial assumption after the proof is complete.	First of all I'd like to say that I have looked for the answers to my specific question and have not found it in the existing topics. The question is fairly simple. Say, we need to  prove statement P by the method of contradiction. Assuming that $\lnot P$ holds, using the list of statements proven earlier to hold or derived by us during the proof, we arrive to P being $true$. $$\lnot P  \to A_1 \to\ ... \ \to A_n \to P$$ $$\lnot P  \to  P \iff \lnot(\lnot P) \lor P \iff P $$ We can therefore add P to the list of our proven statements, because it was derived. Most of the proofs contain something in the lines of "the obtained contradiction proves that our initial assumption ($\lnot P$) was wrong and so $P$ holds". What I don't understand is, if the initial assumption ($\lnot P$) is thus proven to be false, then why can we be sure that anything derived from it holds (in particular, that P holds)? On the other hand, if it cannot be derived then the assumption ($\lnot P$) can in fact be true.  Can someone explain why this type of argument cannot be used?	Prueba por contradicción, estado de suposición inicial después de que la prueba esté completa.	En primer lugar me gustaría decir que he buscado las respuestas a mi pregunta específica y no la he encontrado en los temas existentes. La pregunta es bastante simple. Digamos, necesitamos probar la afirmación P por el método de contradicción. Suponiendo que $\lnot P$ es cierto, utilizando la lista de afirmaciones probadas anteriormente para sostener o derivadas por nosotros durante la prueba, llegamos a que P es $true$. $$\ln no P \to A_1 \to\... \to A_n \to P$$ $$\ln no P \to P \iff \l\t P) \lor P \iff P $$ Podemos, por lo tanto, agregar P a la lista de nuestras afirmaciones probadas, porque fue derivado. La mayoría de las pruebas prueban algo en las líneas de "la hipótesis obtenida de contradicción que era derivada ($\lnot P$) y así que no podemos entender que P {\displaystyle P} puede ser falso si alguien puede sostenerlo, entonces, si se puede explicar por qué es falso en el caso de que se puede sostener algo derivado de la hipótesis inicial ($\lnot P$) ($\lnot P$) (por lo que entonces, si se puede tener algo en la mano) (P) (por lo que no podemos entender que se puede ser demostrado en el hecho, entonces, si se puede tener algo en la prueba de la prueba de que se puede derivar de la prueba de la prueba inicial ($\lnot P$) ($\lnot P$) ($\lnot P$) (por lo cual, entonces, si se puede que se puede que se puede que se puede que se puede tener en el hecho) (p) (en el caso de que se puede que se puede que se puede tener en el caso de la prueba de que se puede que se haya derivado de la prueba de la prueba de la prueba de la prueba de la prueba de la prueba de P?	logic,proof-writing
A.37	Non trivial examples of $f\circ g = g \circ f$ but $f^{-1} \neq g$ and $f\neq\mathrm{id}\neq g$.	Are there real-valued functions $f$ and $g$ which are neither each other's inverses, the identity, nor linear, yet exhibit the behaviour $$f\circ g = g \circ f?$$ Examples such as $f(x) = 2x$ and $g(x)=3x$ are "trivial" in this sense.  Moreover, given a function $f$, can one go about obtaining an example of a function $g$ which commutes with $f$?  I suppose this would be similar to fixed point iteration? E.g. if $f\colon\mathbb R\smallsetminus\{1\}\to\mathbb R$ is defined by $f(x) = 2x/(1-x)$, I would need a function $g$ such that  $$g(x) = f^{-1}\circ g\circ f =\frac{g(\frac{2x}{1-x})}{2+g(\frac{2x}{1-x})},$$ so maybe choosing an appropriate "starting function" $g_0$ and finding a fixed point of $g_{n+1} \mapsto f^{-1}\circ g_n\circ f$ would be a possible strategy, but I can't seem to find a suitable $g_0$.	Ejemplos no triviales de $f\circ g = g \circ f$ pero de $f^{-1} \neq g$ y $f\neq\mathrm{id}\neq g$.	¿Existen funciones de valor real $f$ y $g$ que no son inversas, la identidad, ni lineales entre sí, pero que muestran el comportamiento $$f\circ g = g \circ f?$$ Ejemplos como $f(x) = 2x$ y $g(x)=3x$ son "triviales" en este sentido. Además, dadas una función $f$, ¿puede uno obtener un ejemplo de una función $g$ que comuta con $f$? Supongo que esto sería similar a la iteración de punto fijo? Por ejemplo, si $f\colon\mathbb R\smallsetminus\{1\}\to\mathbb R$ es definido por $f(x) = 2x/(1-x)$, necesitaría una función $g$ tal que $$g(x) = f^{-1}\circ g\circ f =\frac{g\frac{2x}{1}}{2+g\frac}{2}{2}{2}}{2}}{2}{2}{2}{2}{2}{2}{2}}{2}{2}}{2}}{2}}{2}}{2}}{2}}{2}}{2}}{2}}{2}}{2}}}{2}{2}}{2}}{2}}}{2}}{2}}{2}}{2}}{2}}{2}}{2}}{2}}{2}{2}}{2}}{2}}{2}}{2}}{2}}{2}{2}}{2}}{2}{2}}}{2}{2}}}{2}{2}}{2}}{2}}{2}}{2}{2}}{2}{2}}}{2}{2}}{2}}{3}}{3}{3}}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}}{3}{3}{3}{3}{3}{3}{3}{3}}{3}{3}{3}{3}{3}{3}{3}}{3}{3}{3}{3}}{3}{3}{3}}{3}{3}{3}{3}{3}}}{3}{3}{3}{3}}{3}{3}}}{3}{3}{3}{3}}{3}{3}{3}}{3}}{3}{3}}{3}{3}{3}{3}}{3}{3}{3}}}}{3}{3}{3}}{3}{3}{3}{3}{3}}{3}{3}}{3}{3}{3}{3}{3}}{3}{3}{3}}{3}{3}{3}{3}}}{3}{3}{3}{3}}{3}}}{3}{3}}{3}{3}}{3}{3}}}{3}{3}{3}{3}{3}}}{3}{3}}{3}{3}}{3}{3}}}{3}{3}}}{3}}}}{3}{3}{3}{3}{3}}{3}}}}}}{3}{3}{3}{3}{3}{3}{3}{3}{3}}}{3}{3}{3}{3}{3}}}{3}{3}}}{3}{3}}{3}{3}{3}{3}}}}{3}{3}}}{3}}}}}{3}{3}{3}{3}}{3}}}}}}}{3}{3	real-analysis,functional-analysis,functions
A.38	Uses of Axiom of Choice	I am a first-year maths student but I occasionally drift away from our taught material. Some years ago I saw the ZFC axioms for the first time, but now that I am in college, and although the stuff I've been taught so far is nowhere near ZFC (in terms of difficulty), it happened to me that we use the axiom of choice all the time in every module, even if we don't know it by name yet. For example, in the proof that, for every non-negative integers $a, b$, there exist integers $q, r: a = bq + r$ (with the known restrictions on r), and the proof starts like this: $Choose$ the largest integer $q : qb <= a$... blah blah blah. Is it the axiom of choice that allows us to execute this simple yet so important step?  And a couple more questions: Can you name some other simple proofs, theorems, results etc for which the axiom of choice is essential? Also, I've read that AOC has long been a topic of dispute for mathematicians, and that even today, some people do not accept it. Are there any alternative axiomatic systems that work equally well without needing AOC? Thanks!	Utilizaciones del axioma de la elección	Soy estudiante de matemáticas de primer año pero de vez en cuando me alejo de nuestro material enseñado. Hace algunos años vi los axiomas de ZFC por primera vez, pero ahora que estoy en la universidad, y aunque las cosas que me han enseñado hasta ahora no están cerca de ZFC (en términos de dificultad), me pasó que usamos el axioma de elección todo el tiempo en cada módulo, incluso si aún no lo conocemos por nombre. Por ejemplo, en la prueba de que, para cada número entero no negativo $a, b$, existen números enteros $q, r: a = bq + r$ (con las restricciones en r), y la prueba comienza así: $Choose$ el número entero más grande $q : qb <= a$ ... bla bla bla bla. ¿Es el axioma de elección que nos permite ejecutar este simple tan importante? Y un par de preguntas más: ¿Llamáis a algunos otros simples, o los resultados, por el cual el trabajo de los sistemas de axiomas no es esencial, ¿puede que la gente de hoy en día acepta que el sistema de axiomas es igual? ¡También hay una discusión, ¿y si todavía hay algún tipo de matemáticos que no tienen un problema de elección?	set-theory
A.39	How to know which value is bigger?	Which is bigger between $2018^{2019}$ or $\ 2019^{2018}\ $? When taking logs of both sides and  I get:  $2019\log(2018)\ $ and $\ 2018 \log(2019)$ I know $\log 2019\gt \log 2018$ so does this mean that $2019^{2018}$ is the biggest one? And did I do it properly?	¿Cómo saber cuál es el valor más grande?	¿Cuál es mayor entre $2018^{2019}$ o $\ 2019^{2018}\ $? Cuando tomo registros de ambos lados y obtengo: $2019\log(2018)\ $ y $\ 2018 \log(2019)$ sé $\log 2019\gt \log 2018$ así que esto significa que $2019^{2018}$ es el más grande? ¿Y lo hice correctamente?	algebra-precalculus,logarithms
A.40	What is the meaning of the term "linear"	$a_1x_1+a_2x_2+a_3x_3+...+a_nx_n=$ is called a linear equation because it represents the equation of a line in an n dimensional space. So "linear" comes from the word "line".Basically there should not be any higher power of x failing which the graph of the function will not be a straight line. simillarly $a(x)y+b(x)y'+c(x)y"+d(x)y'''+...+q(x)=0$ is also called linear differential equation because all the derivatives have power equal to 1 which is similar to the above definition of a linear equation. A function f is called linear if: $f(x+y)=f(x)+f(y)$ and $f(cx)=cf(x)$. Here c is a constant. In this definition of linearity of function "$f$" what does the word linear means? How does it relate to a straight line? Finally what does the term linear means in case of linear vector spaces? Where is the reference to a straight line? So, whether linear is just a word used in different contexts? Does it have different meaning in different situation? Or linearity refers to some relation to a straight line? At Least please explain how the linearity of function f and linear vector space relate to the equation of a line.	¿Qué significa el término "lineal"	$a_1x_1+a_2x_2+a_3x_3+...+a_nx_n=$ se llama ecuación lineal porque representa la ecuación de una línea en un espacio n dimensiones. Así que "lineal" proviene de la palabra "linea".Básicamente no debe haber ninguna potencia superior de x fallido en el que el gráfico de la función no será una línea recta. de manera similar $a(x)y+b(x)y'+c(x)y"+d(x)y'''+...+q(x)=0$ también se llama ecuación diferenciale lineal porque todas las derivadas tienen una potencia igual a 1 que es similar a la definición anterior de una ecuación lineal. Una función f se llama lineal si: $f(x+y)=f(x)+f(y)$ y $f(cx)=cf(x)$. Aquí c es una constante. En esta definición de linealidad de función "$f$" ¿qué significa la palabra lineal? ¿Cómo se relaciona con una línea recta? ¿Qué significa el término lineal en caso de espacios de líneas de vectores lineales? ¿Dónde está la referencia a una línea recta? ¿Por favor, por favor, explicar si se utiliza una palabra diferente en contextos diferentes de una función lineal? ¿O en algún contexto, ¿cuál es el significado de la relación de la línea recta? ¿O en algún contexto, ¿se refiere a la función lineal a la relación de la línea recta?	linear-algebra
A.41	Confusion in how to find number of onto functions if two sets are given	In the book it is given if A and B are two finite sets containing $m$ and $n$ elements, respectively, then the number of onto functions from A to B will be if  $n \leq m$  $$\sum_{r=1}^n (-1)^{(n-r)} {n \choose r}(r)^m $$ well I can't understand it and I am aware with combinations.	Confusión en cómo encontrar el número de en funciones si se dan dos conjuntos	En el libro se da si A y B son dos conjuntos finitos que contienen los elementos $m$ y $n$, respectivamente, entonces el número de en funciones de A a B será si $n \leq m$ $$\sum_{r=1}^n (-1)^{(n-r)} {n \choose r}(r)^m $$ bueno no puedo entenderlo y soy consciente de las combinaciones.	combinatorics,functions,combinations
A.42	What is a simple, physical situation where complex numbers emerge naturally?	I'm trying to teach middle schoolers about the emergence of complex numbers and I want to motivate this organically. By this, I mean some sort of real world problem that people were trying to solve that led them to realize that we needed to extend the real numbers to the complex.  For instance, the Greeks were forced to recognize irrational numbers not for pure mathematical reasons, but because the length of the diagonal of a square with unit length really is irrational, and this is the kind of geometrical situation they were already dealing with. What similar situation would lead to complex numbers in terms that kids could appreciate? I could just say, try to solve the equation $x^2 + 1 = 0$, but that's not something from the physical world. I could also give an abstract sort of answer, like that $\sqrt{-1}$ is just an object that we define to have certain properties that turn out to be consistent and important, but I think that won't be entirely satisfying to kids either.	¿Qué es una situación física simple en la que los números complejos surgen naturalmente?	Estoy tratando de enseñar a los estudiantes de secundaria sobre la aparición de números complejos y quiero motivar esto orgánicamente. Por esto, quiero decir una especie de problema del mundo real que la gente estaba tratando de resolver que les llevó a darse cuenta de que necesitábamos extender los números reales al complejo. Por ejemplo, los griegos se vieron obligados a reconocer los números irracionales no por razones matemáticas puras, sino porque la longitud de la diagonal de un cuadrado con longitud unitaria es realmente irracional, y este es el tipo de situación geométrica con la que ya estaban tratando. ¿Qué situación similar llevaría a números complejos en términos que los niños podrían apreciar? Podría decir, tratar de resolver la ecuación $x^2 + 1 = 0$, pero eso no es algo del mundo físico. También podría dar un resumen de la respuesta, como que $\sqrt{-1}$ es un tipo de objeto que definimos para tener ciertas propiedades que se vuelven consistentes y que no es importante para satisfacer a los niños.	complex-numbers,physics,applications
A.43	Prove $\sum_{n\geq1}\frac1{n^2+1}=\frac{\pi\coth\pi-1}2$	I am trying to prove  $$\sum_{n\geq1}\frac1{n^2+1}=\frac{\pi\coth\pi-1}2$$ Letting $$S=\sum_{n\geq1}\frac1{n^2+1}$$ we recall the Fourier series for the exponential function $$e^x=\frac{\sinh\pi}\pi+\frac{2\sinh\pi}\pi\sum_{n\geq1}\frac{(-1)^n}{n^2+1}(\cos nx-n\sin nx)$$ Plugging in $x=\pi$ $$e^\pi=\frac{\sinh\pi}\pi+\frac{2\sinh\pi}\pi\sum_{n\geq1}\frac{(-1)^n}{n^2+1}(\cos n\pi-n\sin n\pi)$$ $$e^\pi=\frac{\sinh\pi}\pi+\frac{2\sinh\pi}\pi\sum_{n\geq1}\frac{(-1)^n}{n^2+1}((-1)^n-n\cdot0)$$ $$e^\pi=\frac{\sinh\pi}\pi+\frac{2\sinh\pi}\pi S$$ $$S=\frac{\pi e^\pi}{2\sinh\pi}-\frac12$$ But that is nowhere near to correct. What did I do wrong, and how do can I prove the identity? Thanks.	Prueba $\sum_{n\geq1}\frac1{n^2+1}=\frac{\pi\coth\pi-1}2$	Estoy tratando de probar $$\sum_{n\geq1}\frac1{n^2+1}=\frac{\pi\coth\pi-1}2$$ Dejar $$S=\sum_{n\geq1}\frac1{n^2+1}$$ recordamos la serie de Fourier para la función exponencial $$e^x=\frac{\sinh\pi}\pi+\frac{2\sinh\pi}\pi\\\\frac{2\sinh\pi}\pi\\frac{2\frac{1}\n\n}\n}{n^2\coth\pi-1}\n^1}\n nx-n\sin) $$ Plugging en $$e\frac{1\pinx}\\\h\pinx}\\\\\\\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx\pinx	real-analysis,sequences-and-series
A.44	For $A,B \in \mathscr{M}_{2\times2}(\mathbb{Q}) $ of finite order, show that $AB$ has infinite order	Let $G$ be the group $ ( \mathscr{M}_{2\times2}(\mathbb{Q}) , \times ) $ of nonsingular matrices. Let $ A = \left ( \begin{matrix}  0 & -1 \\   1 & 0  \end{matrix} \right ) $, the order of $A$ is $4$; Let $ B = \left ( \begin{matrix}  0 & 1 \\   -1 & -1  \end{matrix} \right ) $, the order of $B$ is $3$. Show that $AB$ has infinite order.  The only reasoning possible here is by contradiction as $G$ is not abelian. And so I tried, but I got stuck before any concrete development. Any hints are welcome, Thanks.	Para $A,B \in \mathscr{M}_{2\times2}(\mathbb{Q}) $ de orden finito, muestre que $AB$ tiene orden infinito	Que $G$ sea el grupo $ ( \mathscr{M}_{2\times2}(\mathbb{Q}) , \times ) $ de matrices no singulares. Que $ A = \left ( \begin{matrix}  0 & -1 \\   1 & 0  \end{matrix} \right ) $, el orden de $A$ es $4$; Que $ B = \left ( \begin{matrix}  0 & 1 \\   -1 & -1  \end{matrix} \right ) $, el orden de $B$ es $3$. Muestre que $AB$ tiene un orden infinito. El único razonamiento posible aquí es por contradicción ya que $G$ no es abeliano. Y así lo intenté, pero me quedé atascado antes de cualquier desarrollo concreto. Cualquier sugerencia es bienvenida, gracias.	matrices,group-theory,cyclic-groups
A.45	How to prove that {$\sin(x) , \sin(2x) , \sin(3x) ,...,\sin(nx)$} is independent in $\mathbb{R}$?	Prove that {$\sin(x) , \sin(2x) , \sin(3x) ,...,\sin(nx)$} is independent in $\mathbb{R}$  my trial : we know that the Wronsekian shouldn't be $0$ to get the trivial solution and thus they are independent. its not trivial to show that $ W \not = 0$ W =  $\begin{vmatrix} (1)\sin(x) & (1)\sin(2x) & (1)\sin(3x) &  ... &   (1)\sin(nx) \\ (1)\cos(x) & (2)\cos(2x) & (3)\cos(3x) &  ... &   (n)\cos(nx) \\  -(1)^2\sin(x) & -(2)^2\sin(2x) & -(3)^2\sin(3x) &  ... &   -(n)^2\sin(nx) \\ -(1)^3\cos(x) & -(2)^3\cos(2x) & -(3)^3\cos(3x) &  ... &   -(n)^3\cos(nx) \\ \end{vmatrix}$ and so on. it looks like Vandermonde matrix but i cant prove that and so we conclude that its $W\not =0$	¿Cómo demostrar que {$\sin(x) , \sin(2x) , \sin(3x) ,...,\sin(nx)$} es independiente en $\mathbb{R}$?	Pruebe que {$\sin(x) , \sin(2x) , \sin(3x) ,...,\sin(nx)$} es independiente en $\mathbb{R}$ mi ensayo: sabemos que el Wronsekian no debería ser $0$ para obtener la solución trivial y por lo tanto son independientes. no es trivial para mostrar que $ W \not = 0$ W = $\begin{vmatrix} (1)\sin(x) & (1)\sin(2x) & (1)\sin(3x) &  ... &   (1)\sin(nx) \\ (1)\cos(x) & (2)\cos(2x) & (3)\cos(3x) &  ... &   (n)\cos(nx) \\  -(1)^2\sin(x) & -(2)^2\sin(2x) & -(3)^2\sin(3x) &  ... &   -(n)^2\sin(nx) \\ -(1)^3\cos(x) & -(2)^3\cos(2x) & -(3)^3\cos(3x) &  ... &   -(n)^3\cos(nx) \\ \end{vmatrix}$ y así sucesivamente. se parece a la matriz de Vandermonde pero no puedo probar que y así concluimos que su $W\not =0$	ordinary-differential-equations
A.46	Suppose $f$ is a Lebesgue integrable function on$[0,1]$ which satisfies $\int x^k f(x) dx=0$ , prove $f=0 \text{ a.e.}$	Suppose $f$ is an indefinitely differentiable real valued function on$[0,1]$ which satisfies $\int_0^1 x^k f(x)\, dx=0$ for $k=\{0,1,2,3,.. .\}$, prove $f=0$ . My attempt : To prove this assertion , it suffice to prove $$\int_0^1 f^2 (x) \,dx=0$$  Then by approximation theorem , we can find a polynomial such that for every $\epsilon \gt 0$ $$\int_0^1 f^2 (x) \,dx= \int_0^1 (f(x)-\sum_{n=0}^N a_n x^n)f(x) ,dx+\int_0^1 \sum_{n=0}^N f(x) a_n x^n\,dx \le \epsilon M$$ where $M=\sup_{x \in [0,1]}|f(x)|$ . It seems that we do not need the condition that $f$ is indefinitely differentiable , if $f$ is continuous then the conclution may hold . My question : a) Suppose $f$ is a Lebesgue integrable real valued function on$[0,1]$ which satisfies $\int_0^1 x^k f(x)\ dx=0$ for $k=\{0,1,2,3,.. .\}$, can we prove $f=0$ except on a set of measure $0$ ?      b) If a) is not true , suppose $f$ is a Riemann integrable real valued function on$[0,1]$ which satisfies $\int_0^1 x^k f(x)\ dx=0$ for $k=\{0,1,2,3,.. .\}$, can we prove $f=0$ except on a set of measure $0$ ?   EDIT: To prove $f=0 \text{  a.e.}$ , it suffice to prove all the fourier coefficient of $f$ equal to $0$ , then  $$\int_0^1 f(x) \cos(2 \pi nx) \,dx \le \int_0^1 |f(x)||\cos(2 \pi nx)-\sum_{n=0}^{N}a_n x^n| \le \epsilon||f||_{L^1}$$ and the proof is complete.	Supongamos que $f$ es una función integrable de Lebesgue en $[0,1]$ que satisface $\int x^k f(x) dx=0$ , prueba $f=0 \text{ a.e.}$	Supongamos que $f$ es una función real de valor indefinidamente diferenciable en $[0,1]$ que satisface $\int_0^1 x^k f(x)\, dx=0$ para $k=\{0,1,2,3,.. .\}$, prueba $f=0$ . Mi intento: Para probar esta afirmación, basta con probar $$\int_0^1 f^2 (x) \,dx=0$$ Entonces, mediante el teorema de aproximación , podemos encontrar un polinomio tal que para cada $\epsilon \gt 0$ $$\int_0^1 f^2 (x) \,dx= \int_0^1 (fx) \,dx= \int_0^1 (fx) \,x=\sum_{n=0} \n=x) \,dx+\int_0^1 \n=0} \n^x) \n_xn=xn \,dx\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n	real-analysis
A.47	Prove that for a given prime $p$ and each $0 < r < p-1$, there exists a $q$ such that $rq \equiv 1 \bmod p$	Prove that for a given prime $p$ and each $0 < r < p-1$, there exists a $q$ such that  $$rq \equiv 1 \bmod p$$ I've only taken one intro number theory course (years ago), and this just popped up in a computer science class (homework). I was assuming that this proof would be elementary since my current class in an algorithm cours, but after the few basic attempts I've tried it didn't look promising. Here's a couple approaches I thought of:  (reverse engineer) To arrive at the conclusion we would need $$rq - 1 = kp$$ for some $k$. A little manipulation: $$qr - kp = 1$$ That looks familiar, but I can't see anything from it.  (sum on $r$) $$\sum_{r=1}^{p-2} r = \frac{(p-2)(p-1)}{2} = p\frac{p - 3}{2} + 1 \equiv 1 \bmod p$$ which looks good but I don't know how to incorporate $r$ int0 the final equality.    (Wilson's Theorem—proved by Lagrange)   I vaguely recall this theorem, but I was looking at it in an old book and it wasn't easy to see how we arrived there. Anyways, $p$ is prime iff $$(p-1)! \equiv -1 \bmod p$$ Here the $r$ multiplier is built in to the factorial expression so I was thinking of adding $2$ to either side $$(p-1)! + 2 \equiv 1 \bmod p$$ which is a dead end (pretty sure). But then I was thinking, maybe multiplying Wilson't Thm by $(p+1)$? Then getting $$(p+1)(p-1)! = -(p+1) \bmod p$$ which I think results in $$(p+1)(p-1)! = 1 \bmod p$$ of which $r$ is a multiple and $q$ is obvious. But I'm not sure if that's valid.	Demostrar que para un dado primo $p$ y cada $0 < r < p-1$, existe un $q$ tal que $rq \equiv 1 \bmod p$	Pruebe que para un dado número primo $p$ y cada $0 < r < p-1$, existe un $q$ tal que $$rq \equiv 1 \bmod p$$ He tomado sólo un curso de teoría de números introductorio (hace años), y esto acaba de aparecer en una clase de ciencias de la computación (tarea de trabajo). Yo estaba asumiendo que esta prueba sería elemental desde mi clase actual en un curso de algoritmo, pero después de los pocos intentos básicos que he intentado no parecía prometedor. Aquí hay un par de enfoques que pensé: (ingeniero inverso) para llegar a la conclusión que necesitaríamos $$rq \bmod p$$ para algunos $k$. Entonces necesitamos $$rq \b=1\b=1\b=1\b=1\b=1\b=1\b=1\b=1\b=1\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\	elementary-number-theory,proof-verification
A.48	Hints for showing that if $x,y \geq 0$, then $(x+y)^k \geq x^k + y^k$ for all $k \geq 1$	I'm trying to show the following:   If $x,y \geq 0$, then $(x+y)^k \geq x^k + y^k$ for all $k \in \mathbb{R_{\geq 1}}$   So, far I've tried a few things, but nothing seems to stick. Clearly $x \leq x+ y$ and since both sides of the inequality are positive, the inequality $x^k \leq (x + y)^k$ will hold for $k \geq 1$. Similarly, $y^k \leq (x+y)^k$. Adding both inequalities together, we obtain: $x^k + y^k \leq 2(x+y)^k$. While this is close, of course, it is not what we want to show. Alternatively, I was thinking that if we fix $x,y \geq 0$, let $f(k) = (x+y)^k$, and let $g(k) = x^k + y^k$, we can show using the binomial theorem that $(x+y)^r \geq x^r + y^r$ for all $r \in \mathbb{Z^+}$. Then, if we can show both $f$ and $g$ intersect only when $k =1 $, we might have better luck proving the statement since then we would have $(x+y)^r > x^r + y^r$ for all positive integers $r \geq 2$. A real number $m \notin \mathbb{Z}$ with the property that $f(m) = g(m)$ could not then exist since then that would violate the fact that $k=1$ is the only intersection. We could then invoke the continuity of $f$ and $g$ together with the fact that $(x+y)^r > x^r + y^r$ for all positive integers $r \geq 2$ to obtain our result. Of course, all of this is dependent on rigorously showing that $f$ and $g$ intersect only when $k=1$. Otherwise, I'm running low on ideas. Any hints would be greatly appreciated.	Indicios para mostrar que si $x,y \geq 0$, entonces $(x+y)^k \geq x^k + y^k$ para todos los $k \geq 1$	Estoy tratando de mostrar lo siguiente: si $x,y \geq 0$, entonces $(x+y)^k \geq x^k + y^k$ para todos los $k \in \mathbb{R_{\geq 1}}$ Así que, hasta ahora he intentado algunas cosas, pero nada parece quedarse. Claramente $x \leq x+ y$ y ya que ambos lados de la desigualdad son positivos, la desigualdad $x^k \leq (x + y)^k$ se mantendrá para $k \geq 1$. De manera similar, $y^k \leq (x+y)^k$. Sumando ambas desigualdades juntas, obtenemos: $x^k + y^k \leq 2(x+y)^k$. Mientras que esto es cercano, por supuesto, no es lo que queremos mostrar. Alternativamente, estaba pensando que si fijamos $x,y \geq 0$, que $f(k) = (x+y)^k$, y que $x,y \geq 0$0, podemos mostrar usando el teorema binómico que $x,y \geq 0$1 para todos los $x,y \geq 0$2. Entonces, si podemos mostrar que ambos $x,y \geq 0$3 y $x,y \geq 0$4 se cruzan solo cuando $x,y \geq 0$5, podríamos tener mejor suerte probando la afirmación entonces tendríamos $x,y \geq 0$6 para todos los hinces positivos $x,y \geq 0$7. Una propiedad real con el $x,y \geq 0$9 entonces podría obtener que no se invierta el hecho de que entonces sólo se puede violar el hecho de que $x,y \geq 0$3 y $x,y \geq 0$4 entonces podemos mostrar que todo el $x,y \geq 0$4 se cruza con el $(x+y)^k \geq x^k + y^k$0.	real-analysis,functions,inequality
A.49	Is there a simple combinatoric interpretation of this identity?	I came across an exercise in which we are asked to prove the identity: $${2n\choose n}=\sum_{k=0}^n{n\choose k}^2$$ The exercise gives the hint: $$\left(1+x\right)^{2n}=\left[(1+x)^n\right]^2$$ It's not too difficult to use the hint to prove the identity (the expressions in the identity are the coefficients of $x^n$ in the respective expansions of the expressions in the hint, which of course must be the same number), but I was wondering whether there is a neater equivalent-counting interpretation... It's clear that ${2n \choose n}$ is the number of ways in which we can choose half the elements in a set (where this is possible): how can we interpret $\sum_{k=0}^n{n\choose k}^2$ equivalently?	¿Existe una interpretación combinatoria de esta identidad?	Me encontré con un ejercicio en el que se nos pide que probemos la identidad: $${2n\choose n}=\sum_{k=0}^n{n\choose k}^2$$ El ejercicio da la pista: $$\izquierda(1+x\derecha)^{2n}=\izquierda[(1+x)^n\derecha]^2$$ No es demasiado difícil usar la pista para probar la identidad (las expresiones en la identidad son los coeficientes de $x^n$ en las respectivas expansiones de las expresiones en la pista, que por supuesto debe ser el mismo número), pero estaba preguntando si existe una interpretación de conteo más precisa... Está claro que ${2n \choose n}$ es el número de formas en que podemos elegir la mitad de los elementos en un conjunto (donde esto es posible): ¿cómo podemos interpretar equivalentemente $\sum_{k=0}^n{n\choose k}^2$?	combinatorics,binomial-coefficients
A.50	Divergent series $\sum{\frac{1}{n^{2+\cos{n}}}}$	Bonjour.  Show that  $$\sum{\frac{1}{n^{2+\cos{n}}}}$$ is a divergent serie. $$\\$$ My main problem is: If $\epsilon$ is “infinitely small positive real number” define $A_{\epsilon}$ as the set of all $n, |2+\cos n|\leq 1+\epsilon$ $(n \in A_{\epsilon}\iff-1\leq \cos n \leq -1+\epsilon)$. The divergence should come from the sum over $A_{\epsilon}$ but I have no idea to how to handle this. $$\\$$	Serie de divergentes $\sum{\frac{1}{n^{2+\cos{n}}}}$	Bonjour. Muestre que $$\sum{\frac{1}{n^{2+\cos{n}}}}$$ es una serie divergente. $$\\$$ Mi principal problema es: Si $\epsilon$ es un número real positivo infinitamente pequeño define $A_{\epsilon}$ como el conjunto de todos los $n, |2+\cos n|\leq 1+\epsilon$ $(n \in A_{\epsilon}\iff-1\leq \cos n \leq -1+\epsilon)$. La divergencia debe provenir de la suma sobre $A_{\epsilon}$ pero no tengo idea de cómo manejar esto. $$\\$$	real-analysis,integration,sequences-and-series,analysis
A.51	Sum of series having binomial coefficients	Prove that $\displaystyle \sum_{r=0}^n {n+r\choose r} \frac{1}{2^{r}}= 2^{n}$ what i try $$\binom{n}{n}+\binom{n+1}{1}\frac{1}{2}+\binom{n+2}{2}\frac{1}{2^2}+\binom{n+3}{3}\frac{1}{2^3}+\cdots +\binom{n+n}{n}\frac{1}{2^n}$$ $$\binom{n}{n}+\binom{n+1}{n}\frac{1}{2}+\binom{n+2}{n}\frac{1}{2^2}+\binom{n+3}{n}\frac{1}{2^3}+\cdots +\binom{n+n}{n}\frac{1}{2^n}.$$ coefficient of $x^n$ in  $$(1+x)^n+(1+x)^{n+1}\frac{1}{2}+(1+x)^{n+2}\frac{1}{2^2}+\cdots\cdots +(1+x)^{2n}\frac{1}{2^n}.$$ How do i solve ithelp me plesse	Sumas de series con coeficientes binomial	Pruebe que $\displaystyle \sum_{r=0}^n {n+r\choose r} \frac{1}{2^{r}}= 2^{n}$ lo que intento $$\binom{n}{n}+\binom{n+1}{1}{2}+\binom{n+2}{2}\frac{1}{2^2}+\binom{n+3}{3}\frac{1}{2^3}{n}+\cdots +\binom{n+n}{n}{n}\frac{1}{2^n}$$} $$\binom{n}{n}+\binom{n+1}{n}{n}+\binom{n+d2}{n}\frac{1}{2^2}{n}\n3}{n}{n}{1}{2^2}{2^3}{n}{2}{2}{2}{2}{2}{2}{3}{2}{2}{2}{2}{2}{2}{2}{2}}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}	binomial-coefficients
A.52	Prove $\forall n\in\mathbb{N}$, $\exists m\in\mathbb{N}$ s.t. $m>n$ and $m$ is prime	There are two parts I am having trouble getting started. A. Prove that $n_1, n_2,...,n_k\in\mathbb{N}$ are each at least $2$ then $n=n_1n_2...n_k+1$ is not divisible by any numbers $n_1, n_2,...,n_k$.  B. Prove that the truth of the negation leads to a contradiction. (Use theorem: For all $a,b\in\mathbb{N}$ there exist a unique quotient $q$ and remainder $r$ in $\mathbb{Z^+}$ such that we have both $a=qb+r$ and $0\leq r<q$.) For part A, I started with, given $k\in\mathbb{N}$ and $n_1, n_2,...,n_k\geq1$, I'll show that $\forall i$, $n_i \nmid n=n_1n_2...n_k+1$ to set it up, but I'm not sure how to actually go about starting it. For part B, I know that the negation is $\exists n\in\mathbb{N}$ s.t. $\forall m\in\mathbb{N}$ either $m\leq n$ or $m$ is not prime, but again I'm not sure what I should do to start the proof or exactly how to incorporate that theorem.	Prueba $\forall n\in\mathbb{N}$, $\exists m\in\mathbb{N}$ s.t. $m>n$ y $m$ es primos	Hay dos partes que tengo problemas para comenzar. A. Pruebe que $n_1, n_2,...,n_k\in\mathbb{N}$ son cada uno al menos $2$ entonces $n=n_1n_2...n_k+1$ no es divisible por ningún número $n_1, n_2,...,n_k$. B. Pruebe que la verdad de la negación conduce a una contradicción. (Use teorema: para todos los $a,b\in\mathbb{N}$ existe un cuotiente único $q$ y el resto $r$ en $\mathbb{Z^+}$ de tal manera que tenemos tanto $a=qb+r$ como $n_1, n_2,...,n_k\in\mathbb{N}$0.) Para la parte A, empecé con, dado $n_1, n_2,...,n_k\in\mathbb{N}$1 y $n_1, n_2,...,n_k\in\mathbb{N}$2, voy a mostrar que $n_1, n_2,...,n_k\in\mathbb{N}$3, $n_1, n_2,...,n_k\in\mathbb{N}$4 para establecerlo, pero no estoy seguro de cómo realmente comenzarlo. Para la parte B, sé que la negación es $n_1, n_2,...,n_k\in\mathbb{N}$5 s.t. $n_1, n_2,...,n_k\in\mathbb{N}$6 o $n_1, n_2,...,n_k\in\mathbb{N}$7 o $n_1, n_2,...,n_k\in\mathbb{N}$8 no es exactamente primos, pero de nuevo no estoy seguro de qué debo hacer para comenzar la prueba o cómo incorporar ese teorema.	proof-writing,prime-numbers
A.53	Show that one-sided inverse of a square matrix is a true inverse	We know that for a group element $g\in G$, $gh=1$ does not necessarily mean that $hg = 1$. In the case for matrices (linear maps between vector spaces), it is also true that $AB = 1 \nRightarrow BA = 1$. This happens when the $A$ and $B$ are not square matrices (in which case they do not even form a group under multiplication). However if we restrict the square matrices, $AB = 1 \Rightarrow BA = 1$. What is simple proof of this that avoids chasing the entries, and makes use simply the vector space structure of linear transformations? (In fact if we could prove this, I think this might imply that for a group to have one-sided(but not two-sided) inverses, it has to be infinite, since every finite group admits a finite dimensional representation.	Muestre que la inversa unilateral de una matriz cuadrada es una inversa verdadera	Sabemos que para un elemento de grupo $g\in G$, $gh=1$ no significa necesariamente que $hg = 1$. En el caso de matrices (mapas lineales entre espacios vectoriales), también es cierto que $AB = 1 \nRightarrow BA = 1$. Esto sucede cuando los $A$ y $B$ no son matrices cuadradas (en cuyo caso ni siquiera forman un grupo bajo multiplicación). Sin embargo, si restringimos las matrices cuadradas, $AB = 1 \Rightarrow BA = 1$. ¿Cuál es la prueba simple de esto que evita perseguir las entradas, y utiliza simplemente la estructura del espacio vectorial de las transformaciones lineales? (De hecho, si pudiéramos probar esto, creo que esto podría implicar que para un grupo tener inversos unilaterales, pero no bidimensionales, tiene que ser infinito, ya que cada grupo finito admite una representación dimensional finita.	linear-algebra,group-theory
A.54	By using a diagonal argument, show that the powerset $P(N) = (S|S ⊆ N)$ is uncountable.	Any tips or solutions for this one? By using a diagonal argument, show that the powerset $P(N) = (S|S ⊆ N)$ is uncountable.	Usando un argumento diagonal, muestra que el conjunto de potencias $P(N) = (S|S ⊆ N)$ es incontable.	¿Alguna sugerencia o solución para este? Usando un argumento diagonal, muestre que el conjunto de poderes $P(N) = (S|S ⊆ N)$ es incontable.	discrete-mathematics,elementary-set-theory
A.55	$\frac{1}{\sqrt{-1}}=\sqrt{-1}$?	I have trouble to comprehend what my mistake is in the following calculation: If we set $\sqrt{-1}$ to be the new number with the property that $(\sqrt{-1})^2 = -1$ then I can write $$\frac{1}{\sqrt{-1}}=\sqrt{\frac{1}{-1}}=\sqrt{-1}.$$ But we also have (and I know this is the correct result) $$ \frac{1}{\sqrt{-1}}\cdot\frac{\sqrt{-1}}{\sqrt{-1}}=\frac{\sqrt{-1}}{-1}=-\sqrt{-1}$$ What am I missing? Thanks.	¿La $\frac{1}{\sqrt{-1}}=\sqrt{-1}$?	Tengo problemas para comprender cuál es mi error en el siguiente cálculo: Si establecemos $\sqrt{-1}$ como el nuevo número con la propiedad de que $(\sqrt{-1})^2 = -1$ entonces puedo escribir $$\frac{1}{\sqrt{-1}}=\sqrt{\frac{1}{-1}}=\sqrt{-1}.$$ Pero también tenemos (y sé que este es el resultado correcto) $$ \frac{1}{\sqrt{-1}}\cdot\frac{\sqrt{-1}}{\sqrt{-1}}{-1}}=\frac{\sqrt{-1}}{-1}=-\sqrt{-1}$$ ¿Qué me falta? Gracias.	complex-numbers,definition
A.56	A curious logical formula involving prime numbers	Let $S$ be a nonempty set of natural numbers. Is the following formula $$ \exists p\ \bigl(\text{$p$ is prime } \rightarrow \forall x  \text{ ($x$ is prime)}\bigr)  $$ true or false on $S$? I know the answer to this question, but what would be the shortest way to arrive to the conclusion using some deduction system?	Una curiosa fórmula lógica que involucra números primos	¿Existe la siguiente fórmula $$ \existe p\ \bigl\\text{$p$ es primo } \rightarrow \forall x \text{ ($x$ es primo) }\bigr) $$ verdadero o falso en $S$? Sé la respuesta a esta pregunta, pero ¿cuál sería la forma más corta de llegar a la conclusión utilizando algún sistema de deducción?	logic,first-order-logic
A.57	Preimage of continuous one-to-one function on connected domain is not continuous.	I know that given $B$, a compact subset of $\mathbb{R}^n$, and $f : B \to \mathbb{R}^m$, a continuous injective (one-to-one) function, $f^{-1}$ is continuous on $f(B)$. (This true). I also know that image $f(X)$ of a connected subset $X$ is connected under a continuous function. Now let $X$ be a connected (non-compact) subset of $\mathbb{R}^n$, and $f : X \to \mathbb{R}^m$ be a continuous injective (one-to-one) function. I am trying (and struggling) to provide a counterexample in which mapping $f^{-1} : f(X) \mapsto X$ is not continuous on $f(X)$. (A rigorous, parametrized example). Thank you in advance!	La imagen previa de la función continua uno a uno en un dominio conectado no es continua.	Sé que dado $B$, un subconjunto compacto de $\mathbb{R}^n$ y $f : B \to \mathbb{R}^m$, una función inyectiva continua (uno a uno), $f^{-1}$ es continua en $f(B)$. (esto es cierto). También sé que la imagen $f(X)$ de un subconjunto conectado $X$ está conectada bajo una función continua. Ahora, que $X$ sea un subconjunto conectado (no compacto) de $\mathbb{R}^n$, y $f : X \to \mathbb{R}^m$ sea una función inyectiva continua (uno a uno). Estoy tratando (y luchando) para proporcionar un contraejemplo en el que el mapeo de $f^{-1} : f(X) \mapsto X$ no es continuo en $f(X)$. (Un ejemplo riguroso y parámétrico). Gracias por adelantado!	real-analysis,general-topology,analysis,continuity,metric-spaces
A.58	Prove that $3\arcsin \frac{1}{4} + \arccos \frac {11}{16} = \frac {\pi}{2}$	Can someone help me with this exercise? I honestly don't know where to start and how to prove it. You don't have to answer it fully, just give me a hint or something. Thank you in advance.  Exercise 1. Prove that  $3\arcsin \frac{1}{4} + \arccos \frac {11}{16} = \frac {\pi}{2}$  Thanks.	Prueba eso $3\arcsin \frac{1}{4} + \arccos \frac {11}{16} = \frac {\pi}{2}$	¿Puede alguien ayudarme con este ejercicio? Sinceramente no sé por dónde empezar y cómo demostrarlo. No tienes que contestarlo completamente, sólo dame una pista o algo así. Gracias por adelantado.	trigonometry
A.59	Multiple proofs of $\sum_{d|n}{\phi(d)}=n$	I am looking for multiple proofs of that statement: here $\phi(n)$ denotes the Euler’s totient  $$\sum_{d|n}{\phi(d)}=n$$  Here’s one:  By unique factorisation theorem: $n=\prod_{k=1}^{m}{p_k^{\alpha_k}}$ and $d=\prod_{k=1}^{m}{p_k^{\beta_k}}$ where $0\leq \beta_k\leq \alpha_k$ so:  $\begin{align} \sum_{d|n}{\phi(d)}&=\sum_{0\leq \beta_k\leq \alpha_k}{\phi\left(\prod_{k=1}^{m}{p_k^{\beta_k}}\right)}\\ &= \sum_{0\leq \beta_k\leq \alpha_k}{\prod_{k=1}^{m}\phi({p_k^{\beta_k})}}\\ &=\sum_{0\leq \beta_k\leq \alpha_k}{\prod_{k=1}^{m}{(p_k^{\beta_k}-p_k^{\beta_k-1}})}\\ &=\prod_{k=1}^{m}{\sum_{0\leq \beta_k\leq \alpha_k}{(p_k^{\beta_k}-p_k^{\beta_k-1}}})\\ &= \prod_{k=1}^{m}{p_k^{\alpha_k}}\\ &=n. \end{align}$	Pruebas múltiples de la $\sum_{d|n}{\phi(d)}=n$	Estoy buscando múltiples pruebas de esa afirmación: aquí $\phi(n)$ denota el totiente de Euler $$\sum_d_d_d_d_n}{\phi(d)}=n$$ Aquí está uno: Por teorema de factorizamiento único: $n=\prod_{k=1}^{m}{p_k^{\alpha_k}}$ y $d=\prod_{k=1}^{m}{p_k^{\beta_k}}$ donde $0\leq \beta_k\leq \alpha_k$ así: $\begin{align} \sum_{d|n}{\phi(d)}&=\sum_{0\leq \beta_k\leq \alpha_k}{\phi\left(\prod_{k=1}^{m}{p_k^{\beta_k}}\right)}\\ &= \sum_{0\leq \beta_k\leq \alpha_k}{\prod_{k=1}^{m}\phi({p_k^{\beta_k})}}\\ &=\sum_{0\leq \beta_k\leq \alpha_k}{\prod_{k=1}^{m}{(p_k^{\beta_k}-p_k^{\beta_k-1}})}\\ &=\prod_{k=1}^{m}{\sum_{0\leq \beta_k\leq \alpha_k}{(p_k^{\beta_k}-p_k^{\beta_k-1}}})\\ &= \prod_{k=1}^{m}{p_k^{\alpha_k}}\\ &=n. \end{align}$	group-theory,number-theory,alternative-proof,big-list
A.60	Limiting value of a sequence when n tends to infinity	Q) Let, $a_{n} \;=\; \left ( 1-\frac{1}{\sqrt{2}} \right ) ... \left ( 1- \frac{1}{\sqrt{n+1}} \right )$ , $n \geq 1$. Then $\lim_{n\rightarrow \infty } a_{n}$ (A) equals $1$ (B) does not exist (C) equals $\frac{1}{\sqrt{\pi }}$ (D) equals $0$  My Approach :- I am not getting a particular direction or any procedure to simplify $a_{n}$ and find its value when n tends to infinity. So, I tried like this simple way to substitute values and trying to find the limiting value :- $\left ( 1-\frac{1}{\sqrt{1+1}} \right ) * \left ( 1-\frac{1}{\sqrt{2+1}} \right )*\left ( 1-\frac{1}{\sqrt{3+1}} \right )*\left ( 1-\frac{1}{\sqrt{4+1}} \right )*\left ( 1-\frac{1}{\sqrt{5+1}} \right )*\left ( 1-\frac{1}{\sqrt{6+1}} \right )*\left ( 1-\frac{1}{\sqrt{7+1}} \right )*\left ( 1-\frac{1}{\sqrt{8+1}} \right )*.........*\left ( 1-\frac{1}{\sqrt{n+1}}    \right )$  =$(0.293)*(0.423)*(0.5)*(0.553)*(0.622)*(0.647)*(0.667)* ....$ =0.009*... So, here value is tending to zero. I think option $(D)$ is correct. I have tried like this $\left ( \frac{\sqrt{2}-1}{\sqrt{2}} \right )*\left ( \frac{\sqrt{3}-1}{\sqrt{3}} \right )*\left ( \frac{\sqrt{4}-1}{\sqrt{4}} \right )*.......\left ( \frac{\sqrt{(n+1)}-1}{\sqrt{n+1}} \right )$ = $\left ( \frac{(\sqrt{2}-1)*(\sqrt{3}-1)*(\sqrt{4}-1)*.......*(\sqrt{n+1}-1)}{{\sqrt{(n+1)!}}} \right )$ Now, again I stuck how to simplify further and find the value for which $a_{n}$ converges when $n$ tends to infinity . Please help if there is any procedure to solve this question.	Valor limitante de una secuencia cuando n tiende a infinito	P) Vamos, $a_{n} \;=\; \left ( 1-\frac{1}{\sqrt{2}} \right ) ... \left ( 1- \frac{1}{\sqrt{n+1}} \right )$ , $n \geq 1$. Entonces $\lim_{n\rightarrow \infty } a_{n}$ (A) igual a $1$ (B) no existe (C) igual a $\frac{1}{\sqrt{\pi }}$ (D) igual a $0$ Mi enfoque :- No estoy recibiendo una dirección particular o ningún procedimiento para simplificar $a_{n}$ y encontrar su valor cuando n tiende a infinito. Así que, intenté esta manera simple de sustituir valores y tratar de encontrar el valor limitante :- $\left ( 1-\frac{1}{\sqrt{1+1}} \right ) * \left ( 1-\frac{1}{\sqrt{2+1}} \right )*\left ( 1-\frac{1}{\sqrt{3+1}} \right )*\left ( 1-\frac{1}{\sqrt{4+1}} \right )*\left ( 1-\frac{1}{\sqrt{5+1}} \right )*\left ( 1-\frac{1}{\sqrt{6+1}} \right )*\left ( 1-\frac{1}{\sqrt{7+1}} \right )*\left ( 1-\frac{1}{\sqrt{8+1}} \right )*.........*\left ( 1-\frac{1}{\sqrt{n+1}}    \right )$ =$(0.293)*(0.423)*(0.5)*(0.553)*(0.622)*(0.647)*(0.667)* ....$ =0.009*... Así que aquí el valor tiende a cero. Creo que $a_{n} \;=\; \left ( 1-\frac{1}{\sqrt{2}} \right ) ... \left ( 1- \frac{1}{\sqrt{n+1}} \right )$0 es correcto. He intentado como esta opción $a_{n} \;=\; \left ( 1-\frac{1}{\sqrt{2}} \right ) ... \left ( 1- \frac{1}{\sqrt{n+1}} \right )$1 = $a_{n} \;=\; \left ( 1-\frac{1}{\sqrt{2}} \right ) ... \left ( 1- \frac{1}{\sqrt{n+1}} \right )$2 Ahora, otra vez me he atascado cómo simplificar más y encontrar el valor para el cual $a_{n}$ converge cuando $a_{n} \;=\; \left ( 1-\frac{1}{\sqrt{2}} \right ) ... \left ( 1- \frac{1}{\sqrt{n+1}} \right )$3 tiende a infinito . Por favor, ayude si hay algún procedimiento para resolver esta pregunta.	calculus,sequences-and-series,limits,products
A.61	There exists $i, j \in \mathbb{N}$ such that $n=3i+5j$ for $n\ge 8$	Prove that there exists $i, j \in \mathbb{N}$ such that $n=3i+5j$ for $n\ge 8$  I'm having a hard time with this exercise, I'm trying to prove it by induction: Basis step:  $n=8 \implies 8=3\cdot1+5\cdot 1$ $n=9 \implies 9=3\cdot3+5\cdot0$ $n=10 \implies 10=3\cdot0+5\cdot2$  Induction step: If it's true for $n=h$ then it must be true for $n=h+1$. So now, I don't know how to begin proving that $k+1=3i+5j$.	Existe $i, j \in \mathbb{N}$ tal que $n=3i+5j$ para $n\ge 8$	Pruebe que existe $i, j \in \mathbb{N}$ tal que $n=3i+5j$ para $n\ge 8$ Estoy teniendo un tiempo difícil con este ejercicio, estoy tratando de probarlo por inducción: Paso base: $n=8 \implies 8=3\cdot1+5\cdot 1$ $n=9 \implies 9=3\cdot3+5\cdot0$ $n=10 \implies 10=3\cdot0+5\cdot2$ Paso de inducción: Si es cierto para $n=h$ entonces debe ser cierto para $n=h+1$. Así que ahora, no sé cómo empezar a probar que $k+1=3i+5j$.	elementary-number-theory,discrete-mathematics,induction,diophantine-equations
A.62	Prove that the cardinality of the set of rational numbers and the set of integers is equal	I just learned about cardinality in my discrete class a few days ago, and this is in the homework. This is all fairly confusing to me, and I'm not entirely sure where to even start. Here's the full question: Let $\mathbb{Q}$ denote the set of rational numbers and $\mathbb{Z}$ denote the set of integers. Prove that $|\mathbb{Q}| = |\mathbb{Z}|$. I thought about saying that every element in $\mathbb{Q}$ can be written as some element in $\mathbb{Z} \times \mathbb{Z}$, but I still don't know how to prove that that is a bijection, or even how to prove that $|\mathbb{Z} \times \mathbb{Z}| = |\mathbb{Z}|$. Any help would be greatly appreciated.	Demostrar que la cardinalidad del conjunto de números racionales y el conjunto de números enteros es igual	Hace unos días aprendí sobre la cardinalidad en mi clase discreta, y esto está en la tarea. Esto es bastante confuso para mí, y no estoy completamente seguro de dónde empezar. Aquí está la pregunta completa: Vamos a $\mathbb{Q}$ denotar el conjunto de números racionales y $\mathbb{Z}$ denotar el conjunto de números enteros. Pruebe que $|\mathbb{Q}| = |\mathbb{Z}|$. Pensé en decir que cada elemento en $\mathbb{Q}$ se puede escribir como algún elemento en $\mathbb{Z} \times \mathbb{Z}$, pero todavía no sé cómo demostrar que es una bijección, o incluso cómo probar que $|\mathbb{Z} \times \mathbb{Z}| = |\mathbb{Z}|$. Cualquier ayuda sería muy apreciada.	discrete-mathematics
A.63	$\gcd$ and $\text{lcm}$ of more than $2$ positive integers	For any two positive integers ${n_1,n_2}$, the relationship between their greatest common divisor and their least common multiple is given by $$\text{lcm}(n_1,n_2)=\frac{n_1 n_2}{\gcd(n_1,n_2)}$$ If I have a set of $r$ positive integers ${n_1,n_2,n_3,...,n_r}$, does the same relationship hold? Is it true that $$\text{lcm}(n_1,n_2,n_3,...,n_r)=\frac{\prod_{i=1}^r n_i}{gcd(n_1,n2,n_3,...,n_r)}$$ I feel like this should be easy to prove, but I'm struggling to get a handle on it.	de más de 20 y menos de 20	Para cualquier dos números enteros positivos ${n_1,n_2}$, la relación entre su mayor divisor común y su menor múltiple común es dada por $$\text{lcm}(n_1,n_2)=\frac{n_1 n_2}{\gcd(n_1,n_2)}$$ Si tengo un conjunto de $r$ números enteros positivos ${n_1,n_2,n_3,...,n_r}$, ¿se mantiene la misma relación?	proof-explanation,greatest-common-divisor,least-common-multiple
A.64	Suppose that f : [a, b] → R is continuous and that f([a, b]) ⊂ [a, b]. Prove that there exists a point c ∈ [a, b] satisfying f(c) = c.	Suppose that $f : [a, b] \to \mathbb{R}$ is continuous and that $f([a, b]) \subset [a, b]$. Prove that there exists a point $c \in [a, b]$ satisfying $f(c) = c$.  (If either $f(a) = a$ or $f(b) = b$ there is nothing left to show, so you might as well assume that $f(a) = a$ and $f(b) = b$. Since $f$ takes its values in $[a, b]$ this is the same as assuming that $f(a) > a$ and $f(b) < b$.) So far, I have: Pf. Assume $f(a)>a$ and $f(b)< b$.  Let $x, y \in [a,b]$ such that $f(a)=x$ and $f(b)=y$ which means $f[a,b]=[x,y]$. Notice $[x,y]\subset [a, b]$. Since f is continuous on $[x,y]$, there exists some $c \in [a,b]$ such that $x$ is less than or equal to $c$ is less than or equal to $y$... This is where I am stuck because I don't think I can just assume by Intermediate Value Theorem that some $f(c)=c$?	Supongamos que f: [a, b] → R es continua y que f([a, b])  [a, b]. Pruebe que existe un punto c ∈ [a, b] satisfactorio f(c) = c.	Supongamos que $f : [a, b] \to \mathbb{R}$ es continuo y que $f([a, b]) \subset [a, b]$. Pruebe que existe un punto $c \in [a, b]$ que satisface $f(c) = c$. (Si o $f(a) = a$ o $f(b) = b$ no queda nada que mostrar, entonces también puede asumir que $f(a) = a$ y $f(b) = b$.	real-analysis,continuity,proof-explanation
A.65	How can we show that $e^{-2\lambda t}\lambda^2\le\frac1{e^2t^2}$ for all $\lambda,t\ge0$?	How can we show that $$e^{-2\lambda t}\lambda^2\le\frac1{e^2t^2}\tag1$$ for all $\lambda,t\ge0$? Applying $\ln$ to both sides yields that $(1)$ should be equivalent to $$t\lambda\le e^{t\lambda-1}\tag2.$$ So, if I did no mistake, it should suffice to show $x\le e^{x-1}$ for all $x\ge0$. How can we do this?	¿Cómo podemos mostrar que $e^{-2\lambda t}\lambda^2\le\frac1{e^2t^2}$ para todos los $\lambda,t\ge0$?	¿Cómo podemos mostrar que $$e^{-2\lambda t}\lambda^2\le\frac1{e^2t^2}\tag1$$ para todos los $\lambda,t\ge0$? Aplicando $\ln$ a ambos lados, resulta que $(1)$ debe ser equivalente a $$t\lambda\le e^{t\lambda-1}\tag2.$$ Así que, si no cometí ningún error, debería ser suficiente para mostrar $x\le e^{x-1}$ para todos los $x\ge0$.	calculus,inequality,exponential-function
A.66	if $x,h \in \mathbb{R}^d$ and $A \in \mathbb{R}^{d\times d}$ is it possible to justify that $(x^TAh)^T = h^TA^Tx$?	if $x,h \in \mathbb{R}^d$ and $A \in \mathbb{R}^{d\times d}$ is it possible to justify that $(x^TAh)^T = h^TA^Tx$?	si $x,h \in \mathbb{R}^d$ y $A \in \mathbb{R}^{d\times d}$ es posible justificar que $(x^TAh)^T = h^TA^Tx$?	si $x,h \in \mathbb{R}^d$ y $A \in \mathbb{R}^{d\times d}$ es posible justificar que $(x^TAh)^T = h^TA^Tx$?	linear-algebra,transpose
A.67	Combination of matrixes	If A is a $k\times k$ matrix,B is a $k\times l$ matrix and C is a $l\times l$ matrix prove that: $\det{\begin{bmatrix}A&B\\O&C\end{bmatrix}}=\det(A)\det(C)$ O is the matrix that all it's elements are equal to zero. I know some rules for calculating determinants but I don't know how to begin in this question.	Combinación de matrices	Si A es una matriz $k\times k$, B es una matriz $k\times l$ y C es una matriz $l\times l$ prueba que: $\det{\begin{bmatrix}A&B\\O&C\end{bmatrix}}=\det(A)\det(C)$ O es la matriz que todos sus elementos son iguales a cero.	calculus,determinant
A.68	Prove $a^n+1$ is divisible by $a + 1$ if $n$ is odd	Prove $a^n+1$ is divisible by $a + 1$ if $n$ is odd: We know $a$ cannot be $-1$ and the $n \in \mathbb{N}$. Since $n$ must be odd, we can rewrite $n$ as $2k+1$. Now we assume it holds for prove that it holds for the next term. $$a^{2(k+1)+1}+1$$ $$=a^{2k+3}+1$$ $$=a^3\cdot a^{2k}+1$$ $$=(a^3+1)\cdot a^{2k} -a^{2k}+1$$ Im not sure on what to do next. Since $a^{2k}$ means that the exponential term will be even and thus you cant use the fact that $a^n+1$ is divisible by $a + 1$ if $n$ is odd.	Prueba que $a^n+1$ es divisible por $a + 1$ si $n$ es impar	Pruebe que $a^n+1$ es divisible por $a + 1$ si $n$ es impar: sabemos que $a$ no puede ser $-1$ y el $n \in \mathbb{N}$. Dado que $n$ debe ser impar, podemos reescribir $n$ como $2k+1$. Ahora supongamos que se mantiene para probar que se mantiene para el siguiente término. $$a^{2(k+1) +1} +1$$ $$=a^{2k+3} +1$$=a^3\cdot a^{2k} +1$$=a^3+1)\cdot a^{2k} -a^{2k} +1$$ No estoy seguro de qué hacer a continuación.	polynomials,induction,divisibility
A.69	Induction with two variable parameters	So I was assigned this homework problem: $$\ {s \choose s} + {s+1 \choose s} +...+ {n \choose s} = {n+1 \choose s+1}$$ for all s and all $n \geq s$ I've tried to email both my professor and my TA and their explanations seem contradictory. My professor responded saying the statement I need to prove is "The formula is correct for $0 \leq s \leq n$." Whereas my TA told me I need to use induction on both variables and I'm not sure how to do that. Any help is appreciated!	Inducción con dos parámetros variables	Así que me asignaron este problema de tarea: $$\ {s \choose s} + {s+1 \choose s} +...+ {n \choose s} = {n+1 \choose s+1}$$ para todos s y todos $n \geq s$ He intentado enviar un correo electrónico a mi profesor y mi TA y sus explicaciones parecen contradictorias. Mi profesor respondió diciendo que la declaración que necesito probar es "La fórmula es correcta para $0 \leq s \leq n$. " Mientras que mi TA me dijo que necesito usar la inducción en ambas variables y no estoy seguro de cómo hacer eso. ¡Cualquier ayuda es apreciada!	combinatorics
A.70	Proving $\sum_{j=0}^{N-1}\cos\frac{\left(2j+1\right)\pi}{2N}=0$	Let $l\in\mathbb{Z}$ and $N\in\mathbb{N}$. I need to prove the following: $\begin{equation} \sum_{j=0}^{N-1}\cos\left(l\frac{\left(2j+1\right)\pi}{2N} \right)=0 \end{equation}$ I tried to use Euler formula and then sum the first $N$ terms of the geometric serie I get, but it didn't work. Any ideas?	Prueba de la $\sum_{j=0}^{N-1}\cos\frac{\left(2j+1\right)\pi}{2N}=0$	Vamos a $l\in\mathbb{Z}$ y $N\in\mathbb{N}$. Necesito probar lo siguiente: $\begin{equation} \sum_{j=0}^{N-1}\cos\left(l\frac{\left(2j+1\right)\pi}{2N} \right)=0 \end{equation}$ Intenté usar la fórmula de Euler y luego sumar los primeros términos $N$ de la serie geométrica que obtuve, pero no funcionó. ¿Alguna idea?	trigonometry,summation
A.71	Show, with induction that $1^2 + 2^2 + .... + n^2 = \frac{n(n+1)(2n+1)}{6}$	Show, with induction that $1^2 + 2^2 + .... + n^2 = \frac{n(n+1)(2n+1)}{6}$ My attempt Case 1: n = 1 $LHS = 1^2$  $RHS = \frac{(1+1)(2+1)}{6} = \frac{2*3}{6} = 1$ Case 2: n = p $LHS_{p} = 1^2 + 2^2 + ... + p^2$ $RHS_{p} = \frac{p(p+1)(2p+1)}{6}$ Case 3: n = p + 1 $LHS_{p+1} = 1^2+2^2+....+p^2+(p+1)^2$ $RHS_{p+1} = \frac{(p+1)((p+1)+1)(2(p+1)+1)}{6}$ Now to show this with induction I think i need to show that $RHS_{p+1} = RHS_{p} + (p+1)^2$ $RHS_{p+1} = \frac{p(p+1)(2p+1)}{6} + (p+1)^2$ So I need to rewrite  $RHS_{p+1} = \frac{(p+1)((p+1)+1)(2(p+1)+1)}{6} $to be equal to $\frac{p(p+1)(2p+1)}{6} + (p+1)^2$  Anyone see how I can do that? Or got any other solution?	Muestra, con inducción que $1^2 + 2^2 + .... + n^2 = \frac{n(n+1)(2n+1)}{6}$	Muestre, con inducción que $1^2 + 2^2 + .... + n^2 = \frac{n(n+1)(2n+1)}{6}$ Mi intento caso 1: n = 1 $LHS = 1^2$ $RHS = \frac{(1+1)(2+1)}{6} = \frac{2*3}{6} = 1$ caso 2: n = p $LHS_{p} = 1^2 + 2^2 + ... + p^2$ $RHS_{p} = \frac{p(p+1)(2p+1)}{6}$ caso 3: n = p + 1 $LHS_{p+1} = 1^2+2^2+....+p^2+(p+1)^2$ $RHS_{p+1} = \frac{(p+1)((p+1)+1)(2(p+1)+1)}{6}$ Ahora para mostrar esto con inducción creo que necesito mostrar que $RHS_{p+1} = RHS_{p} + (p+1)^2$ $RHS_{p+1} = \frac{p(p+1)(2p+1)}{6} + (p+1)^2$ Así que necesito reescribir $1^2 + 2^2 + .... + n^2 = \frac{n(n+1)(2n+1)}{6}$0 para ser igual a $1^2 + 2^2 + .... + n^2 = \frac{n(n+1)(2n+1)}{6}$1 ¿Alguien ve cómo puedo hacer eso? O tengo alguna otra solución?	induction
A.72	Is it possible that $\mathcal{X} = \mathcal{Y}$, yet $\mathcal{X} \in \mathcal{Y}$?	Is it possible for a set to equal another set, yet the former set be an element in the latter set?  I.e.: $\mathcal{X} = \mathcal{Y}$, yet $\mathcal{X} \in \mathcal{Y}$	¿Es posible que $\mathcal{X} = \mathcal{Y}$, pero $\mathcal{X} \in \mathcal{Y}$?	¿Es posible que un conjunto sea igual a otro conjunto, pero el conjunto anterior sea un elemento en el último conjunto?	set-theory,axioms
A.73	Help on proof of $\binom{n}{0}^2 + \binom{n}{1}^2 + ... + \binom{n}{n}^2 = \binom{2n}{n}$	The proof is required to be made through the binomial theorem. I will expose the demonstration I was tought, and forward my questions after exposing it. You'll see question marks like this one (?-n) on points I don't quite understand, where $n$ is the numeration of the mark. This are the doubts I have about the demonstration, the which I hope someone can clarify. Prove that $\binom{n}{0}^2 + \binom{n}{1}^2 + ... + \binom{n}{n}^2 = \binom{2n}{n}$. We will use the following equality, and call it $P$:  $(1+x)^n(1+x)^n=(1+x)^{2n}$ (?-1) The result will be proved finding the $x^n$ coefficient of both terms of this equality (?-2). According to the binomial theorem, the left-hand side of this equation is the product of two factors, both equal to $\binom{n}{0}1+\binom{n}{1}x+...+\binom{n}{r}x^r+...+\binom{n}{n}x^n$ When both factors multiply, a term on $x^n$ is obtained when a term of the first factor has some $x^i$ and the term of the second factor has some $x^{n-i}$. Therefor the coefficients of $x^n$ are $\binom{n}{0}\binom{n}{n}+\binom{n}{1}\binom{n}{n-1}+\binom{n}{2}\binom{n}{n-2}+...\binom{n}{n}\binom{n}{0}$ . Since $\binom{n}{n-r}=\binom{n}{r}$, the previous summation is equal to $\binom{n}{0}^2 + \binom{n}{1}^2 + ... + \binom{n}{n}^2$. So the left hand side of the equation we are asked to proove is a coefficient of $x^n$. When we expand the right-hand side of the equation $P$, we find that $\binom{2n}{n}$ is a coefficient of $x^n$. Therefore (?-3) the left-hand side of the equation we were asked to prove is in deed equal to $\binom{2n}{n}$. In conclussion, $\binom{n}{0}^2 + \binom{n}{1}^2 + ... + \binom{n}{n}^2 = \binom{2n}{n}$. This was all the demonstration. My doubt one (?-1) goes about where the heck does this equation come from? How would I know what equation to come up with if requested to prove a different equality? Doubt two (?-2) goes about why would the solution of the first equation would have anything to do with finding the $x^n$ coefficients of the one I just made up (see doubt one). Doubt three (?-3) goes about why demonstrating that $a$ is a coefficient of $x^n$ on the left hand side of the equation I made up, and that $b$ is a coefficient of $x^n$ on the right-hand side of this equation as well, would prove my original equation, the one I was supposed to prove on the first place? I know there are many doubts here, I hope you guys can help me. Sorry for the long post, it's a long demonstration.	Ayuda en la prueba de $\binom{n}{0}^2 + \binom{n}{1}^2 + ... + \binom{n}{n}^2 = \binom{2n}{n}$	La prueba se requiere que se haga a través del teorema binomial. Vamos a exponer la demostración que se me ha enseñado, y presentaré mis preguntas después de exponerlo. Verá marcas de preguntas como esta (?-n) en puntos que no entiendo muy, donde $n$ es la numeración de la marca. Estas son las dudas que tengo sobre la demostración, que espero que alguien pueda aclarar. Pruebe que $\binom{n}{0}^2 + \binom{n}{1}^2 + ... + \binom{n}{n}^2 = \binom{2n}{n}$. Vamos a usar la siguiente igualdad, y lo llamamos $P$: $(1+x)^n(1+x)^n=(1+x)^{2n}$ (?-1) El resultado será encontrar el coeficiente $x^n$ original de ambos términos de esta igualdad (?-2). Según el teorema binomial, el lado izquierdo de esta ecuación es el producto de dos factores, ambos igual a $\binom{n}{0}1+\binom{n}{1}x+...+\binom{n}{r}x^r+...+\binom{n}{n}x^n$ multiplicado, una suma en la mano de la cual se obtiene cuando un factor de la primera mano y el término del factor de la segunda mano de la expuesta ($n$2) se ha hecho una demostración de la expuesta de la ecuación XX. ¿Por qué se puede probar que la expuesta de la expuesta de la ecuación XX? ¿Cuál es la razón por la cual se puede probar que la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de la expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de expuesta de	discrete-mathematics,binomial-coefficients,binomial-theorem
A.74	Show that the image of the function $f:(0,\infty)\rightarrow \mathbb{R}$, $f(x)=x+\dfrac{1}{x}$ is the interval $[2,\infty)$.	Show that the image of the function $f:(0,\infty)\rightarrow \mathbb{R}$, $f(x)=x+\dfrac{1}{x}$ is the interval $[2,\infty)$.  If $x=1$, then $f(1)=2$. So how can I show that the mage of the function is the interval $[2,\infty)$?	Muestre que la imagen de la función $f:(0,\infty)\rightarrow \mathbb{R}$, $f(x)=x+\dfrac{1}{x}$ es el intervalo $[2,\infty)$.	Muestre que la imagen de la función $f:(0,\infty)\rightarrow \mathbb{R}$, $f(x)=x+\dfrac{1}{x}$ es el intervalo $[2,\infty)$. Si $x=1$, entonces $f(1)=2$. Entonces, ¿cómo puedo mostrar que el mago de la función es el intervalo $[2,\infty)$?	functions,elementary-set-theory
A.75	Prove that for each integer $m$, $ \lim_{u\to \infty} \frac{u^m}{e^u} = 0 $	I'm unsure how to show  that for each integer $m$, $ \lim_{u\to \infty} \frac{u^m}{e^u} = 0 $.   Looking at the solutions it starts with $e^u$ $>$ $\frac{u^{m+1}}{(m+1)!}$ but not sure how this is a logical step.	Pruebe que para cada número entero $m$, $ \lim_{u\to \infty} \frac{u^m}{e^u} = 0 $	No estoy seguro de cómo mostrar que para cada número entero $m$, $ \lim_{u\to \infty} \frac{u^m}{e^u} = 0 $. Mirando las soluciones comienza con $e^u$ $>$ $\frac{u^{m+1}}{(m+1)!}$ pero no estoy seguro de cómo este es un paso lógico.	real-analysis,calculus,limits
A.76	Covering $\mathbb{Z}$ by arithmetic progressions	I am solving problems from an old exam (in topology, but I've translated the problem into more algebraic terms). The problem is the following:  Let $a+b\mathbb{Z}=\{z\in \mathbb{Z}\mid z = a+bk \text{ for some  }k\in \mathbb{Z}\}$ where $a\in \mathbb{Z}$ and $b\in  \mathbb{Z}-\{0\}$. Suppose we have a collection of such sets   $\{a_i+b_i\mathbb{Z}\mid i \in \mathbb{N}\}$   satisfying: $$\bigcup_{i \in \mathbb{N}}(a_i+b_i\mathbb{Z})=\mathbb{Z}$$ Show whether it is always possible to extract a finite   $I\subset \mathbb{N}$ s.t. $$\bigcup_{i \in I}(a_i+b_i\mathbb{Z})=\mathbb{Z}$$  Unfortunately, I seem to have forgotten a lot of my elementary algebra... Nevertheless, I have attempted something: Let $\{p_k\}=\{2,3,5,\dots\}$ be the set of primes. We can construct: $$\left(\bigcup_{k\in \mathbb{N}}(0+p_k\mathbb{Z})\right)\cup (-1+\ell_1 \mathbb{Z})\cup (1+\ell_2\mathbb{Z})=\mathbb{Z}$$ for some appropriate non-negative integers $\ell_1,\ell_2$. We could for instance pick $\ell_1=\ell_2=5$. Suppose there is a finite sub-collection $\{0+p_{k_j}\}$, $j=1,\dots,n$ s.t.  $$\left(\bigcup_{1\leq j\leq n}(0+p_{k_j}\mathbb{Z})\right)\cup (-1+5 \mathbb{Z})\cup (1+5\mathbb{Z})$$ Now, assume $p$ is some prime s.t. $p>\max\{p_{k_1},\dots,p_{k_n}\}$, then clearly $p\notin \bigcup_{1\leq j\leq n}(0+p_{k_j}\mathbb{Z})$. But here I run into a problem. I want $p\notin(-1+5 \mathbb{Z})\cup (1+5\mathbb{Z})$. That is, I want $5\nmid p-1$ and $5\nmid p+1$. This is of course possible if $p$ is a prime with a $7$ as its last digit. However, this approach means I have to prove that there are infinitely many primes ending on a $7$, which seems like a silly thing to prove for a simple problem like this. Surely, there is a nicer way of solving this? EDIT: I am particularily interested in a solution not relying on topology, and whether a solution like my attempted solution works.	Cubriendo el $\mathbb{Z}$ por progresos aritméticos	Estoy resolviendo problemas de un viejo examen (en topología, pero he traducido el problema en términos más algebraicos). El problema es el siguiente: Vamos a $a+b\mathbb{Z}=\{z\in \mathbb{Z}\mid z = a+bk \text{ for some  }k\in \mathbb{Z}\}$ donde $a\in \mathbb{Z}$ y $b\in  \mathbb{Z}-\{0\}$. Supongamos que tenemos una colección de tales conjuntos $\{a_i+b_i\mathbb{Z}\mid i \in \mathbb{N}\}$ satisfactoria: $$\bigcup_{i \in \mathbb{N}}(a_i+b_i \mathbb{Z}) =\mathbb{Z}$$ Muestre si siempre es posible extraer un finito $I\subset \mathbb{N}$ s.t. $$\bigcup_{i \in I}(a_i+b_i\mathbb{Z}) =\mathbb{Z}$$ Desafortunadamente, parece que he probado un problema infinito de álgebra elemental j\in \mathbb{N}}... Pero nunca he intentado probar que es posible construir un conjunto de primas como $a+b\mathbb{Z}=\{z\in \mathbb{Z}\mid z = a+bk \text{ for some  }k\in \mathbb{Z}\}$5. Pero, por supuesto, esto podría ser el juego de primas. Podemos tener una solución s\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\	general-topology,elementary-number-theory
A.77	Show that the relation $(- 1) (- 1) = 1$ is a consequence of the distributive law	Show that the relation $(- 1) (- 1) =  1$ is a consequence of the distributive law.  This question is the first problem from 'Number Theory for Beginners" by Andre Weil. I cannot get the point from where to begin. I tried using $1\cdot 1 = 1$ and $ 1\cdot x = x $, but couldn't get somewhere. Can you help me just with a hint? I would be willing to work up from there.	Muestre que la relación $(- 1) (- 1) = 1$ es una consecuencia de la ley distributiva	Muestre que la relación $(- 1) (- 1) =  1$ es una consecuencia de la ley distributiva. Esta pregunta es el primer problema de la "Teoría de números para principiantes" de Andre Weil. No puedo entender el punto de dónde empezar. Traté de usar $1\cdot 1 = 1$ y $ 1\cdot x = x $, pero no pude llegar a algún lugar. ¿Puedes ayudarme con un solo indicio? estaría dispuesto a trabajar desde allí.	elementary-number-theory
A.79	Inequality with complex exponential	Rudin in Real and Complex Analysis uses this in a proof near the beginning of chapter 9:  $\displaystyle \left \vert{ \frac {e^{-ixu}-1}{u}}\right\vert \le \vert x \vert$ for all real $u \ne 0$  Why is this true? Edit: I believe $x$ is real	Desigualdad con exponencial complejo	Rudin en Análisis Real y Complejo utiliza esto en una prueba cerca del comienzo del capítulo 9: $\displaystyle \left \vert{ \frac {e^{-ixu}-1}{u}}\right\vert \le \vert x \vert$ para todo el real $u \ne 0$ ¿Por qué es verdad?	inequality,exponential-function,fourier-transform
A.80	Why does this proof that the set of all finite subsets of N is a countable set not work for the set of all subsets of N?	I found this proof in a StackExchange thread and found it pretty understandable and simple: "The other answers give some sort of formula, like you were trying to do.  But, the simplest way to see that the set of all finite subsets of $\mathbb{N}$ is countable is probably the following. If you can list out the elements of a set, with one coming first, then the next, and so on, then that shows the set is countable.  There is an easy pattern to see here.  Just start out with the least elements. $$\emptyset, \{1\}, \{2\}, \{1, 2\}, \{3\}, \{1, 3\}, \{2, 3\}, \{1, 2, 3\}, \{4\}, \ldots$$ In other words, first comes $\{1\}$, then comes $\{2\}$.  Each time you introduce a new integer, $n$, list all the subsets of $[n] = \{1, 2, \ldots, n\}$ that contain $n$ (the ones that don't contain $n$ have already showed up).  Therefore, all subsets of $[n]$ show up in the first $2^{n}$ elements of this sequence." I understand how it applies for finite subsets of N, but I cant really pinpoint of why it would not apply to a set of all subsets of N. We could continue this scheme for ever, couldnt we?  I assume that I think in a wrong way about infinity but I am not quite sure. Any help is greatly appreciated!	¿Por qué esta prueba de que el conjunto de todos los subconjuntos finitos de N es un conjunto contable no funciona para el conjunto de todos los subconjuntos de N?	Encontré esta prueba en un hilo de StackExchange y la encontré bastante comprensible y simple: "Las otras respuestas dan algún tipo de fórmula, como lo que estabas tratando de hacer. Pero, la forma más simple de ver que el conjunto de todos los subconjuntos finitos de $\mathbb{N}$ es contable es probablemente la siguiente. Si puedes enumerar los elementos de un conjunto, con uno que viene primero, luego el siguiente, y así sucesivamente, entonces eso muestra que el conjunto es contable. Hay un patrón fácil de ver aquí. Sólo comience con el mínimo. $$\emptyset, \{1\}, \{1, 2\}, \{3\}, \{1, 3\}, \{2, 3\}, \{2, 3\}, \{4\}, \{2} En otras palabras, $\{1\}$ puede contener un conjunto de elementos finitos. ¡No puedo entender cómo cualquier secuencia de números puede contener un número de los subconjuntos, pero creo que podemos seguir con un sistema de subconjuntos finitos, pero no podemos mostrarlo de una manera muy buena, pero no podemos entender que todos los subconjuntos finitos de $n$ se establecen en el sistema $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ $n$ XXXXXXX$n$	analysis,elementary-set-theory,proof-explanation
A.81	Any infinite set contains a countable subset. Why is my proof wrong? (Axiom of Choice)	Let $M$ be an infinite set.    Proposition 1:   For any $n \in \mathbb{N}$, there exists an injection from $\{1, \cdots, n\}$ to $M$.      (1) Since $M \neq \emptyset$, there exists $x \in M$. Define $f(1)$ as $f(1) := x$. $f$ is an injection from $\{1\}$ to $M$. (2) Suppose that there exists an injection $f$ from $\{1, \cdots, n\}$ to $M$. Since $M$ is an infinite set, $M - \{f(1), \cdots, f(n)\}$ is not an empty set. So, there exists $x \in M - \{f(1), \cdots, f(n)\}$. Define $g(1), \cdots, g(n+1)$ as $g(1) := f(1), \cdots, g(n):=f(n)$ and $g(n+1) := x$. Obviously, $g$ is an injection from $\{1, \cdots, n+1\}$ to $M$.   Let $n_1$ be an arbitrary natural number. If I wanna calculate $h(n_1)$, then I get an injection $g$ from $\{1, \cdots, n_1\}$ to $M$ by Proposition 1. And I return $g(n_1)$ as the value of $h(n_1)$. And I store the pairs $(1, g(1)), \cdots, (n_1, g(n_1))$ to my database.   If I wanna calculate $h(n_2)$ for $n_2 \leq n_1$, then I search my database and I get the value $g(n_2)$ from my database and I return $g(n_2)$ as the value of $h(n_2)$. If I wanna calculate $h(n_3)$ for $n_3 > n_1$, then I add the pairs $(n_1 + 1, g(n_1+1)), \cdots, (n_3, g(n_3))$ to my database by Proposition 1 and I return $g(n_3)$ as the value of $h(n_3)$.   I can calculate $h(n)$ for any $n \in \mathbb{N}$.   From above, we get an injection $h : \mathbb{N} \to M$.   Why is my proof wrong? By the way. Suppose that a man wanna know if I have an injection $h : \mathbb{N} \to M$ or not. Then how can the man know if I have  an injection $h : \mathbb{N} \to M$ or not?	Cualquier conjunto infinito contiene un subconjunto contable. ¿Por qué mi prueba está equivocada?	Si $M$ es un conjunto infinito, $M$0 no es un conjunto vacío. Así que, existe $M$1. Definir $M$2 como $M$3 y $M$4. Obviamente, $M$5 es una inyección de $M$6 a $M$. Dejemos que $M$7 sea un número natural arbitrario. Si quiero calcular $M$8, entonces obtengo una inyección $M$5 de $M$9 a $M$ por Proposición 1. Y devuelvo $n \in \mathbb{N}$0 como el valor de $M$8. Y guardo los pares $n \in \mathbb{N}$1 en mi base de datos.	elementary-set-theory,axiom-of-choice
A.82	All definite integrals evaluate to 0 using periodic functions.	I know that my reasoning is incorrect, I just don't know where I went wrong. I did discuss this with my Maths teacher, and even she could not find what I did wrong. Let us begin by assuming a function, $f(x)$ that is continuous and has an antiderivative in the interval $[0, 2\pi]$. Let $A$ be the area under the curve for $f(x)$ in the interval $[0, 2\pi]$ $A = \displaystyle \int_{0}^{2\pi}{f(x)\space\mathrm{d}x}$ Now there must exist a function, $g(x)$ such that:   $f(x) = g(x)\cdot \cos(x)$ Substituting the value of $f(x)$: $A = \displaystyle\int_{0}^{2\pi}{g(x)\cdot \cos(x)\space\mathrm{d}x}$ Using t substitution: Let $t = \sin(x)$ Then: $\mathrm{d}t = \cos(x)\space\mathrm{d}x$ And:  $x = \arcsin(t)$ Changing the limits: $t = \sin(x)$ $0$ becomes $\sin(0) = 0$ $2\pi$ becomes $\sin(2\pi) = 0$ Substituting in the definite integral: $A = \displaystyle \int_{0}^{0}{g(\arcsin(t))\space\mathrm{d}t}$ But Definite Integral where the lower and upper bounds are the same is $0$. So: $A = 0$, which is not possible. Thanks for the help.	Todos los integrals definidos se evalúan a 0 utilizando funciones periódicas.	Sé que mi razonamiento es incorrecto, sólo no sé dónde me equivoqué. Yo hablé de esto con mi profesora de matemáticas, y incluso ella no pudo encontrar lo que hice mal. Comencemos asumiendo una función, $f(x)$ que es continua y tiene un antiderivado en el intervalo $[0, 2\pi]$. Que $A$ sea el área debajo de la curva de $f(x)$ en el intervalo $[0, 2\pi]$ $A = \displaystyle \int_{0}^{2\pi}{f(x)\space\mathrm{d}x}$ Ahora debe existir una función, $g(x)$ tal que: $f(x) = g(x)\cdot \cos(x)$ Substituir el valor de $f(x)$: $A = \displaystyle\int_{0}^{2\pi}{g(x)\cdot \cos(x)\space\mathrm{d}x}$ Usando la sustitución t: Que $t = \sin(x)$ Entonces: $\mathrm{d}t = \cos(x)\space\mathrm{d}x$ Y: $f(x)$0 Cambiar los límites: $t = \sin(x)$ $f(x)$1 $f(x)$2 $f(x)$3 $f(x)$4 Se convierte en sustitución en la integral definida: $f(x)$5 Pero Definida Integral donde los límites inferior y superior son los mismos es $f(x)$1. Así que: $f(x)$6, que no es posible. Gracias por la ayuda.	calculus,integration,trigonometry,definite-integrals,inverse-function
A.83	Is the sequence of sums of inverse of natural numbers bounded?	I'm reading through Spivak Ch.22 (Infinite Sequences) right now. He mentioned in the written portion that it's often not a trivial matter to determine the boundedness of sequences. With that in mind, he gave us a sequence to chew on before we learn more about boundedness. That sequence is: $$1, 1+\frac{1}{2}, 1+\frac{1}{2}+\frac{1}{3}, 1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}, . . .$$ I know that a sequence is bounded above if there is a number $M$ such that $a_n\leq M$ for all $n$. Any hints here?	¿Es la secuencia de sumas invertidas de números naturales limitada?	Estoy leyendo en Spivak Ch.22 (Sequencias Infinitas) ahora mismo. Mencionó en la parte escrita que a menudo no es una cuestión trivial determinar la limitación de las secuencias. Con eso en mente, nos dio una secuencia para masticar antes de aprender más sobre la limitación. Esa secuencia es: $$1, 1+\frac{1}{2}, 1+\frac{1}{2}+\frac{1}{3}, 1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}, . . .$$ Sé que una secuencia está limitada arriba si hay un número $M$ tal que para todos los $n$. ¿Alguna pista aquí?	calculus,sequences-and-series,harmonic-numbers
A.84	Is the ideal generated by ${4,x}$ a principal ideal in $Z[x]$?	I've : $I=<p,x>$ is not a principal ideal in $Z[x]$ where p is prime. My question :   Is $I=<p,x>$ a principal ideal in $Z[x]$ where p is not a prime? More particularly, is the ideal generated by ${4,x}$ a principal ideal in $Z[x]$ ?	¿El ideal generado por ${4,x}$ es un ideal principal en $Z[x]$?	Tengo: $I=<p,x>$ no es un ideal principal en $Z[x]$ donde p es primario. Mi pregunta: ¿Es $I=<p,x>$ un ideal principal en $Z[x]$ donde p no es un ideal primario?	abstract-algebra,ring-theory,ideals,principal-ideal-domains
A.85	Expected number of steps for a bug to reach position $N$	A bug starts at time $0$ at position $0$. At each step, the bug either moves to the right by $1$ step $(+1)$ with probability $1/2$, or returns to the origin with probability $1/2$. What is the expected number of steps for this bug to reach position $N$? I tried to first find the possibility that this bug reaches $N$ as the number of steps goes to infinity. The recurrence equation I find is $$p_n = \frac{1}{2}p_{n-1}$$, where $p_n$ is the possibility for the bug starting at position $n$ to reach $N$. We also have the boundary condition $p_N = 1$. Then we see that $p_{N-1}=2$, and that $p_0 = 2^N$, which doesn't make sense at all because it is greater than $1$. I think I should sort out the value of probability first, and think about the number of expected steps later. I'm sure there is something wrong with the recurrence equation, but what's wrong about it?	Número de pasos esperados para que un error alcance la posición $N$	Un error comienza en el momento $0$ en la posición $0$. En cada paso, el error se mueve a la derecha por el paso $1$ $(+1)$ con probabilidad $1/2$, o regresa al origen con probabilidad $1/2$. ¿Cuál es el número esperado de pasos para que este error alcance la posición $N$? Traté de encontrar primero la posibilidad de que este error alcance $N$ ya que el número de pasos va a infinito. La ecuación de recurrencia que encuentro es $$p_n = \frac{1}{2}p_{n-1}$$, donde $p_n$ es la posibilidad de que el error que comienza en la posición $n$ alcance $N$. También tenemos la condición límite $p_N = 1$. Entonces vemos que $0$0, y que $0$1, que no tiene sentido en absoluto porque es mayor que $1$. Creo que primero debería pensar en el valor de la probabilidad, y qué número de pasos más tarde. Estoy seguro de que con la ecuación de recurrencia hay algo que se debe esperar, pero ¿qué es lo que se trata de la ecuación?	markov-chains,random-walk
A.86	Is it true that $\sum_{k=0}^{n}k\cdot \left(\begin{array}{l}{n}\\{k}\end{array}\right)=O\left(2 ^ {n\log _{3}n}\right)?$	Problem: Is it true that $\sum_{k=0}^{n}k\cdot \left(\begin{array}{l}{n}\\{k}\end{array}\right)=O\left( 2 ^ {n\log _{3}n}\right)?$ My start of solution: $$\sum_{k=0}^{n}k\cdot \left(\begin{array}{l}{n}\\{k}\end{array}\right)\leq \sum_{k=0}^{n}k\cdot \left(\begin{array}{l}{n}\\{\lfloor \frac{n}{2}\rfloor}\end{array}\right)\leq \frac{n\cdot(n+1)}{2}\cdot \left(\begin{array}{l}{n}\\{\lfloor \frac{n}{2}\rfloor}\end{array}\right)\leq n(n+1)! \leq nn^n \leq n^{n+1}$$ I think this upper bound is way too large and I can't seem to find a solution.	¿Es cierto que $\sum_{k=0}^{n}k\cdot \left(\begin{array}{l}{n}\\{k}\end{array}\right)=O\left(2 ^ {n\log _{3}n}\right)?$	Problema: ¿Es cierto que $\sum_{k=0}^{n}k\cdot \left(\begin{array}{l}{n}\\{k}\end{array}\right)=O\left( 2 ^ {n\log _{3}n}\right)?$ Mi comienzo de solución: $$\sum_{k=0}^{n}k\cdot \left\\begin{array}{l}{n}\\{k}\end{array}\right)\leq \sum_{k=0}^{n}k\cdot \left\\begin{array}{l}{n}\\{n}{\lfloor \frac}{2}\rfloor}\end{rfloor}\end{rarray}\n}\n\n\c\n+1)}{2}\cdot \left\dot \left\begin{ray}{l}{n}{l}{l}{l}{l}{l}\l}{l}{l}{l}{l}\l}{l}{l}{l}{l}{l}{l}\l}{l}{l}{n}}{n}}{n}{n}{n}{n}\l}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}\n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}\n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}	combinatorics,elementary-number-theory,discrete-mathematics
A.87	Is it true that $\forall n \in \Bbb{N} : (\sum_{i=1}^{n} a_{i} ) (\sum_{i=1}^{n} \frac{1}{a_{i}} ) \ge n^2$ , if all $a_{i}$ are positive?	If  $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$ , is it true that $\forall n \in \Bbb{N} : \big(\sum_{i=1}^{n}a_{i}\big) \big(\sum_{i=1}^{n}  \frac{1}{a_{i}}\big) \ge n^2$ ?  I have been able to prove that this holds for $n=1$ , $n=2$, and $n=3$ using the following lemma:  Lemma 1:  Let $a,b \in \Bbb{R}^+$. If $ab =1$ then $a+b \ge 2$  For example, the case for $n=3$ can be proven like this: Let $a,b,c \in \Bbb{R}^+$. Then we have: $(a+b+c)\big(\frac{1}{a} + \frac{1}{b} + \frac{1}{c}\big) = 1 + \frac{a}{b} + \frac{a}{c} + \frac{b}{a} + 1 + \frac{b}{c} + \frac{c}{a} + \frac{c}{b}  + 1 $ $= 3 + \big(\frac{a}{b}  + \frac{b}{a}\big) + \big(\frac{a}{c} + \frac{c}{a}\big) + \big(\frac{b}{c} + \frac{c}{b}\big) $ By lemma 1, $\big(\frac{a}{b}  + \frac{b}{a}\big) \ge 2$,  $ \big(\frac{a}{c} + \frac{c}{a}\big) \ge 2$ and  $\big(\frac{b}{c} + \frac{c}{b}\big) \ge 2$ , therefore: $3 + \big(\frac{a}{b}  + \frac{b}{a}\big) + \big(\frac{a}{c} + \frac{c}{a}\big) + \big(\frac{b}{c} + \frac{c}{b}\big) \ge 3 + 2 + 2 +2 = 9 = 3^2 \ \blacksquare $ However I'm not sure the generalized version for all natural $n$ is true. I can't come up with a counterexample and when I try to prove it by induction I get stuck. Here is my attempt: Let $P(n)::\big(\sum_{i=1}^{n}a_{i}\big) \big(\sum_{i=1}^{n} \frac{1}{a_{i}}\big) \ge n^2$ Base case: $\big(\sum_{i=1}^{1}a_{i}\big) \big(\sum_{i=1}^{1} \frac{1}{a_{i}}\big) = a_{1} \frac{1}{a_{1}} = 1 = 1^2$ , so $P(1)$ is true. Inductive hypothesis:  I assume $P(n)$ is true. Inductive step: $$\left(\sum_{i=1}^{n+1}a_{i}\right) \left(\sum_{i=1}^{n+1} \frac{1}{a_{i}}\right) = \left[\left(\sum_{i=1}^{n}a_{i}\right) + a_{n+1}\right] \left[\left(\sum_{i=1}^{n} \frac{1}{a_{i}}\right) + \frac{1}{a_{n+1}}\right]$$ $$=\left(\sum_{i=1}^{n}a_{i}\right) \left[\left(\sum_{i=1}^{n} \frac{1}{a_{i}}\right) + \frac{1}{a_{n+1}}\right] + a_{n+1} \left[\left(\sum_{i=1}^{n} \frac{1}{a_{i}}\right) + \frac{1}{a_{n+1}}\right]$$ $$=\left(\sum_{i=1}^{n}a_{i}\right)\left(\sum_{i=1}^{n} \frac{1}{a_{i}}\right) +\left(\sum_{i=1}^{n}a_{i}\right) \frac{1}{a_{n+1}} + a_{n+1} \left(\sum_{i=1}^{n} \frac{1}{a_{i}}\right) +a_{n+1} \frac{1}{a_{n+1}}$$ $$=\left(\sum_{i=1}^{n}a_{i}\right)\left(\sum_{i=1}^{n} \frac{1}{a_{i}}\right) +\left(\sum_{i=1}^{n}a_{i}\right) \frac{1}{a_{n+1}} + a_{n+1} \left(\sum_{i=1}^{n} \frac{1}{a_{i}}\right) +1 $$ $$\underbrace{\ge}_{IH} n^2 + \left(\sum_{i=1}^{n}a_{i}\right) \frac{1}{a_{n+1}} + a_{n+1} \left(\sum_{i=1}^{n} \frac{1}{a_{i}}\right) + 1$$ And here I don't know what to do with the $\big( \sum_{i=1}^{n}a_{i} \big) \frac{1}{a_{n+1}} + a_{n+1} \big(\sum_{i=1}^{n} \frac{1}{a_{i}}\big)$ term. Is this inequality true? If it is, how can I prove it? If it isn't, can anyone show me a counterexample?	¿Es cierto que $\forall n \in \Bbb{N} : (\sum_{i=1}^{n} a_{i} ) (\sum_{i=1}^{n} \frac{1}{a_{i}} ) \ge n^2$ , si todos los $a_{i}$ son positivos?	Si $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$ , es cierto que $\forall n \in \Bbb{N} : \big(\sum_{i=1}^{n}a_{i}\big) \big(\sum_{i=1}^{n}  \frac{1}{a_{i}}\big) \ge n^2$ ? He sido capaz de probar que esto es válido para $n=1$ , $n=2$ y $n=3$ usando el siguiente lema: Lemma 1: Vamos $a,b \in \Bbb{R}^+$. Si $ab =1$ entonces $a+b \ge 2$ Por ejemplo, el caso de $n=3$ puede ser probado de esta manera: Vamos $a,b,c \in \Bbb{R}^+$. Entonces tenemos: $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$0 $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$1 Por lemma 1, $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$2, $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$3 y $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$4 , por lo tanto: $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$5 Sin embargo, no estoy seguro de que la versión generalizada para todo el $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$6 natural es verdad. No puedo llegar a un contraejemplo y cuando lo hago por inducción obtengo probarlo. Aquí es mi intento: {{{{{{{}} $ab =1$ entonces $a+b \ge 2$} Así que podemos probar que el caso de $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$ es verdad. {{{} $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$0 $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$1 Por lemma 1, $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$2, $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$3 y $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$4 , por lo tanto: $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$5 Sin embargo, no estoy seguro de que la versión generalizada para todo el $\forall i \in \Bbb{N}: a_{i} \in \Bbb{R}^+$6 natural es verdad. {{} Si puedo llegar a un contraejemplo y si lo hago por inducción {{} {{} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {}} {} {} {} {} {} {} {} {} {} {}} {} {} {} {} {} {} {}} {}} {} {} {}} {} {} {}} {} {} {}}} {} {} {} {} {} {}} {} {} {} {}} {} {} {}} {} {} {}} {} {} {}}} {} {} {}} {} {}} {}} {} {}}} {} {} {} {}} {} {}} {}} {} {} {}} {} {} {}} {} {} {}}}} {} {} {}} {} {} {}}}} {}}} {} {} {} {}} {} {}}} {} {} {} {} {}}}} {} {}}} {} {}} {}} {} {} {} {}}} {}} {}}} {} {}} {} {} {}}} {} {}}} {} {} {}}} {} {}}} {} {}}} {} {} {} {}}}}} {} {} {} {} {} {}}}}} {} {} {} {} {}}}} {} {} {} {}} {}}}} {} {} {} {} {} {}}} {}}} {} {} {} {}}}} {}} {} {} {}}} {} {} {} {} {} {} {} {}}}}}}} {} {} {} {} {} {}} {}}}}} {}}} {} {} {} {}} {}} {} {} {}}} {} {} {}}}}} {} {} {} {} {}}}} {} {} {}}} {} {}}}} {} {} {}} {} {} {}}} {} {} {}}} {}} {} {}} {} {} {}} {}} {}}}} {} {}}} {} {} {}} {} {} {}}}}}} {} {} {} {} {}}} {} {} {}}}} {}}}} {} {} {}} {} {}}}}} {} {} {}}}}} {}}}}} {} {}} {}	algebra-precalculus,inequality
A.88	Is the polynomial $x^4+10x^2+1$ reducible over $\mathbb{Z}[x]$?	Is the polynomial  $x^4+10x^2+1$  reducible over  $\mathbb{Z}[x]$?	¿Es el polinomio $x^4+10x^2+1$ reducible por $\mathbb{Z}[x]$?	¿Es el polinomio $x^4+10x^2+1$ reducible por $\mathbb{Z}[x]$?	abstract-algebra,ring-theory,field-theory,irreducible-polynomials
A.89	Parametrization of pythagorean-like equation	Is there any known complete parametrization of the Diophantine equation $$ A^{2} + B^{2} = C^{2} + D^{2} $$ where $A, B, C, D$ are (positive) rational numbers, or equivalently, integers?	Parametrización de la ecuación similar a la de Pitágoras	¿Hay alguna parametrización completa conocida de la ecuación Diofantina $$ A^{2} + B^{2} = C^{2} + D^{2} $$ donde $A, B, C, D$ son números racionales (positivos) o equivalentemente, enteros?	number-theory,diophantine-equations
A.90	Question on the definition of an Inverse matrix	By definition, if $A$ is a $ n \times n $ matrix, an inverse of $A$ is an $ n \times n $ matrix $A^{-1}$ with the property that: $$ A^{-1}A=\mathbb I_n \ \ \land \ \ AA^{-1}=\mathbb I_n \ \ \ \ (1)$$  where $ \mathbb I_n $ is the $ n \times n $ identity matrix. Are there any cases where $ A^{-1}A=\mathbb I_n$ but $AA^{-1} \neq \mathbb I_n$ or the other way around (and thus making (1) a false statement) ?	Pregunta sobre la definición de una matriz inversa	Por definición, si $A$ es una matriz $ n \times n $, una inversa de $A$ es una matriz $A^{-1}$ de $ n \times n $ con la propiedad de que: $$ A^{-1}A=\mathbb I_n \ \ \ \ \ \ land \ \ \ AA^{-1}=\mathbb I_n \ \ \ \ \ \ (1) $$ donde $ \mathbb I_n $ es la matriz de identidad $ n \times n $. ¿Hay casos en los que $ A^{-1}A=\mathbb I_n$ pero $AA^{-1} \neq \mathbb I_n$ o viceversa (y por lo tanto haciendo (1) una declaración falsa) ?	linear-algebra,matrices
A.91	Continuous function that reaches each value on its range exactly 2 times.	Is there a continuous function from $\mathbb{R}\to\mathbb{R}$ that reaches all of its possible values (each value in it's range) exactly $2$ times (for example, $x^2$ would be perfect if it wasn't for $0$..). Also, the same question but $3$ times. I'm almost certain that there aren't such functions but who knows haha maybe there are a bunch...	Función continua que alcanza cada valor en su rango exactamente 2 veces.	¿Hay una función continua de $\mathbb{R}\to\mathbb{R}$ que alcanza todos sus valores posibles (cada valor en su rango) exactamente $2$ veces (por ejemplo, $x^2$ sería perfecto si no fuera para $0$..). También, la misma pregunta pero $3$ veces. Estoy casi seguro de que no hay tales funciones pero quién sabe haha tal vez hay un montón...	real-analysis,calculus
A.92	Is there a principal maximal ideal in $\mathbb F_q[X,Y]$?	Given an infinite field $K$, one can prove that any maximal ideal of $K[X,Y]$ can't be principal. In fact, every non-principal prime ideal is a maximal ideal, and can be generated by two polynomials. I am wondering whether the same result holds in $\mathbb F_q[X,Y]$. Can we find a principal ideal $I = (P(X,Y))$ for some irreducible polynomial $P$ that is a maximal ideal ?    Such a polynomial $P$ must have positive degrees in both $X$ and $Y$. Indeed, given an irreducible polynomial $Q(X)$ in only one variable, the quotient  $$\mathbb F_q[X,Y]/(Q(X))\cong (\mathbb F_q[X]/(Q(X)))[Y]$$ is a ring of polynomials over a field and as such, can never be a field.   Moreover, such a polynomial $P$ must have the form  $$P(X,Y) = \sum_{i=0}^n P_i(X)Y^i$$ where $d\geq 1$, the $P_i$'s are polynomials in $X$ and $P_n$ is a nonzero polynomial that vanishes identically on $\mathbb F_q$, thus $P_n$ must be divisible by $\prod_{\alpha \in \mathbb F_q} (X-\alpha)$. Indeed, if there were some $\alpha \in \mathbb F_q$ such that $P_n(\alpha) \not = 0$, then the ideal $I:=(P,X-\alpha)$ would contain $(P)$ strictly. If $(P)$ were to be maximal, $I$ would be the whole of $\mathbb F_q[X,Y]$. Writing down the fact that $1\in I$ and evaluating $X=\alpha$ would leads us to the conclusion $n=\deg_Y(P)=0$, which is absurd.   This is all I could infer so far. With respect to the above, I tried looking at $P(X,Y) = (X^{p-1}-1)XY - 1$ or $P(X,Y) = (X^{p-1}-1)XY - X - 1$ in $\mathbb F_p[X,Y]$ for some prime number $p$ but I have trouble determining whether the quotient is a field or not.   Would somebody know the answer of the problem, and according to it, give a proof or a counter-example ? Thank you very much in advance.	¿Hay un ideal máximo principal en $\mathbb F_q[X,Y]$?	Dado un campo infinito $K$, se puede demostrar que cualquier ideal máximo de $K[X,Y]$ no puede ser principal. De hecho, dado un polinomio primario irreducible $Q(X)$ en una sola variable, el cuotivo $$\mathbb F_q[X,Y]/QX)) \mathbb F_q[X] (\mathbb F_q[X]) /QiX (\mathbb) (\mathbb F_q[X]) (\mathbb) /QiX (\mathbb) (\mathbb) /QiX (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathbb) (\mathb) (\mathbb) (\mathb) (\mathb) (\mathbb) (\mathb) (\mathb) (\mathb) (\mathb) (\mathb) (\mathb) (\mathb) (\mathb) (\mathb) (\mathb) (\mathb) (\mathb) (\mathb) (\mathb) (\\mathb) (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\	polynomials,commutative-algebra,field-theory,finite-fields
A.93	Characteristic Polynomial $AB =$ characteristic polynomial $ BA$?	Let $A,B$ matrix on $\mathbb{R}$ size $nxn$. How can I prove that $det(xI - AB) = det(xI - BA)$ if $A$ and $B$ are singular matrix	Polinomio característico $AB =$ polinomio característico $ BA$?	Dejemos que la matriz $A,B$ en el tamaño $\mathbb{R}$ $nxn$. ¿Cómo puedo probar que $det(xI - AB) = det(xI - BA)$ si $A$ y $B$ son matriz singular	linear-algebra,polynomials
A.94	Are there $2^{\aleph_{0} }$ sets of natural numbers such that each two have finite intersection	Question: Are there $2^{\aleph_{0} }$ sets of natural numbers such that each two have finite intersection. From what I've read about infinite families, I need to ignore those who have the properpty $P$. Property $P$: the family is threadless, but whenever we take finitely many sets from the family, those sets have infinite intersection. and probably find ones with property $T$. Property $T$: the family is threadless, and it is an “almost-tower”: Whenever you pick two sets in the family, one of them is almost-contained in the other. - probably meaning that we can find such an intersection which is finite, because members are contained in each other. Then I thought.. To find them, I should think of rational numbers instead of natural numbers, remembering that rational numbers can be paired up with natural ones, so solving this problem for families of rational numbers is the same as solving it for families of natural numbers. Now, I need to consider various ways of defining the real numbers. And I'm stuck.. any help is appreciated.	¿Hay $2^{\aleph_{0} }$ conjuntos de números naturales tales que cada dos tienen una intersección finita?	Pregunta: ¿Hay $2^{\aleph_{0} }$ conjuntos de números naturales tales que cada uno de los dos tenga una intersección finita? De lo que he leído sobre familias infinitas, necesito ignorar a aquellos que tienen el propio $P$. Propiedad $P$: la familia es sin hilos, pero cada vez que tomamos infinitos conjuntos de la familia, esos conjuntos tienen una intersección infinita. y probablemente encontrar aquellos con la propiedad $T$. Propiedad $T$: la familia es sin hilos, y es una  casi-torre: Cada vez que elijas dos conjuntos en la familia, uno de ellos está casi contenido en el otro. - probablemente lo que significa que podemos encontrar una intersección que es finita, porque los miembros están contenidos en el otro. Entonces pensé.. para encontrarlos, debería pensar en números racionales en lugar de números naturales, recordando que los números racionales pueden ser combinados con números naturales, así que resolver este problema de las mismas familias, es casi contenido en el otro.	cardinals,rational-numbers,natural-numbers
A.95	Length of convex paths and bounding $\sin x$	The problem:  Defining $\sin x$ as the leg $b$ of a right triangle with $\angle B=x$ (in radians) and hypotenuse $1$, prove that $$\lim_{x\to 0}\frac{\sin x}x=1$$  (The motivation is to find the derivative of $\sin x$ in a elementary, "pre-Taylor" and "pre-series" context). I have seen many times a proof that it is based in the fact that the length of the arc $x$ satisfies $$\sin x<x<\tan x$$ or sometimes $$\sin x<x<\sin x+1-\cos x$$ The lower bound is clear because the $\sin x$ is the length of a straight segment and $x$ is the length of a curved segment with the same endpoints. But I find that the upper bound is based on this intuitive fact:  If $F$ and $G$ are two convex subsets of $\Bbb R^2$ and   $F\subset G$, then $|\partial F|<|\partial G|$.  ($|\partial F|$ is the length of the boundary of $F$). But I haven't ever seen a proof of that. I tried it myself but I get stuck trying to bound $$\int_s^t\sqrt{1+y'(u)^2}du$$ provided for example that $y''$ is negative and $y(s)=y(t)$. I realize that $y'$ can't be bounded (note for example $y=\sqrt{1-x^2}$, $-1\le x\le 1$). Question Is it possible to justify the derivative of $\sin x$ or the inequality about the lengths of bounds? Is there any calculus text with this approach (or similar) to define trigonometical functions?	Duración de las vías convexas y del límite $\sin x$	El problema: Definir $\sin x$ como la pierna $b$ de un triángulo rectángulo con $\angle B=x$ (en radianos) y hipotenusa $1$, probar que $$\lim_{x\to 0}\frac{\sin x}x=1$$ (La motivación es encontrar la derivada de $\sin x$ en un contexto elemental, "pre-Taylor" y "pre-serie"). He visto muchas veces una prueba de que se basa en el hecho de que la longitud del arco $x$ satisface $$\sin x<x<\tan x5 o a veces $$\sin x<x<\sin x+1-\cos x5 La línea inferior es clara porque la $\sin x$ es la longitud de un segmento recto y $x$ es la longitud de un segmento derivado con los mismos puntos finales. Pero encuentro que la aproximación se basa en este hecho: ¿No puedo probar que el límite de la curva $\sin x$5 y la línea de los límites de la línea de la línea de los puntos de arriba es igual a la línea de la línea de arriba? Pero si alguna vez he intentado definir la longitud de la línea de arriba de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de arriba de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de	real-analysis,derivatives,trigonometry,reference-request,arc-length
A.96	Let $\sum_i a_i$ be a convergent sum with positive $a_i$. Does $\sum_i \frac{a_i}{a_i+a_{i+1}+a_{i+2}+\cdots}$ always diverge?	Let $\sum_i a_i$ be a convergent sum, with all $a_i$ positive.  Let $s_n=\sum_{i=n}^{\infty}a_i$.   Does $\sum_i  \frac{a_i}{s_i}$ always diverge?  I've tried a few examples such as $a_i= r^i$ (geometric series) and $a_i=1/i^2$ and it seems to always diverge.	Que $\sum_i a_i$ sea una suma convergente con el positivo $a_i$. ¿$\sum_i \frac{a_i}{a_i+a_{i+1}+a_{i+2}+\cdots}$ siempre diverge?	Que $\sum_i a_i$ sea una suma convergente, con todos los $a_i$ positivos. Que $s_n=\sum_{i=n}^{\infty}a_i$. ¿$\sum_i  \frac{a_i}{s_i}$ siempre diverge? He intentado algunos ejemplos como $a_i= r^i$ (serie geométrica) y $a_i=1/i^2$ y parece que siempre diverge.	sequences-and-series,analysis
A.97	what is the dimension of $\mathbb{R}$ at a vector space over there field $\mathbb{Q}$?	If we look at $\mathbb{C}$ as a vector space over $\mathbb{R}$ it's dimension will be $2$, because $\mathbb{C} = span\{1,i\}$.  A question I thought of is what would be the dimension of $\mathbb{R}$ as a vector space over $\mathbb{Q}$?  I feel like the answer should be infinity, because if the dimension was finite, say $n$, then for every $m := n+1$ real numbers  $x_1,...x_m$ there was a linear combination with rational coefficients that gives $0$: $\frac{a_1}{b_1}x_1+...+\frac{a_m}{b_m}x_m = 0$. Multiplying by $lcm(b_1,...,b_m)$ we get that for every $m$ real numbers there is a linear combination with natural coefficients that gives $0$. That feels false, how do you prove it?	¿Cuál es la dimensión de $\mathbb{R}$ en un espacio vectorial allá en el campo $\mathbb{Q}$?	Si vemos a $\mathbb{C}$ como un espacio vectorial sobre $\mathbb{R}$ su dimensión será $2$, porque $\mathbb{C} = span\{1,i\}$. Una pregunta que pensé es cuál sería la dimensión de $\mathbb{R}$ como un espacio vectorial sobre $\mathbb{Q}$? Creo que la respuesta debería ser infinita, porque si la dimensión era finita, digamos $n$, entonces para cada $m := n+1$ números reales $x_1,...x_m$ había una combinación lineal con coeficientes racionales que da $0$: $\mathbb{C}$0. Multiplicando por $\mathbb{C}$1 obtenemos que para cada $\mathbb{C}$2 números reales hay una combinación lineal con coeficientes naturales que da $0$. Eso se siente falso, ¿cómo lo probas?	linear-algebra,vector-spaces
A.98	If $R:S^{1}\rightarrow S^{1}$ is a irrational rotation, $\{R^{n}([x])\}$ is dense in $S^{1}$ for all points.	Let $\alpha$ a irrational number, and $R:S^{1}\rightarrow S^{1}$ the irrational rotation, i.e., $[x]\rightarrow[x+\alpha]$. I need to prove that, for all $[x]\in S^{1}$, the set $\{R^{n}([x])\}$ is dense in $S^{1}$. First, I can write $R$ by $$R(e^{2\pi ix})=e^{2\pi i (x+\alpha)}.$$ So, I can write $R^{n}(x)$, $n\in\mathbb{Z}$ by $$R^{n}(e^{2\pi i x})=e^{2\pi i(x+n\alpha)} $$ I need to prove that, for all $e^{2\pi i x}\in S^{1}$ and for all $[y]=e^{2\pi i y}\in S^{1}$, every neighborhood $V$ of $[y]$ contains a point $[z_{y}]=e^{2\pi i z}$ such that $[z_y]=R^{n}([x])$ for some $n\in\mathbb{Z}$. That is, $e^{2\pi i z}=e^{2\pi i (x+\alpha n)}\Rightarrow 2\pi iz=2\pi i(x+\alpha n)+2ik\pi\;\textrm{for some}\;k\in\mathbb{Z}\Rightarrow z=x+\alpha n+k.$ Is my way correct? If it does, how can I proceed now? If it doesn't, what I need to do? I don't think this question is duplicate. I'm showing my attempt to proof, that is different from other proofs.	Si $R:S^{1}\rightarrow S^{1}$ es una rotación irracional, $\{R^{n}([x])\}$ es denso en $S^{1}$ para todos los puntos.	Así que, puedo escribir $R^{n}(x)$, $\alpha$0 por $$R^{n}}}}{e^{2\pi i x}})=e^{2\pi i x}}}}}}{x}+n\alpha}}}}}{x8} Necesito probar que, para todos los $\alpha$1 y para todos los $\alpha$2, cada vecindario $\alpha$3 de $\alpha$4 contiene un punto $\alpha$5 tal que $\alpha$6 para algún $\alpha$0. Es decir, prueba $\alpha$7 ¿Cómo puedo proceder ahora? ¿Qué no necesito hacer?	general-topology,circles,rotations,irrational-numbers
A.99	Rationals can be the set of continuity of a function?	Most of the functions that I have seen have their discontinuities on rationals and continuities on irrationals! I am wondering if there is any exampe of some function whose continuities are rationals? Or is other words   The set of continuities of a function $f:\mathbb{R}\to\mathbb{R}$ can be $\mathbb{Q}$?	¿Los racionales pueden ser el conjunto de continuidad de una función?	La mayoría de las funciones que he visto tienen sus discontinuidades en racionales y continuidades en irracionales! Me pregunto si hay algún ejemplo de alguna función cuyas continuidades son racionales?	real-analysis,calculus,continuity
A.100	Is this set "not closed"?	Is it correct to say that this set $E=(0,1]$ where $E\subseteq R$ (Where $R$ is the set of real numbers) is not closed?	¿Este conjunto no está cerrado?	¿Es correcto decir que este conjunto $E=(0,1]$ donde $E\subseteq R$ (donde $R$ es el conjunto de números reales) no está cerrado?	real-analysis
A.201	Matrix over division ring having one sided inverse is invertible	I want to see if there is any elementary way to prove the following assertion about matrices over division rings (such as not using Wedderburn's theory or tensoring techniques). If an $n\times n$ matrix over a division ring has left inverse, then it also has right inverse. The assertion has elementary proof for matrices over fields, but I am considering over division rings.  One can give some hints also.	Matriz sobre anillo de división que tiene un lado inverso es invertible	Quiero ver si hay alguna forma elemental de probar la siguiente afirmación sobre matrices sobre anillos de división (como no usar la teoría de Wedderburn o técnicas de tensoría). Si una matriz $n\times n$ sobre un anillo de división ha dejado el inverso, entonces también tiene el inverso derecho. La afirmación tiene prueba elemental para matrices sobre campos, pero estoy considerando sobre anillos de división. Uno puede dar algunas pistas también.	abstract-algebra,matrices,ring-theory
A.202	Rings Trapped Between Fields	Some Background and Motivation: In this question, it is shown that an integral domain $D$ such that $F \subset D \subset E$, $E$ and $F$ fields with $[E:F]$ finite, is itself a field.  However, a significantly more general result holds and seems worthy, of independent address; hence, Let $F \subset E \tag 1$ be fields with $[E:F] < \infty; \tag 2$ if $R$ is a ring such that $F \subset R \subset E, \tag 3$ show that $R$ is in fact a field.	Anillos atrapados entre campos	Algunos antecedentes y motivación: En esta pregunta, se muestra que un dominio integral $D$ tal que los campos $F \subset D \subset E$, $E$ y $F$ con $[E:F]$ finito, es en sí mismo un campo. Sin embargo, un resultado significativamente más general se mantiene y parece digno, de dirección independiente; por lo tanto, que $F \subset E \tag 1$ sean campos con $[E:F] < \infty; \tag 2$ si $R$ es un anillo tal que $F \subset R \subset E, \tag 3$ muestre que $R$ es de hecho un campo.	abstract-algebra,ring-theory,field-theory,extension-field
A.203	Why does the subtraction symbol go away? $-(-x)= x$	$+(+x) = +x$ but why is $-(-x) = +x$??? What's the reason behind the rule, it's really basic and "obvious" because a no turns a no to a yes But I don't want to reason like that, lol. So how would you explain it? Do I just say on a real number line $-x$ makes a turnaround and $-(-x)$ would turn it positive again? Also if I say for example: $-x = 5$ then I do have $-(-x) = -5$ Is it correct? It wouldn't matter, right? (Btw: I don't know if the tag "elementary-number-theory" is correct) **The question is different to $(-x)*(-x)=x$	¿Por qué desaparece el símbolo de restancia?	¿Cómo lo explicaría? ¿Simplemente digo que en una línea de números reales $-x$ hace una vuelta y $-(-x)$ lo vuelve positivo? También si digo por ejemplo: $-x = 5$ entonces tengo $-(-x) = -5$ ¿Es correcto?	abstract-algebra
A.204	subscheme where two morphisms agree is points where they agree on residue fields	Let $X, Y, Z$ be schemes, where $X, Y$ are $Z$ schemes.  I know the definition of "the locally closed subscheme of $X$ where two $Z$-  morphisms $\pi, \pi': X\rightarrow Y$ agree" from its universal property.  Also I can define it as the fiber product of the diagonal $$\delta :  Y\rightarrow Y\times_Z Y$$ with $$(\pi, \pi'): X\rightarrow Y\times_Z Y.$$ My question:  how to prove that the underlying set of "the locally closed subscheme where the two morphisms agree" is the same as the set of points where the two morphism agree on the residue field. It is probably clear thatthe former is contained in the latter, but why is it all of them?  That is, why is a point where $\pi, \pi'$ agree on the residue field necessarily contained in "the subscheme where $\pi, \pi'$ agree"?	subesquema donde dos morfísmos coinciden es puntos donde coinciden en campos de residuos	Ponga $X, Y, Z$ en esquemas, donde $X, Y$ es $Z$ esquemas. Conozco la definición de "el subesquema localmente cerrado de $X$ donde dos morfismos $Z$ se ponen de acuerdo" desde su propiedad universal. También puedo definirlo como el producto de fibra de la diagonal $$\delta: Y\arrow Y\times_Z Y$$ con $$ ((\pi, \pi'): X\arrow Y\times_Z Y.$$ Mi pregunta: ¿cómo demostrar que el conjunto subyacente de "el subesquema localmente cerrado donde los dos morfismos coinciden" es el mismo que el conjunto de puntos donde los dos morfismos coinciden en el campo de residuos?	algebraic-geometry,schemes
A.205	How can we find x for x^n = n^x	Find values of x such that $x^n=n^x$ Here, n $\in$ I.  One solution will remain x=n But i want to find if any more solutions can exist $$x^n=n^x$$	¿Cómo podemos encontrar x para x^n = n^x	Encuentra valores de x tales que $x^n=n^x$ Aquí, n $\in$ I. Una solución permanecerá x=n Pero quiero encontrar si hay más soluciones pueden existir $XX1$	algebra-precalculus,logarithms
A.206	I'm confused on the limit of $\left(1+\frac{1}{n}\right)^n$	Okay so I read Richard Rusczyk's AoPS Volume 2 Book, and I stumbled upon the part where he informs very briefly that $\lim_{n \rightarrow \infty} \left(1+\frac{1}{n}\right)^n=e$. But he doesn't really provide a rigorous proof as to why that's true (not criticizing him or anything).. It would really help if someone could provide me with the simplest proof possible as to why $\lim_{n \rightarrow \infty} \left(1+\frac{1}{n}\right)^n=e$. Thank you in advance!	Estoy confundido en el límite de $\left(1+\frac{1}{n}\right)^n$	Bien, entonces leí el libro AoPS Volumen 2 de Richard Rusczyk, y me encontré con la parte donde informa muy brevemente que $\lim_{n \rightarrow \infty} \left(1+\frac{1}{n}\right)^n=e$. Pero no proporciona una prueba rigurosa de por qué eso es cierto (no criticándolo o nada).	algebra-precalculus,limits,exponential-function
A.207	What function is asymptotically eqyivalent to $\sum_{k \geq 0}k!/N^k$?	I am working on this problem to find a function $f(N)$ s.t. $$ f(N) \sim \sum_{k \geq 0}\frac{k!}{N^k} $$ where $\sim$ means that given functions $f$ and $g$, we have $f \sim g \implies f = O(g) \text{ and } f=\Omega(g)$. For instance, given the right hand side of the equation above, on input $N$ we have the following (it's a divergent series) $$ f(N) \sim 1 + \frac{1}{N} + \frac{1}{2N^2} + \frac{1}{6N^3} + O\bigg(\frac{1}{N^4}\bigg) $$ The closest function I can think of are the binomials where: $$ (N \text{ choose } r) \sim \frac{N^r}{r!} $$ But it doesnt really equal the first equation above. Any help?	¿Qué función es asimptóticamente equivalente a $\sum_{k \geq 0}k!/N^k$?	Estoy trabajando en este problema para encontrar una función $f(N)$ s.t. $$ f(N) \sim \sum_{k \geq 0}\frac{k!}{N^k} $$ donde $\sim$ significa que las funciones $f$ y $g$ dadas, tenemos $f \sim g \implies f = O(g) \text{ and } f=\Omega(g)$. Por ejemplo, dado el lado derecho de la ecuación anterior, en la entrada $N$ tenemos la siguiente (es una serie divergente) $$ f(N) \sim 1 + \frac{1}{N} + \frac{1}{2N^2} + \frac{1}{6N^3} + O\biggg\frac{1}{N^4}\bi) $$ La función más cercana que puedo pensar son las binarias donde $$ (Nomi \ r) } \frac{N} {2} ¡Pero ¿alguna cosa realmente ayuda a escoger la primera ecuación anterior?	algorithms,asymptotics,approximation,factorial
A.208	Where does this asymptote for $H_n^{(k)}$ come from?	@Claude Leibovici's answer to this Math Stack Exchange question (it's the second answer) gives an asymptote for the generalised harmonic number $H_n^{(k)}=\sum_{i=1}^n \frac{1}{i^k}$: $$H_n^{(k)}=n^{-k}    \left(-\frac{n}{k-1}+\frac{1}{2}-\frac{k}{12    n}+O\left(\frac{1}{n^3}\right)\right)    +\zeta (k)$$ Heuristically, this is an excellent fit. But can someone please tell me if this is a published result, and more importantly how it is derived?	¿De dónde viene este asintoto para $H_n^{(k)}$?	La respuesta de Claude Leibovici a esta pregunta de la Estaca de Matemáticas (es la segunda respuesta) da un asímptote para el número armónico generalizado $H_n^{(k)}=\sum_{i=1}^n \frac{1}{i^k}$: $$H_n^{(k)}=n^{-k} \left(-\frac{n}{k-1}+\frac{1}{2}-\frac{k}{12 n}+O\left(\frac{1}{n^3}\right)\right) +\zeta (k)$$ Heurísticamente, esto es un ajuste excelente. ¿Pero alguien puede decirme si este es un resultado publicado, y lo que es más importante, cómo se deriva?	asymptotics,harmonic-functions,upper-lower-bounds,harmonic-numbers
A.209	Evaluate the definite integral: $\int_0^\infty e^{-hx^2}\;\mathrm{d}x$	where $h>0$. Could someone explain to me how to solve it? I searched the internet and I found the result is $\frac{\sqrt{\pi}}{2\sqrt{h}}$ but I couldn't undersand Gauss error function - that is involved in solving.	Evaluar la integral definida: $\int_0^\infty e^{-hx^2}\;\mathrm{d}x$	¿Puede alguien me explicar cómo resolverlo? busqué en Internet y encontré el resultado es $\frac{\sqrt{\pi}}{2\sqrt{h}}$ pero no pude subestimar la función de error de Gauss - que está involucrado en la resolución.	calculus,integration,definite-integrals
A.210	what's an elegant way to show that $x(1-x) \leq \frac14$?	for $x \in \mathbb{R}$, consider $f(x) = x(1-x)$, using traditional methods of finding global extremas, we can show that the derivative has a unique zero at $x= \frac12$ and $f''(\frac12) < 0$, thus $x(1-x) \leq \frac14 = f(\frac12)$ is there a more elegant way ?	¿Cuál es una forma elegante de mostrar ese $x(1-x) \leq \frac14$?	Para $x \in \mathbb{R}$, considere $f(x) = x(1-x)$, utilizando métodos tradicionales de encontrar extremos globales, podemos mostrar que la derivada tiene un cero único en $x= \frac12$ y $f''(\frac12) < 0$, por lo tanto, $x(1-x) \leq \frac14 = f(\frac12)$ hay una manera más elegante ?	calculus,inequality
A.211	$\int\sqrt{x^2\sqrt{x^3\sqrt{x^4\sqrt{x^5\sqrt{x^6\sqrt{x^7\sqrt{x^8\ldots}}}}}}}\,dx$	I was attempting to solve an MIT integration bee problem (1) when I misread the integral and wrote (2) instead.  $$\int\sqrt{x\cdot \sqrt[3]{x\cdot \sqrt[4]{x\cdot\sqrt[5]{x\ldots } }}}\,dx\tag{1}$$ $$\int\sqrt{x^2\sqrt{x^3\sqrt{x^4\sqrt{x^5\sqrt{x^6\sqrt{x^7\sqrt{x^8\ldots}}}}}}}\,dx\tag{2}$$ I was able to solve (1), as the integrand simplifies to $x^{e-2}$, however, I'm struggling with solving (2).  If we rewrite the roots as powers, we get: $$\int x^\frac{2}{2}\cdot x^\frac{3}{4}\cdot x^\frac{4}{8}\cdot x^\frac{5}{16}\ldots\,dx$$ combining the powers we get: $$\int x^{\frac{2}{2}+\frac{3}{4}+\frac{4}{8}+\frac{5}{16}+\ldots}$$ the exponent is the infinite sum $$\sum^{\infty}_{n=1}\frac{n+1}{2^n}\tag{3} $$ we can split this into:  $$\sum^{\infty}_{n=1}\frac{n}{2^n}+\sum^{\infty}_{n=1}\frac{1}{2^n} $$ The right sum is well known except here the sum begins at $n=1$, meaning that the right sum evaluates to 1. Messing around with desmos, the integrand appears to be $x^3,x>0$ implying that (3) converges to 3 and the $\sum^{\infty}_{n=1}\frac{n}{2^n}$ converges to 2. Which is part I'm struggling with. Any ideas?  $$\sum^{\infty}_{n=1}\frac{n}{2^n}$$	$\int\sqrt{x^2\sqrt{x^3\sqrt{x^4\sqrt{x^5\sqrt{x^6\sqrt{x^7\sqrt{x^8\ldots}}}}}}}\,dx$	Estaba tratando de resolver un problema de integración de MIT (1) cuando mal leí la integral y escribí (2) en su lugar. $$\int\sqrt{x\cdot \sqrt[3]{x\cdot \sqrt[4]{x\cdot \sqrt[5]{x\ldots } }}}\,dx\tag{1} $$\int\sqrt{x^2\sqrt{x^2}\sqrt{x^3\sqrt{x^4\sqrt{x^5\sqrt{x^6\sqrt{x^7\sqrt{x^8\ldots}}}}}\, dx\cdot{2} $$} pude resolverlo como la suma de las sumas conocidas, sin embargo, estoy luchando con la suma de las sumas convertidas para obtener la convergencia de las resumadas, como lo conseguimos, esto significa que la suma de las resumadas se divide en las resumadas de las resumadas de las resumadas de las resumadas de las resumadas de las resumadas de las resumadas de las resumadas de las resumadas de las resumadas de las resumadas de las resumadas de resumadas de resumadas de resumadas de resumadas de resumidas de resumadas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumadas resumidas de resumadas resumidas de resumidas de resumidas de resumidas de resumadas resumidas de resumidas de resumidas de resumidas de resumadas resumidas de resumadas resumidas de resumadas resumidas de resumadas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumadas resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de resumidas de res	calculus,sequences-and-series
A.212	Evaluating an infinite series	I've been given the function $$f(x)=\sum_{n=0}^{\infty}(2n+1)(2x)^{2n}$$ And I have to evaluate $f(1/4)$ so find the value of $$f(1/4)=\sum_{n=0}^{\infty}\frac{2n+1}{2^{2n}}$$ I would appreciate any help with this as I am pretty lost.	Evaluación de una serie infinita	Me han dado la función $$f(x)=\sum_{n=0}^{\infty}(2n+1)(2x)^{2n}$$ Y tengo que evaluar $f(1/4)$ así que encontrar el valor de $$f(1/4)=\sum_{n=0}^{\infty}\frac{2n+1}{2^{2n}}$$ Yo agradecería cualquier ayuda con esto ya que estoy bastante perdido.	calculus,sequences-and-series,power-series,taylor-expansion
A.213	Calculate $\sum_{x=1}^{\infty} \frac{(x-1)}{2^{x}}$	I can prove it converges but I don't know at what value it converges. $\sum_{x=1}^{\infty} \frac{(x-1)}{2^{x}}$	Calculación de la $\sum_{x=1}^{\infty} \frac{(x-1)}{2^{x}}$	Puedo demostrar que converge pero no sé a qué valor converge.	calculus,power-series
A.214	Show that $\int\limits_{-\infty}^\infty e^{-\pi x^2}dx = 1$	I want to show that $\int\limits_{-\infty}^\infty e^{-\pi x^2}dx = 1$. By definition $$\int\limits_{-\infty}^\infty e^{-\pi x^2}dx = \lim\limits_{t\to\infty}\int\limits_{-t}^t e^{-\pi x^2}dx$$ and since the integrand $e^{-\pi x^2}$ is an even function $$\int\limits_{-\infty}^\infty e^{-\pi x^2}dx = \lim\limits_{t\to\infty}\int\limits_{-t}^t e^{-\pi x^2}dx = 2\lim\limits_{t\to\infty}\int\limits_0^t e^{-\pi x^2}dx$$ i.e. we can equivalently show that $\lim\limits_{t\to\infty}\int\limits_0^t e^{-\pi x^2}dx=\frac{1}{2}$. Since the antiderivative of $e^{-x^2}$ is given by the error function we can't straightforwardly evaluate the integral, so I tried to use the power series expansion, hoping to be able to see that the resulting series will converge to $\frac{1}{2}$: $$|\int\limits_0^t e^{-\pi x^2}dx-\frac{1}{2}| = |\int\limits_0^t\sum\limits_{n=0}^\infty\frac{\pi^n\cdot x^{2n}}{n!}dx - \frac{1}{2}| = |\sum\limits_{n=0}^\infty\frac{\pi^n\cdot t^{2n+1}}{n!\cdot(n+1)}-\frac{1}{2}|$$ However, I'm in a doubt that it converges and a quick check in Wolfram Mathematica shows indeed that with $t\to\infty$ the resulting series will diverge. What am I doing wrong? Can anybody help me with a proof for this problem? Any help will be really appreciated.	Muéstrate eso $\int\limits_{-\infty}^\infty e^{-\pi x^2}dx = 1$	Quiero mostrar que $\int\limits_{-\infty}^\infty e^{-\pi x^2}dx = 1$.} Por definición $$\int\pilimits_{-\infty}^\infty e^{-\pi x^2}dx = \\limits_{t\to\infty}\int\limits_{t\pi x^2}dx$$ y ya que el integrando $e^{-\pi x^2}$ es una función igual $$\int\limits_{-\infty}^\infty e^{\pi x^2}dx = \\limits_{t\to\infty}\int\limits_{t\to\infty}\t e intentó{-\pi x2}dx = 2\limits_{t\to_dotin} pero ¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡	calculus,integration,improper-integrals
A.215	Set Of Discontinuities Of A Derivative	Prove that the set of discontinuities of a derivative of an everywhere differentiable function $f(x)$ is of 1st category. Let $f'(x)$ be a derivative of an everywhere differentiable function $f(x)$. Now as the set of discontinuities of any arbitrary functions can be written as a countable union of closed sets. So let $A$ be the set of discontinuities of $f'(x)$, then we can write $$A=\bigcup_{n=1}^{\infty}A_n$$ where all the $A_n$ are closed set. Now suppose that for $n=n_0$ the set $A_{n_0}$ is not nowhere dense then there exists an open interval $(p, q)$ such that for any interval $I$ in that open interval $(p, q)$ we have $$I \cap A_{n_0} \neq \phi$$ and hence $A_{n_0}$ is dense in the open interval $(p, q)$ and as $A_{n_0}$ is closed so it contains the interval $(p, q)$ and hence $f'(x)$ is entirely discontinuous on the open interval $(p, q)$, but as the derivative of an everywhere differentiable function cannot be entirely discontinuous on an interval, so a contradiction. Is My Proof Correct??	Conjunto de discontinuidades de un derivado	Demostrar que el conjunto de discontinuidades de una derivada de una función diferenciable en todas partes $f(x)$ es de 1a categoría. Supongamos que $f'(x)$ sea un derivado de una función diferenciable en todas partes $f(x)$. Ahora, como el conjunto de discontinuidades de cualquier función arbitraria puede ser escrito como una unión contable de conjuntos cerrados. Así que vamos a $A$ ser el conjunto de discontinuidades de $f'(x)$, entonces podemos escribir $$A=\bigcup_{n=1}^{\infty}A_n$$ donde todos los $A_n$ están establecidos. Ahora supongamos que para $n=n_0$ el conjunto $A_{n_0}$ no es en ninguna parte denso entonces existe un intervalo abierto $(p, q)$ tal que para cualquier intervalo $I$ en ese intervalo abierto $(p, q)$ tenemos $$I \n_0} \nephix así que el intervalo de $$ y $A_{n_0}$ es completamente denso en el intervalo abierto y el intervalo de $(p, q)$ está cerrado y el intervalo de $(p, q)$ es un intervalo abierto y el intervalo de $A_{n_0}$ es un intervalo abierto y el intervalo de $(p, q)$ es un intervalo abierto, así que el intervalo de $A_{n_0}$ es un intervalo abierto y el intervalo de $(p, q)$ es un intervalo abierto, pero el intervalo de $(p, q)$ es un intervalo discontino como el intervalo abierto, pero el intervalo de $(p, q)$ es un intervalo abierto.	calculus
A.216	Compute the limit $\lim\limits_{t \to + \infty} \int_0^{+ \infty} \frac{ \mathrm d x}{e^x+ \sin tx} $	I have been working on this limit for days, but I am not getting it. The question is  Compute the limit $$\lim_{t \to + \infty} \int_0^{+ \infty} \frac{ \mathrm d x}{e^x+ \sin (tx)}$$  Note that the integral is well defined and convergent for every $t >0$. Indeed the integrand function is a positive function for every $t >0$ since $$e^x + \sin tx > e^x-1 > x>0$$ And as $x \to + \infty$ the integrand function behaves like $e^{-x}$. WHAT I TRIED: I consider $t=2n \pi$ a multiple of $2 \pi$, and see what happens: $$\int_0^{+ \infty} \frac{ \mathrm d x}{e^x+ \sin (2n \pi x)} = \sum_{k=0}^\infty \int_{k /n}^{(k+1) /n} \frac{ \mathrm d x}{e^x+ \sin (2n \pi x)}$$ Making the change of variables $u = 2n \pi x$ I get \begin{align}\sum_{k=0}^\infty \frac{1}{2n \pi} \int_{2k \pi}^{(2k+2) \pi} \frac{ \mathrm d u}{e^{u/2n \pi}+ \sin (u)} &\ge \sum_{k=0}^\infty \frac{1}{2n \pi} \int_{2k \pi}^{(2k+2) \pi} \frac{ \mathrm d u}{e^{(2k+2) \pi/2n \pi}+ \sin (u)} \\&= \sum_{k=0}^\infty \frac{1}{2n \pi} \int_{2k \pi}^{(2k+2) \pi} \frac{ \mathrm d u}{e^{(k+1)/n}+ \sin (u)}\end{align} where I write the lower bound with the minimum of the function at $u=(2k+2) \pi$. Now I use the fact that the integrand function does is integrated over a period of $2 \pi$, and using the result for $C>1$ $$\int_0^{2 \pi} \frac{ \mathrm d u}{C+ \sin (u)} = \frac{2 \pi}{\sqrt{C^2-1}}$$ I get the estimate \begin{align}\sum_{k=0}^\infty \frac{1}{2n \pi} \int_{2k \pi}^{(2k+2) \pi} \frac{ \mathrm d u}{e^{(k+1)/n}+ \sin (u)} &= \sum_{k=0}^\infty \frac{1}{2n \pi} \frac{2 \pi}{\sqrt{e^{2(k+1)/n} -1 }} \\&= \frac{1}{n} \sum_{k=0}^\infty \frac{1}{\sqrt{e^{2(k+1)/n} -1 }}\end{align} Summing all up, I got that $$\int_0^{+ \infty} \frac{ \mathrm d x}{e^x+ \sin (2n \pi x)} \ge \frac{1}{n} \sum_{k=0}^\infty \frac{1}{\sqrt{e^{2(k+1)/n} -1 }}$$ As $n \to \infty$ the series converges to the Riemann integral $$\int_0^{+ \infty} \frac{\mathrm d y}{\sqrt{e^{2y}-1}} = \frac{\pi}{2}$$ Hence the limit should be a number larger than $\pi/2$, or $+ \infty$. Using WA I got for large values of $t$ that the integral is between $1$ and $2$, thus $\pi/2$ could be the actual limit.	Calcule el límite $\lim\limits_{t \to + \infty} \int_0^{+ \infty} \frac{ \mathrm d x}{e^x+ \sin tx} $	La pregunta es calcular el límite $$\lim_{t \t \t \t \t \t \t \t \t \infty} x0$$ y como $x \to + \infty$ la función integrada se comporta como $e^{-x}$. WHAT I TRIED: considero $t=2n \pi$ un múltiplo de $2 \pi$, y vea lo que sucede: $$\t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \t \	calculus,integration,limits,definite-integrals
A.217	An easy Calculus Problem	Here's the question- Find the maximum area of an isosceles triangle inscribed in the ellipse $x^2/a^2 + y^2/b^2 = 1$. My teacher solved it by considering two arbitrary points on the ellipse to be vertices of the triangle, being $(a\cos\theta, b\sin \theta)$ and $(a\cos\theta, -b\sin \theta)$. (Let's just say $\theta$ is theta) and then proceeded with the derivative tests(which i understood) But, he didn't indicate what our $\theta$ was,and declared that these points always lie on an ellipse. Why so? And even if they do, what's the guarantee that points of such a form will be our required vertices? One more thing, I'd appreciate it if you could suggest another way of solving this problem. Thank you!	Un problema de cálculo fácil	Aquí está la pregunta: encontrar el área máxima de un triángulo de isosceles inscrito en la elipse $x^2/a^2 + y^2/b^2 = 1$. Mi profesor lo resolvió considerando dos puntos arbitrarios en la elipse para ser vértices del triángulo, siendo $(a\cos\theta, b\sin \theta)$ y $(a\cos\theta, -b\sin \theta)$. (Sólo digamos que $\theta$ es theta) y luego continuó con las pruebas derivadas(que entendí) Pero, no indicó lo que nuestro $\theta$ era, y declaró que estos puntos siempre están en una elipse. ¿Por qué?	calculus,derivatives
A.218	Problem involving recursion of binomial coefficients	Wrt Ramsey numbers I have the following identity given to me: $ R(m, n) \leq R(m-1, n)+R(m, n-1) $ And i have the following bases cases: $R(m,2)=m$ and $R(2,n)=n$. One has to prove that: $R(m, n) \leq\left(\begin{array}{c}{m+n-2} \\ {m-1}\end{array}\right)$ It is obvious that we have to go on splitting the two terms on the RHS into pairs of terms decrementing the indices by 1 each time. But the appearance of the combination is non-obvious.	Problema que implica la recursión de los coeficientes binomial	Wrt números Ramsey tengo la siguiente identidad que me dieron: $ R(m, n) \leq R(m-1, n)+R(m, n-1) $ y tengo los siguientes casos de base: $R(m,2)=m$ y $R(2,n)=n$. Uno tiene que probar que: $R(m, n) \leq\left(\begin{array}{c}{m+n-2} \\ {m-1}\end{array}\right)$ Es obvio que tenemos que seguir dividiendo los dos términos en el RHS en pares de términos que disminuyen los índices por 1 cada vez. Pero la apariencia de la combinación no es obvia.	combinatorics,combinations,binomial-coefficients,ramsey-theory
A.219	How to prove a combinatorial identity with a combinatorial argument	I am trying to prove the following identity using a a combinatorial argument: $$\dbinom{n+r+1}{r}=\sum_{k=0}^{r}\dbinom{n+k}{k}$$	Cómo probar una identidad combinatoria con un argumento combinatorial	Estoy tratando de probar la siguiente identidad usando un argumento combinatorial: $$\dbinom{n+r+1}{r}=\sum_{k=0}^{r}\dbinom{n+k}{k}$$	combinatorics,discrete-mathematics,combinations,combinatorial-proofs
A.220	How can i prove the identity $\sum_{k=0}^{n} \binom{x+k}{k}=\binom{x+n+1}{n}$	I'm having a difficult time understanding how to give a combinatorics proof of the identity $$\sum_{k=0}^{n} \binom{x+k}{k}=\binom{x+n+1}{n}$$	¿Cómo puedo probar la identidad de $\sum_{k=0}^{n} \binom{x+k}{k}=\binom{x+n+1}{n}$	Estoy teniendo un tiempo difícil de entender cómo dar una prueba combinatoria de la identidad $$\sum_{k=0}^{n} \binom{x+k}{k}=\binom{x+n+1}{n}$$	combinatorics,summation,binomial-coefficients
A.221	What's the minimum number of $2$s needed to write a positive integer?	This is just for fun and inspired by Estimating pi, using only 2s. For a positive integer $n$, let $f(n)$ denote the minimum number of $2$s needed to express $n$ using addition, subtraction, multiplication, division, and exponentiation, together with the ability to concatenate $2$s, so for example $2 \times 22^2 + \frac{222}{2}$ is a valid expression. Other variants involving different sets of allowed operations are possible, of course. This function is very far from monotonic, so to smooth it out let's also consider $$g(n) = \text{max}_{1 \le m \le n} f(m).$$ For example,  $f(1) = 2$ ($1 = \frac 22$) $f(11) = 3$ ($11 = \frac{22}{2}$)   Question: What can you say about $f(n)$ and $g(n)$? Can you give exact values for small values of $n$? Can you give (asymptotic or exact) upper bounds? Lower bounds?  As a simple example we can write any positive integer $n$ in the form $2^k + n'$ where $n' < 2^k$ ($2^k$ is just the leading digit in the binary expansion of $n$), which gives $f(n) \le f(k) + 1 + f(n')$. If we write $\ell(n) = \lfloor \log_2 n \rfloor$ then iterating this gives something like $$g(n) \le \sum_{k=1}^{\ell(n)} \left( g(k) + 1 \right).$$ This gives an upper bound growing something like $\ell(n) \ell^2(n) \ell^3(n) \dots$ which I think is pessimistic. For example, in my answer to the linked question I show that $$f(14885392687) \le 36$$ and $\ell(14885392687) = 33$ so maybe we can expect something as good as $g(n) = O(\log n)$ for an upper bound. I have no idea about a lower bound, other than to write down an upper bound on the number of possible expressions that can be made with a given number of $2$s. Edit: A related question involving $4$s and more allowed operations: How many fours are needed to represent numbers up to $N$?	¿Cuál es el número mínimo de $2$s necesario para escribir un número entero positivo?	Esto es sólo para diversión e inspirado en Estimar pi, usando sólo 2s. Para un número entero positivo $n$, vamos a $f(n)$ denotar el número mínimo de $2$s necesario para expresar $n$ usando adición, subtracción, multiplicación, división y exponenciación, junto con la capacidad de concatenar $2$s, por ejemplo $2 \times 22^2 + \frac{222}{2}$ es una expresión válida. Otras variantes que implican diferentes conjuntos de operaciones permitidas son posibles, por supuesto. Esta función está muy lejos de ser monótona, así que para suavizarlo también vamos a $$g) = \text{max}_{1 \text m \le n} fm.$$ Por ejemplo, $f(1) = 2$ ($1 = \frac 22$) $f(11) = 3$ ($11 = \frac{22}{2}$): ¿Qué puede decirse acerca de $f(n)$ y $n$0? ¿Das una idea exacta para los valores de los números pequeños de $n$?	combinatorics,optimization,recreational-mathematics
A.222	A company hires $11$ new employees, and they will be assigned to four different departments, A, B, C, D	A company hires $11$ new employees, and they will be assigned to four different departments, A, B, C, D. Each department has at least one new employee. In how many ways can these assignments be done?  I know that for each section (A,B,C,D) I should add a () and as long as every section must get a new employee we should start like this: $$(x+x^2/2!+x^3/3!+...)^4$$ then if we look  it's $(e^x-1)^4$. After this step I don't know what to do.	Una empresa contrata a $11$ nuevos empleados, y serán asignados a cuatro departamentos diferentes: A, B, C, D	Una empresa contrata a $11$ nuevos empleados, y se asignarán a cuatro departamentos diferentes, A, B, C, D. Cada departamento tiene al menos un nuevo empleado. ¿De cuántas maneras se pueden hacer estas asignaciones? Sé que para cada sección (A, B, C, D) debo agregar un () y mientras cada sección tenga que conseguir un nuevo empleado deberíamos comenzar así: $$ ((x+x^2/2!+x^3/3!+...)^4$$ entonces si miramos es $(e^x-1)^4$. Después de este paso no sé qué hacer.	combinatorics,generating-functions
A.223	combinatorial proof that $\sum_{i=0}^n {n+i\choose i}\frac{1}{2^i} = 2^n$	Give a combinatorial proof that $\displaystyle\sum_{i=0}^n {n+i\choose i}\frac{1}{2^i} = 2^n$.  I'm not sure if Pascal's identity is useful here. Or perhaps there is a way involving binary strings? $2^n$ is the number of binary strings of length $n$, so if there was some way to decompose these strings into disjoint sets $B_i$ with cardinality ${n+i\choose i}\frac{1}{2^i}$, a proof using that method might work. ${n+i\choose i}$ is the number of binary strings of length $n+i$ with exactly $i$ ones, since one can choose $i$ of the $n+i$ positions to be ones in ${n+i\choose i}$ ways and make the rest zeroes in one way. Then we divide by the number of binary strings of length $i$, though I'm not sure how to deduce the combinatorial significance of this. I'm most likely thinking of this the wrong way.	prueba combinatoria de que $\sum_{i=0}^n {n+i\choose i}\frac{1}{2^i} = 2^n$	Si hay alguna forma de descomponer estas cuerdas en conjuntos disjointos $B_i$ con cardinalidad ${n+i\choose i}\frac{1}{2^i}$, una prueba usando ese método podría funcionar. ${n+i\choose i}$ es el número de cuerdas binarias de longitud $n+i$ con exactamente $i$ de las, ya que uno puede elegir $i$ de las posiciones $n+i$ para ser una de ${n+i\choose i}$ formas y hacer los demás cero de una manera. Entonces dividimos por el número de cuerdas binarias de longitud $i$, aunque no sé cómo deducir la importancia combinatoria de esto.	combinatorics,elementary-set-theory,summation,combinatorial-proofs
A.224	I think I found a flaw in the $\varepsilon$-$\delta$ definition of continuity.	If I have a function $f(x)$ defined as follows.  $f(x) = 1$ for all $x<1$ and $x>2$; $f(x) = 100$ for $x = 1.5$; $f(x)$ is undefined anywhere else.  According to the $\varepsilon$-$\delta$ definition of continuity, if I take $\delta$ as any positive number smaller than $0.5$, then $f(x)$ by definition is continuous at $x = 1.5$ because within the $\delta$-neighborhood there is only one point defined, but $f(x)$ is obviously not continuous at $x = 1.5$. Below is the $\varepsilon$-$\delta$ definition of continuity: The function $f(x)$ is continuous at a point $x_0$ of its domain if for every positive $\varepsilon$ we can find a positive number $\delta$ such that $$|f(x) - f(x_0)|<\varepsilon$$ for all values $x$ in the domain of $f$ for which $|x-x_0|<\delta$.	Creo que encontré un fallo en la definición de continuidad de $\varepsilon$-$\delta$.	Si tengo una función $f(x)$ definida de la siguiente manera. $f(x) = 1$ para todos los $x<1$ y $x>2$; $f(x) = 100$ para $x = 1.5$; $f(x)$ es indefinido en cualquier otro lugar. Según la definición de continuidad $\varepsilon$-$\delta$, si tomo $\delta$ como cualquier número positivo menor que $0.5$, entonces $f(x)$ por definición es continuo en $x = 1.5$ porque dentro del vecindario $\delta$-hay sólo un punto definido, pero $f(x)$ obviamente no es continuo en $x = 1.5$. A continuación se encuentra la definición de continuidad $\varepsilon$-$\delta$: La función $f(x)$ es continua en un punto $f(x)$0 de su dominio si para cada $\varepsilon$ positivo podemos encontrar un número positivo $\delta$ tal que $f(x)$1fx) - fvarex_x0)<\psilon$f(x)$1 para todos los valores $f(x)$2 en el dominio de $f(x)$3 para el cual $f(x)$4 es el número $f(x)$4.	continuity
A.225	Finding the sum of non-unique roots of cubic equations	The real numbers $\alpha,\beta$ satisfy $$\alpha^3-3\alpha^2+5\alpha-17=0\tag{1}$$ $$\beta^3-3\beta^2+5\beta+11=0\tag{2}$$ Find $\alpha+\beta$  Are the three roots of both cubic equations unique, or is there only one root? How can you prove it? What's the best approach to this problem?  I tried using Vieta's formulas, where the sum of three roots of (1) and (2) are: $$\alpha_1+\alpha_2+\alpha_3=3$$ $$\beta_1+\beta_2+\beta_3=3$$ Summing both, $$\alpha_1+\alpha_2+\alpha_3+\beta_1+\beta_2+\beta_3=6$$ Assuming there is only one root for each of (1) and (2), we are done, but what if there isn't?	Encontrar la suma de las raíces no únicas de las ecuaciones cúbicas	Los números reales $\alpha,\beta$ satisfagan $$\alpha^3-3\alpha^2+5\alpha-17=0\tag{1}$$\beta^3-3\beta^2+5\beta+11=0\tag{2}$$ Encontrar $\alpha+\beta$ ¿Son las tres raíces de ambas ecuaciones cúbicas únicas, o hay sólo una raíz? ¿Cómo puedes probarlo? ¿Cuál es el mejor enfoque para este problema? He intentado usar las fórmulas de Vieta, donde la suma de las tres raíces de (1) y (2) son: $$\alpha_1+\alpha_2+\alpha_3=3$$ $$\alpha_1\alpha_2\alpha_3=3$$ Sumando ambas, $$\alpha_1+\alpha_2\alpha_2\alpha_3\alpha_3\alpha_3\alpha_3\alpha_3\alpha_3\alpha_2\alpha_2\alpha_2\alpha_2\alpha_2\alpha_2\alpha_2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\3\2\2\2\2\2\2\2\2\2\2\2\2\2\2\2\3\2\2\3\2\2\2\2\2\2\2\2\2\3\2\2\2\2\2\3\2\2\3\2\2\2\3\2\2\2\2\2\2\3\2\2\2\2\2\2\3\2\2\2\3\2\2\2\2\2\2\3\3\2\2\2\2\2\2\2\2\3\2\2\2\2\2\2\2\3\2\2\2\2\3\2\2\2\3\3\2\2\2\2\2\2\2\2\3\2\2\2\2\2\2\2\2\3\2\2\2\3\2\2\2\2\2\2\3\2\2\2\2\2\2\2\3\2\3\2\3\2\2\2 \2\2\2\3\2\2\2\2\2\2\2\2\2\2\2\2 \2\2\3\3\2\2 \2 \2\2\2\2 \2\2\3\2 \2 \2\2\3\3\2 \2 \2 \2 \2\3\3\2 \2 \2 \2 \2 \2 \2 \2 \2 \3\2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \2 \3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3\3 \ \ \ \ \ \3\3\3\3 \3\3\3 \ \3 \ \ \ \3\	cubic-equations
A.226	Parametrization of the curve $x^{x^y}=y$	I was looking at the graph of the equation $x^{x^y}=y$ (Desmos link). This graph has two components that cross at the point $(1/e^e,1/e)=(e^{-e},e^{-1})$. Component 1 (as I'll call it) is the component $x^y=y$ which has the simple parametrization $$(x,y)=\left(t^{1/t},t\right),\qquad0 Component 2 is a path between the points $(0,0)$ and $(0,1)$.  Does component 2 also admit a parameterization?  To clarify: Component 2 is a path so of course it abstractly admits a parameterization, but I'm asking if there is a parametrization that we can actually write down algebraically in terms of elementary functions.  My motivation for this question is from the limiting behavior of the sequence $0,1,x,x^x,x^{x^x},x^{x^{x^x}},\ldots$, whose behavior is closely related to the solutions to $x^{x^y}=y$. In particular, if $x$ is less than $e^{-e}$ then this sequence alternates between the upper and lower parts of component 2.	Parametrización de la curva $x^{x^y}=y$	Estaba mirando el gráfico de la ecuación $x^{x^y}=y$ (enlace Desmos). Este gráfico tiene dos componentes que se cruzan en el punto $(1/e^e,1/e)=(e^{-e},e^{-1})$. Componente 1 (como lo llamaré) es el componente $x^y=y$ que tiene la parámetriz simple $$(x,y) =\izquierda(t^{1/t},t\derecha),\qquad0 Componente 2 es un camino entre los puntos $(0,0)$ y $(0,1)$. ¿Accepta también el componente 2 una parámetriz? Para aclarar: Componente 2 es un camino por lo que, por supuesto, admite una parámetriz abstractamente, pero me pregunto si hay una parámetriz que realmente podemos escribir algebraicamente en términos de funciones elementales. Mi motivación para esta pregunta es del comportamiento limitante de la secuencia 7, cuyo comportamiento está estrechamente relacionado con las soluciones de la secuencia $x^{x^y}=y$.	curves,parametric,plane-curves,parametrization
A.227	$1+2+3... =-\frac{1}{12}$ - Question regarding this	So, I'm not a big expert in this subject but I know $1+2+3...=-\dfrac{1}{12}$ isn't to do with 'real' maths but it's all to do with the zeta function; however I was watching a maths video and the equation: $$ \frac{x(x+1)}{2} $$ ... is actually a perfect equation for the series $1+2+3...$ etc. where $x$ represents $n$ in a series and $y$ is the sum of the series up to $n$. So, you can conclude that: $$ \sum^{n}_{i=1}1+2+3...=\frac{x(x+1)}{2} $$ However, this is where it gets weird; as you have probably guessed, the roots of the equation is $x=0,-1$  but if I want to find the integral of the roots from $-1$ to $0$ which is under the $x$ axis, I get the following: $$ \int_{-1}^{0} \frac{x(x+1)}{2}\:dx=-\frac{1}{12} $$ So, my question is why is this the case; what connection is there between the value of the integral under the $x$ axis that this graph has compared to the summation of the series? Link to Desmos graph for more clarity	$1+2+3... =-\frac{1}{12}$ - Pregunta sobre este asunto	Así que, no soy un gran experto en este tema, pero sé que $1+2+3...=-\dfrac{1}{12}$ no tiene que ver con las matemáticas 'reales', pero todo tiene que ver con la función zeta; sin embargo, estaba viendo un video de matemáticas y la ecuación: $$ \frac{x(x+1)}{2} $$ ... es en realidad una ecuación perfecta para la serie $1+2+3...$ etc. donde $x$ representa $n$ en una serie y $y$ es la suma de la serie hasta $n$. Así que, se puede concluir que: $$ \^n}_{i=1}+2+3=\frac{(x+1)}{2} $$ raro, aquí es donde se encuentra; como probablemente has adivinado, las raíces de la ecuación son $x=0,-1$ pero quiero encontrar la suma de la raíces de la serie $0$} pero si la relación entre el eje $0$} y el eje $0$}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}}{2}{2}}{2}{2}}{2}{2}}{2}}{2}{2}}{2}{2}}}{2}{2}}{2}}{2}}{2}{2}}}{2}{2}}}{2}{2}}{2}}{2}}{2}{2}}{2}}{2}}{2}}{2}{2}}}{2}{2}}{2}}{2}}{2}{2}}{2}{2}}}{2}{2}}{2}{2}}{2}}{2}{2}}{2}{2}}{2}}{2}}{2}}{2}{2}{2}}{2}}{2}}{2}}{2}}{2}{2}}{2}{2}{2}}{2}{2}}{2}{2}{2}}{2}{2}}{2}{2}}{2}{2}}{2}{2}{2}}{2}{2}{2}{2}}{2}{2}}{2}{2}{2}{2}}{2}{2}}{2}{2}}{2}{2}{2}{2}}{2}{2}{2}{2}}}{2}{2}{2}{2}}{2}{2}{2}{2}{2}{2}}{2}{2}{2}{2}}}{2}}{2}{2}}{2}{2}{2}{2}{2}{2}{2}}{2}{2}{2}{2}}}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}}{2}{2}{2}{2}{2}{2}}{2}{2}{2}{2}{2}}{2}{2}}{2}{2}}{2}{2}{2}{2}{2}{2}{2}{2}}}{2}{2}{2}{2}}{2}{2}}}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}}{2}{2}{2}{2}}{2}{2}{2}}{2}{2}}}}{2}{2}{2}{2}{2}{2}{2}{2}}}{2}{2}}{2}{2}{2}{2}}}}}{2}{2}	definite-integrals,summation,quadratics,zeta-functions
A.228	Terrible integral with parameter	Let be   $\quad f(x)=\int_{0 }^{+\infty}cos\left(\frac{t^3}{3}+xt\right) d t$  Find the integral $$F(x, y)=\int_{-\infty}^{+\infty} f(t+x) f(t+y) d t$$ I tried exploring f(x), took it in parts, got that it converges. F(x,y) is difficult to investigate, since the product of integrals is there, I don't know what to do with it.	Terrible integral con parámetro	Vamos a ser $\quad f(x)=\int_{0 }^{+\infty}cos\left(\frac{t^3}{3}+xt\right) d t$ Encontrar la integral $$F(x, y) =\int_{-\infty}^{+\infty} f(t+x) f(t+y) d t$$ Intenté explorar f(x), lo tomé en partes, lo conseguí converge.	definite-integrals,improper-integrals
A.229	Finding integral of function involving fractional part of x	The integral given is: $$\int_{0}^{1}\big\lbrace\frac{1}{x}\big\rbrace \big\lbrace\frac{1}{1-x}\big\rbrace \big\lbrace1-\frac{1}{x}\big\rbrace dx$$ where  $\big\lbrace x\big\rbrace$ represents the fractional part of $x$ I first tried breaking it using a piecewise definition but I couldn't figure out how to do it as there wasn't any consistent pattern that I could spot.  I tried graphing it to get an idea but that also didn't get me anywhere. Finally, I tried using the property of definite integral that $\int_{0}^{a}f(x)dx=\int_{0}^{a}f(a-x)dx$ but the first and seccond terms remained the same and the last term changed but not it did not lead to any noticeable changes. I am stuck now. Any help would be appreciated.	Encontrar la integral de una función que involucra una parte fraccionaria de x	La integral dada es: $$\int_{0}^{1}\big\lbrace\frac{1}{x}\big\rbrace \big\lbrace\frac{1}{1-x}\big\rbrace \big\lbrace1-\frac{1}{x}\big\rbrace dx$$ donde $\big\lbrace x\big\rbrace$ representa la parte fraccionaria de $x$ lo quebrío por primera vez usando una definición de pieza intentada pero no pude encontrar la manera de hacerlo ya que no había ningún patrón consistente que pudiera detectar. Traté de graficarlo para obtener una idea pero eso tampoco me llevó a ninguna parte. Finalmente, traté de usar la propiedad de definida integral de $\int_{0}^{a}f(x)dx=\int_{0}^{a}f(a-x)dx$ pero los términos primero y segundo permanecieron los mismos y el término No llevó a cambios no observables, pero ahora me quedaría agradecido.	definite-integrals,fractional-part
A.230	Question about definition of Ramsey number	So I went through the definition of Ramsey number and I have a basic question. Definition: For any given number of colours, $c$, and any given integers $n_1, …, n_c$, there is a number, $R(n_1, …, n_c)$, such that if the edges of a complete graph of order $R(n_1, ..., n_c)$ are coloured with c different colours, then for some i between 1 and c, it must contain a complete subgraph of order ni whose edges are all colour i. Question: Is the multicolour Ramsey number $R(n_1,n_2,..n_c) $same as $R(n_2,n_1,..n_c) $or any other permutation of$ {n_1,n_2,..n_c}$? The definition seems to imply so, I just want to verify if I'm thinking right. I have read that $R(m,n)=R(n,m)$ but nothing about symmetricity of multicolour Ramsey numbers.	Pregunta sobre la definición del número Ramsey	Así que pasé por la definición del número Ramsey y tengo una pregunta básica. definición: para cualquier número dado de colores, $c$, y cualquier número entero dado $n_1, …, n_c$, hay un número, $R(n_1, …, n_c)$, de tal manera que si los bordes de un gráfico completo de orden $R(n_1, ..., n_c)$ están coloreados con c colores diferentes, entonces para algunos i entre 1 y c, debe contener un subgrafo completo de orden ni cuyos bordes son todos colores i. pregunta: ¿Es el número multicolor Ramsey $R(n_1,n_2,..n_c) $ es el mismo que $R(n_2,n_1,..n_c) $ o cualquier otra permutación de $ {n_1,n_2,..n_c}$? la definición parece implicar eso, sólo quiero verificar si estoy pensando bien. He leído que $R(m,n)=R(n,m)$ pero nada sobre la simetría de los números multicolores Ramsey.	definition,ramsey-theory
A.231	Why is 1 divided by aleph null undefined?	So recently I have been thinking about infinity, and one of the things that I thought of was if you were able to get a defined value for the reciprocal of a transfinite (cardinal) number. So, I plugged $\frac{1}{א_0}$ into WolframAlpha and it said the following: img1  Why is this the case? Shouldn't this be similar to this case? $$\lim_{x\to\infty} \frac{1}{x} =0$$ Aren't $\infty$ and $א_0$ equal to the same value in this context? What am I missing here?	¿Por qué 1 dividido por aleph nulo no está definido?	Así que recientemente he estado pensando en el infinito, y una de las cosas que pensé en era si se podía obtener un valor definido para la reciprocidad de un número transfinito (cardenal). Así que, conecté $\frac{1}{א_0}$ en WolframAlpha y dijo lo siguiente: img1 ¿Por qué este es el caso? ¿No debería ser similar a este caso? $$\lim_{x\to\infty} \frac{1}{x} =0$$ ¿No son $\infty$ y $א_0$ igual al mismo valor en este contexto? ¿Qué me falta aquí?	definition
A.232	Definition of Induced Matrix Norm	I'm getting confused between 2 variants of definition of induced matrix norm. Given a norm $||\cdot||$ on $\mathbb{R}^n$, the induced matrix norm is defined by $$ \left\lVert A \right\rVert = \max_{\mathbf v\not =0}\frac{\left\lVert A\mathbf v \right\rVert}{\left\lVert \mathbf v \right\rVert} \qquad for \quad A \in \mathbb{R}^{n\times n}.$$  I'm trying to deduce the second variant from this definition i.e. $$\left\lVert A \right\rVert =\max_{\Vert \mathbf w\Vert = 1}\Vert A \mathbf w\Vert.$$ Consider $\mathbf v= \frac{\left\Vert\mathbf v\right\rVert\mathbf v}{\left\Vert\mathbf v\right\rVert}=\mathbf w\left\Vert\mathbf v\right\rVert $ where $\mathbf w= \frac{\mathbf v}{||\mathbf v||}$ and $||\mathbf w||=1$. Therefore, $$ \left\lVert A \right\rVert = \max_{v\not =0}\frac{\left\lVert A\mathbf v \right\rVert}{\left\lVert \mathbf v \right\rVert}= \max_{v\not =0}\frac{\left\lVert A(\mathbf w\left\Vert\mathbf v\right\rVert )\right\rVert}{\left\lVert \mathbf v \right\rVert}=\max_{\mathbf v\not=0}\frac{||\mathbf v||}{||\mathbf v||}\Vert A \mathbf w\Vert.$$ I don't know how to continue from here on.  Also, I 'm reading textbooks where they say : $$\left\lVert A \right\rVert =\max_{\Vert \mathbf w\Vert = 1}\Vert A \mathbf w\Vert \quad for \quad \mathbf w \in \mathbb{R}^n .$$ My question is shouldn't it be  $$\left\lVert A \right\rVert =\max_{\Vert \mathbf w\Vert = 1}\Vert A \mathbf w\Vert \quad for \quad \mathbf w \in \mathbb{R}^n \setminus \{\mathbf 0\} .$$ Because $\mathbf w=\mathbf 0$ means $||\mathbf w||=0$ which is ruled out because $||\mathbf w||=1.$	Definición de la norma de matriz inducida	Me estoy confundindo entre 2 variantes de definición de la norma de matriz inducida. Dado una norma $||\cdot||$ en $\mathbb{R}^n$, la norma de matriz inducida se define por $$ \left\lVertVertVertVert A \right\rVert = \max_{\mathbf v\not =0}VertVert \frac{\left\lVert A\mathbf v \right\rVert}{\left\Vert\l\l\mathbf v \right\rVert} \qquad para \quad A \mathbbf {\mathbf}{\mathb}{\mathb}{\mathb}{\mathb}{\mathn}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}{\mathb}}{\mathb}{\mathb}{\mathb}{\mathb}{mathb}{mathb}{mathb}}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}{mathb}}{mathb}{mathb}{mathb}{mathb}}{mathb}}{mathb}{mathb}{mathb}{mathb}{mathb}}{mathb}{mathb}}{mathb}{mathb}}{mathb}{mathb}}{mathb}}{mathb}{mathb}}{mathb}{mathb}{mathb}}}{mathb}{mathb}}{mathb}{mathb}}{mathb}{mathb}}{mathb}{mathb}{mathb}}}{mathb}{mathb}}}{mathb}{mathb}{mathb}{mathb}}}{mathb}}{mathb}{mathb}{mathb}}{mathb}}{math}{math}}{mathb}}{math}{math}}}{mathb}{math}}{mathb}{math}}{math}{math}{math}}{math}}{math}{math}}}{math}{math}{math}}{math}}{math}{math}{math}}{math}{math}}{math}{math}}}{math}{math}}{math}{math}{math}}}}}{math}{math}{math}}}}{math}{math}{math}{math}}}{math}{math}{math}{math}}{math}{math}{math}}}{math}{math}}}{math}{math}}{math}{math}}}}{math}{math}{math}{math}}{math}{math}}}{math}{math}{math}{math}{math}{math}}}}{math}}}{math}{math}}{math}{math}}}}{math}{math}{math}{math}{math}}}{math}{math}{math}{math}}}}{math}}}}}{math}{math}{math}{math}}}{math}{math}}{math}{math}}}{math}{math}}}{math}{math}{math}}}}{math}{math}{math}{math}{math}}}{math}{math}{math}{math}}}}{math}{math}}}{math}}}{math}{math}{math}{math}{math}}}}}{{math}}}{3}{math}}}{3}{math}}{math}{{{{{{math}}}}}}}}}}}}	definition,norm
A.233	Motivation for defining tangent vectors with derivations and why they should act on $f\in C^\infty(M)$	I'm revisiting the definition for tangent spaces in Lee's Introduction to Smooth Manifolds and I'm trying to convince myself why we might define tangent vectors as derivations at a point $p\in M$:  Let $M$ be a smooth manifold, and let $p\in M$. A linear map $v:C^\infty(M)\to \mathbb{R}$ is called a derivation at $p$ if \begin{align*} v(fg) = f(p)vg + g(p)vf \end{align*} for all $f,g\in C^\infty(M)$.  So far, I know that if $M=\mathbb{R}^n$, then each derivation can be given as a directional derivative in some direction in $\mathbb{R}^n$. After reading the parts on the differential and its computation in coordinates, I'm still wondering why we would be interested in defining a tangent vector as a map that acts on functions on the manifold and the benefits from acting on smooth functions. The main reason that I can think of is that the collection of derivations at a point forms a vector space, which is we what want for a tangent space. I have also looked at the approach of defining tangent vectors with equivalence classes of curves, but it seems that there's also an action on $f\in C^\infty(M)$ going on; we call curves $\gamma:J\to M$ the tangent vectors, and they have a directional-derivative-like operators that act on $f\in C^\infty(M)$ by \begin{align*} \left.\frac{d}{dt}(f\circ \gamma)(t)\right|_{t=0}. \end{align*} This seems really similar to how a vector in $\mathbb{R}^n$ defines its own directional derivative, but again, I'm not sure why the action on $f\in C^\infty(M)$ would be useful/significant.	Motivación para definir vectores tangentes con derivadas y por qué deberían actuar sobre $f\in C^\infty(M)$	Estoy revisando la definición de espacios tangentes en la Introducción de Lee a Maniflitos Limos y estoy tratando de convencerme de por qué podríamos definir vectores tangentes como derivadas en un punto $p\in M$: Dejemos que $M$ sea un varietal liso, y dejemos que $p\in M$. Un mapa lineal $v:C^\infty(M)\to \mathbb{R}$ se llama una derivación en $p$ si \begin{align*} v(fg) = f(p) vg + g) p) vf \end{align*} para todos los $f,g\in C^\infty(M)$. Hasta ahora, sé que si $M=\mathbb{R}^n$, entonces cada derivado tangente puede ser dado como una derivación direccional en algún punto $\mathbb{R}^n$. Después de leer las partes sobre la colección tangente y su cálculo en coordenadas tangentes, estoy preguntando por qué todavía estaríamos interesados en definir una derivación tangente como una colección tangente que actúa en la dirección de las funciones tangentes y que actúa en la dirección de la función tangente.	differential-geometry,differential-topology,smooth-manifolds,tangent-spaces
A.234	Sards theorem for polynomial	I'm having some struggles with an aspect about something apparently trivial about Sard's theorem, but couldn't find anything online. Let $f$ be a polynomial. According to Sard's theorem, the image $f(Z)$ of the set of critical values  $$Z = \{a \in X : f'(a) = 0\}$$ has measure zero. What if I want to show that the set $Z$ itself has measure zero in the domain of $f$? I feel like it's so simple but i just can't get behind it.	Teorema de Sards para el polinomio	Estoy teniendo algunas luchas con un aspecto sobre algo aparentemente trivial sobre el teorema de Sard, pero no pude encontrar nada en línea. Vamos a $f$ ser un polinomio. Según el teorema de Sard, la imagen $f(Z)$ del conjunto de valores críticos $$Z = \{a \in X : f'(a) = 0\}$$ tiene medida cero. ¿Qué pasa si quiero mostrar que el conjunto $Z$ en sí mismo tiene medida cero en el dominio de $f$?	differential-topology
A.235	Method for solving Diophantine equation $ax^2 + bx + c = y^2$	How do I solve the Diophantine equation $ax^2 + bx + c = y^2$? The approach I have so far is to use the transformation $X = 2ax + b$ and $Y = 2y$. Applying this, we get, $X^2 - dY^2 = n$, where $n = b^2 - 4ac$ and $d = a$. $X^2 - dY^2 = n$ is a Pell equation. Questions:  Is there any other method? What is the complexity of the algorithm for finding the solution to the Pell equation?	Método para resolver la ecuación diofantina $ax^2 + bx + c = y^2$	¿Cómo resolver la ecuación de Diofantino $ax^2 + bx + c = y^2$? El enfoque que tengo hasta ahora es usar la transformación $X = 2ax + b$ y $Y = 2y$. Aplicando esto, obtenemos, $X^2 - dY^2 = n$, donde $n = b^2 - 4ac$ y $d = a$. $X^2 - dY^2 = n$ es una ecuación de Pell. Preguntas: ¿Existe algún otro método? ¿Cuál es la complejidad del algoritmo para encontrar la solución a la ecuación de Pell?	diophantine-equations,computational-complexity,pell-type-equations
A.236	Normalizing constant in Dirichlet distribution	According to references (e.g. Wikipedia and elsewhere), the Dirichlet distribution, parametrized by $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$, is $$ D(x_1, \ldots, x_K) = \frac{1}{\mathrm{B}(\boldsymbol\alpha)} \prod_{i=1}^K x_i^{\alpha_i - 1} $$ where $$ \mathrm{B}(\boldsymbol\alpha) = \frac{\prod_{i=1}^K \Gamma(\alpha_i)}{\Gamma\left(\sum_{i=1}^K \alpha_i\right)}. $$ So, if $K = 2$ and $\alpha_1 = \alpha_2 = 1$ then this gives $ D(x_1, x_2) = 1/\mathrm{B(\boldsymbol\alpha)} $ where $$ \mathrm{B}(\boldsymbol\alpha) = \Gamma(1)^2 / \Gamma(2) = 1 $$ so, $D(x_1, x_2) = 1$ for all $x_1, x_2$.  However, $D(x_1, x_2)$ is defined on the standard $1$-simplex defined in $R^2$ by $x_i \ge 0$ and $x_1 + x_2 = 1$.  This is the span (or affine hull) of the two points $(0, 1)$ and $(1, 0)$.  Since this is a line segment of length $\sqrt{2}$, the integral of the Dirichlet distribution over this simplex is $\sqrt{2}$, not $1$ as expected.  What am I missing here? The same problem comes in higher dimensions.  For instance, for $K=3$, the simplex is a triangle with side $\sqrt{2}$, but the normalization constant becomes $B(\boldsymbol\alpha) = 1/\Gamma(3) = 1/2$, which is not the area of this triangle. What is wrong here?	Normal de la constante en la distribución de Dirichlet	Según referencias (por ejemplo, Wikipedia y en otros lugares), la distribución de Dirichlet, parametrizada por $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$, es $$ D(x_1, \ldots, x_K) = \frac{1}{\mathrm{B}(\boldsymbol\alpha)} \prod_{i=1}^K x_i^{\alpha_i - 1} $$ donde $$ \mathrm{B}\boldsymbol\alpha) = \frac{\prod_{i=1}^K \Gamma\alpha_i)}{\Gamma\le\\{i=1}{Kamma\i_i\right}}.{2} Así que si $K = 2$} y $\alpha_1 = \alpha_2 = 1${4} dan esta suma, sin embargo, ¿Cuál es el tamaño normal de $ D(x_1, x_2) = 1/\mathrm{B(\boldsymbol\alpha)} $ donde $$\m\bolds\bolds\bolds\bolds\bolds\bolds\bolds\b} {\displaystyle $$}\blast} (excepto $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast}) porque esta distribución no está definida aquí como una constante para el triángulo $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast1\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\b\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast\b\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\blast1\blast1\blast1\blast} $\boldsymbol{\alpha}=(\alpha_1,\ldots,\alpha_K)$\b\blast\b\blast\blast\b\blast\b\b\blast\blast\b\blast\b\b\blast\b\b\blast\b\b\b\b\blast\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\b\b\b\r\r\r\b\r\r\b\b\b\b\b\b\b\r\r\b\b\b\b\b\r\b\b\b\b\b\b\r\b\b\r\r\r\b\b\b\r\b\b\r\b\b\b\r\b\b\r\b\b\r\r\b\b\b\b\b\b\r\b\b\b\r\b\b\b\r\b\b\b\b\r\b\b\b\r\r\b\r\b\b\r\r\r\b\r\b\b\b\r\b\b\b\b\b\b\r\r\r\b\r\b\b\b\r\r\r\r\b\b\b\r\r\b\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\b\r\r\r\r\r\r\r\b\b\r\r\r\r\b\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r\r	dirichlet-series
A.237	Rewrite the propositions without implication	I want to rewrite the following types of propositions without the simple or double implication:  $p \land \lnot q \to r$ $p \land \lnot q \to r \land q$ $(p \to r) \leftrightarrow (q \to r)$  So we have to write these propositions without any implication, for example the first proposition like $p \land \lnot q \land r$ or is something else meant?	Reescribir las propuestas sin implicaciones	Quiero reescribir los siguientes tipos de proposiciones sin la implicación simple o doble: $p \land \lnot q \to r$ $p \land \lnot q \to r \land q$ $(p \to r) \leftrightarrow (q \to r)$ Así que tenemos que escribir estas proposiciones sin ninguna implicación, por ejemplo la primera proposición como $p \land \lnot q \land r$ o se quiere decir algo más?	discrete-mathematics,logic
A.238	Definition of Equivalence Relation	I was going through the text "Discrete Mathematics and its Application" by Kenneth Rosen (5th Edition) where I am across the definition of equivalence relation and felt that it is one sided.  Definition: A relation on a set A is called an equivalence relation if it is reflexive, symmetric, and transitive.  Now let us analyze the situation of what equivalence is meant to us intuitively. Let there be a binary relation $R$ defined on a set $A$. Now we suppose that $R$ be reflexive, symmetric and transitive. So we have for $a,b,c \in A$   $a R a$ (by the reflexive property of R) if $a R b$ then $b R a$  (by the symmetric property of R) if $a R b$ and $b R c$ then $aRc$ (by the transitive property of R)  Intuitively we can satisfy ourselves with the fact that the above are the necessary conditions for $R$ to be equivalent. So "if $R$ is reflexive, symmetric and transitive, then $R$ is an equivalence relation" Now working our intuition for equivalence relation $\sim$ we note the following. Let $\sim$ be an equivalence relation on a set A, then for $a,b,c \in A$ we have,  $a \sim a$ (by the intuitive knowledge of what $\sim$ means) if $a\sim b$ then $b \sim a$ (by the intuitive knowledge of what $\sim$ means) if $a\sim b$ and $b \sim c$ then $a\sim c$ (by the intuitive knowledge of what $\sim$ means)  Now we see that (1) implies $\sim$ is reflexive, (2) implies that $\sim$ is symmetric and (3) implies that $\sim$ is transitive. So we have "if $\sim$ is an equivalent relation then $\sim$ is reflexive, symmetric and transitive" From the two intuitive implications we can conclude that A relation on a set A is called an equivalence relation if and only if it is reflexive, symmetric, and transitive. and not what the book says. This definition makes quite sense unlike the book definition which says that if $R$ fails to be either reflexive or symmetric or transitive then $R$ may or may not be an equivalence relation, which after all gives a weird feeling. Correct me if my logic is wrong.	Definición de la relación de equivalencia	Estaba pasando por el texto "Matemáticas discretas y su aplicación" de Kenneth Rosen (5a edición) donde estoy en la definición de relación de equivalencia y sentí que es unilateral. Definición: Una relación en un conjunto A se llama relación de equivalencia si es reflexiva, simétrica y transitiva. Ahora analicemos la situación de lo que significa equivalencia para nosotros intuitivamente. Hay una relación binaria $R$ definida en un conjunto $A$. Ahora supongamos que $R$ sea reflexiva, simétrica y transitiva. Así que si tenemos para $a,b,c \in A$ $a R a$ (por la propiedad reflexiva de R) si $a R b$ entonces $b R a$ (por la propiedad reflexiva de R) si $a R b$ y $b R c$ entonces $aRc$ (por la propiedad transitiva de R) entonces transitivamente podemos satisfacer intuitivamente con el conocimiento de lo que significa que la relación de equivalencia es necesaria para un conjunto de relaciones de equivalencia. Así que si tenemos la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación entre el sentido de $\sim$ y el sentido de la relación de la relación de la relación de la relación de la relación, entonces podemos decir que si tenemos una relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación entre el sentido de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación entre el sentido de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación entre el sentido de la relación de la relación de la relación de la relación de la relación entre el sentido de la relación de la relación de la relación de la relación de la relación entre el sentido de la relación de la relación de la relación de la relación de la relación entre el sentido de la relación de la relación de la relación de la relación entre el sentido de la relación de la relación de la relación de la relación de la relación de la relación entre el sentido, entonces de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación entre el sentido de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación entre el sentido de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación entre el sentido, así del sentido, así como el sentido, así como la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación de la relación con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido con el sentido de la relación de la relación de la relación de la relación de la	discrete-mathematics,elementary-set-theory,proof-writing,definition,relations
A.239	Fake proof, symmetric and transitive relation is already reflexive	Let $R$ be a symmetric, transitive relation. If $(x, y) \in R$ then the symmetric property implies that $(y, x) \in R$. Using the the transitive property upon $(x, y)$ and $(y, x)$ we can conclude $(x, x) \in R$. Is this fair logic or is it flawed?	La prueba falsa, la relación simétrica y transitiva ya es reflexiva	Si $R$ es una relación simétrica, transitiva. si $(x, y) \in R$ entonces la propiedad simétrica implica que $(y, x) \in R$. usando la propiedad transitiva sobre $(x, y)$ y $(y, x)$ podemos concluir $(x, x) \in R$. ¿Es esta lógica justa o es defectuosa?	discrete-mathematics,relations,fake-proofs
A.240	What do the constants "4" and "2" in Bhaskara mean and where did they come from?	In bhaskar, the way to get the result, is to get the $\Delta  = b^2 – 4ac$, and then the $X = (–b \pm \sqrt\Delta)/2a)$. But from where come these constants?	¿Qué significan las constantes "4" y "2" en Bhaskara y de dónde provienen?	En bhaskar, la forma de obtener el resultado es obtener el $\Delta  = b^2 – 4ac$, y luego el $X = (–b \pm \sqrt\Delta)/2a)$. Pero ¿de dónde vienen estas constantes?	education
A.241	Divisibility of $n^3 +6n^2-7n$	Let $n = 2, 3, 4, ...$ be an integer. Show that $n^3 +6n^2-7n$ is divisible by $6$.  How should one approach this? Using modular arithmetic or some other approach?	División de la $n^3 +6n^2-7n$	Si el número $n = 2, 3, 4, ...$ es un número entero, muestra que el número $n^3 +6n^2-7n$ es divisible por el número $6$. ¿Cómo se debe abordar esto?	elementary-number-theory
A.242	Show that for all prime numbers $p$ greater than $3$, $24$ divides $p^2-1$ evenly.	Show that for all prime numbers $p$ greater than $3$, $24$ divides $p^2-1$ evenly.  Since $(p+1)(p-1) = p^2-1$ we have that $\frac{(p+1)(p-1)}{24}=k$, where $k \in \Bbb Z.$ Now since $24 = 2^3 \cdot 3$ and the numerator contains always at least one even factor(?) we have that $24=2^3\cdot3\vert(p+1)(p-1).$ Is my reasoning here correct or am I missing something here?	Muestre que para todos los números primos $p$ mayor que $3$, $24$ divide $p^2-1$ de manera uniforme.	Muestre que para todos los números primos $p$ mayor que $3$, $24$ divide $p^2-1$ de manera uniforme.	elementary-number-theory
A.243	If $2^{2k}-x^2\bigm|2^{2k}-1$ then $x=1$	This is the $y=2^k$ case of this question. Suppose that $k\geq1$ and $0 and $2^{2k}-x^2\bigm|2^{2k}-1$. Is it necessarily the case that $x=1$? Equivalently: Suppose that there are two positive divisors of $2^{2k}-1$ which average to $2^k$. Is it necessarily the case that these two divisors are $2^k-1$ and $2^k+1$?	Si $2^{2k}-x^2\bigm|2^{2k}-1$ entonces $x=1$	Este es el caso $y=2^k$ de esta pregunta. Supongamos que $k\geq1$ y $0 and $2^{2k}-x^2\bigm d2^{2k}-1$. Is it necessarily the case that $x=1$? Equivalently: Suppose that there are two positive divisors of $2^{2k}-1$ which average to $2^k$. Is it necessarily the case that these two divisors are $2^k-1$ and $2^k+1$?	elementary-number-theory,divisibility
A.244	Compute the Cardinality of a quotient set	Let $R$ be a an Equivalence relation on $\Bbb{R}$ defined by: $$aRb \Leftrightarrow (a-b)\in \Bbb{Z}$$ What is the cardinality of $|\Bbb{R}/R|$?   where $\Bbb{R}/R$ is the quotient set of $\Bbb{R}$ under $R$.	Calcule la cardinalidad de un conjunto de cuotientes	Que $R$ sea una relación de equivalencia en $\Bbb{R}$ definida por: $$aRb \arrow (a-b) \in \Bbb{Z}$$ ¿Cuál es la cardinalidad de $|\Bbb{R}/R|$? donde $\Bbb{R}/R$ es el conjunto de cuotientes de $\Bbb{R}$ bajo $R$.	elementary-set-theory
A.245	Is there a known set of closed form solutions to the functional equation f(f(z)) = sin z?	That is $$ f(f(z)) = \sin z $$ where $$ z \in \mathbb{Z} $$	¿Existe un conjunto conocido de soluciones de forma cerrada a la ecuación funcional f ((f ((z)) = sin z?	Eso es $$ f(f(z)) = \sin z $$ donde $$ z \in \mathbb{Z} $$	functional-equations
A.246	Finding $n$ such that in a regular $n$-gon $A_1A_2\ldots A_n$ we have $\frac1{A_1A_2}=\frac1{A_1A_3}+\frac1{A_1A_4}$	INMO '92 Question 9:  Find $n$ such that in a regular $n$-gon $A_1A_2 ...A_n$ we have $$\frac{1}{A_1A_2}=\frac{1}{A_1A_3}+\frac{1}{A_1A_4}$$  I tried the following Assume it is inscribed in a circle. Then length of chord is $2\sin(\theta)$ where $\theta$ is half the angle subtended at the center between consecutive points. So, $\theta=\frac{180^\circ}{n}$. Then we get $$\csc(\theta)=\csc(2\theta)+\csc(3\theta)$$ Not sure quite how to proceed from there- using double and triple angle formulae doesn't seem to work	Encontrando $n$ tal que en un regular $n$-gon $A_1A_2\ldots A_n$ tenemos $\frac1{A_1A_2}=\frac1{A_1A_3}+\frac1{A_1A_4}$	INMO '92 Pregunta 9: Encontrar $n$ tal que en un regular $n$-gon $A_1A_2 ...A_n$ tenemos $$\frac{1}{A_1A_2}=\frac{1}{A_1A_3}+\frac{1}{A_1A_4}$$ Intenté lo siguiente Supongamos que está inscrito en un círculo. Entonces la longitud del acorde es $2\sin(\theta)$ donde $\theta$ es la mitad del ángulo subtendido en el centro entre puntos consecutivos. Así que, $\theta=\frac{180^\circ}{n}$. Entonces obtenemos $$\csc\theta) =\cscc\2\theta) +\csc\3\theta)$$ No estoy seguro de cómo proceder de allí- usando la fórmula de ángulo doble y triplee no parece funcionar	geometry,trigonometry,contest-math,polygons
A.247	Finding the endpoints of the maximal arc of circle $x^2+(y-8)^2=25$ visible from $(0,-5)$.	The equation of circle $C$ is $x^2 + (y − 8)^2 = 25$. The eye is located at $E = (0, −5)$. The maximal circular arc visible to the eye is $AB$, which is then being projected on to the one-dimensional "screen" as $A'B'$. What are the co-ordinates of points $A$ and $B$?  I came this far: point $P$ on circle $C$ has the coordinates $x = 5 \cos\theta$, $y = 8 + 5 \sin \theta$. Now I should use this to find points $A$ and $B$, but I don't know how to proceed.	Encontrar los puntos finales del arco máximo del círculo $x^2+(y-8)^2=25$ visible desde el $(0,-5)$.	La ecuación del círculo $C$ es $x^2 + (y − 8)^2 = 25$. El ojo se encuentra en $E = (0, −5)$. El arco circular máximo visible al ojo es $AB$, que luego se proyecta en la pantalla unidimensional como $A'B'$. ¿Cuáles son las coordenadas de los puntos $A$ y $B$?	geometry,analytic-geometry
A.248	product of elements $\ne e$ implies only one element with order $2$	Let $G$ be an abelian group with even order and $M:=\{g\in G:g^2=e\}$. It is easy to show that $M$ is a sugroup of $G$ and the number of elements of $M$ must be a power of $2$.  I want to prove that the product of the elements of $G$ (which in this case is equal to the product of the elements of $M$) is not the identity element $e$, if and only if #$M=2$ (this means that there is only one element with order $2$). I found this claim when I studied the Wilson criterion for the primality of a number.  The case #$M=4$ is easy. If $a,b\in M$, we can show that $ab$ is not $a,b,e$, hence must be some other element $c$ and we get $abc=c^2=e$. But what about #$M=8$? If we have the elements $e,a,b,c,d,f,g,h$ and $ab=c$ and $df=g$, the product would be $h$ which is impossible considering my claim.  Who can complete my proof ?	producto de elementos $\ne e$ implica sólo un elemento con orden $2$	Si $G$ es un grupo abeliano con orden par y $M:=\{g\in G:g^2=e\}$. Es fácil demostrar que $M$ es un sugroup de $G$ y el número de elementos de $M$ debe ser una potencia de $2$. Quiero demostrar que el producto de los elementos de $G$ (que en este caso es igual al producto de los elementos de $M$) no es el elemento de identidad $e$, si y sólo si #$M=2$ (esto significa que sólo hay un elemento con orden $2$). Encontré esta afirmación cuando estudié el criterio de Wilson para la primalidad de un número. Si el caso #$M=4$ es fácil. $a,b\in M$, podemos demostrar que $ab$ no es $G$0, por lo tanto debe ser algún otro elemento $G$1 y obtenemos $G$2. Pero ¿qué pasa con #$G$3?	group-theory,finite-groups
A.249	An abelian group proof with $g*g=e$ for all $g$.	I have to show that the following group $$ (G, * , e) $$ with its operation $*$, which is defined through $ g*g = e$  for every $g \in G $ is an abelian group. In order to do that one have only to show that the group is commutative. How can one prove it whereas the operation is defined always between an Element and itself? I reckon it is not so simple as it seems Thanks in advance for your help :)	Una prueba de grupo abeliano con $g*g=e$ para todos los $g$.	Tengo que demostrar que el siguiente grupo $$ (G, * , e) $$ con su operación $*$, que se define a través de $ g*g = e$ para cada $g \in G $ es un grupo abeliano. Para hacer eso uno sólo tiene que demostrar que el grupo es commutativo. ¿Cómo se puede demostrar que la operación se define siempre entre un elemento y sí mismo?	group-theory,abelian-groups,monoid
A.250	How to show $(a_1a_2\ldots a_n)^{\frac{1}{n}}\leq \frac{\sum_{i=1}^{n}a_i}{n}$	How to show $(a_1a_2\ldots a_n)^{\frac{1}{n}}\leq \frac{\sum_{i=1}^{n}a_i}{n}$ with $a_i$ positive. Well, I tried by induction: with $n=2$ then $\sqrt{ab}\leq \frac{a+b}{2}$ is equivalent to say (elevate square in both side) $4ab\leq a^2 +2ab + b^2$ and this is equivalent $0\leq(a-b)^2$ and this is true. I suppose it is true for some $n$. But with $n+1$, I don't know how to do, Please can help me with a hint or other way, thank you so much.	Cómo mostrar $(a_1a_2\ldots a_n)^{\frac{1}{n}}\leq \frac{\sum_{i=1}^{n}a_i}{n}$	¿Cómo mostrar $(a_1a_2\ldots a_n)^{\frac{1}{n}}\leq \frac{\sum_{i=1}^{n}a_i}{n}$ con $a_i$ positivo? Bueno, lo intenté por inducción: con $n=2$ entonces $\sqrt{ab}\leq \frac{a+b}{2}$ es equivalente a decir (elevar cuadrado en ambos lados) $4ab\leq a^2 +2ab + b^2$ y esto es equivalente a $0\leq(a-b)^2$ y esto es cierto. Supongo que es cierto para algunos $n$. Pero con $n+1$, no sé cómo hacer, por favor puede ayudarme con una pista u otra manera, muchas gracias.	inequality,a.m.-g.m.-inequality
A.251	How to prove that $(k+1)^{\frac{1}{k+1}} < k^{\frac{1}{k}} (k >= 3)$ using mathematical induction?	I've been trying to solve this for hours, but I just can't seem to do it. And yes, I know I have to show that $(k+2)^{\frac{1}{k+2}} < ... < (k + 1)^{\frac{1}{k+1}}$ from the starting assumption that $(k+1)^{\frac{1}{k+1}} < k^{\frac{1}{k}}$. Any hints would be highly welcome.	¿Cómo probar que $(k+1)^{\frac{1}{k+1}} < k^{\frac{1}{k}} (k >= 3)$ usando inducción matemática?	He estado tratando de resolver esto durante horas, pero no puedo hacerlo. Y sí, sé que tengo que mostrar que $(k+2)^{\frac{1}{k+2}} < ... < (k + 1)^{\frac{1}{k+1}}$ desde el supuesto inicial que $(k+1)^{\frac{1}{k+1}} < k^{\frac{1}{k}}$. Cualquier sugerencia sería muy bienvenida.	inequality,induction
A.252	Unexpected appearances of $\pi^2 /~6$.	"The number $\frac 16 \pi^2$ turns up surprisingly often and frequently in unexpected places." - Julian Havil, Gamma: Exploring Euler's Constant.   It is well-known, especially in 'pop math,' that $$\zeta(2)=\frac1{1^2}+\frac1{2^2}+\frac1{3^2}+\cdots = \frac{\pi^2}{6}.$$ Euler's proof of which is quite nice. I would like to know where else this constant appears non-trivially. This is a bit broad, so here are the specifics of my question:  We can fiddle with the zeta function at arbitrary even integer values to eek out a $\zeta(2)$. I would consider these 'appearances' of $\frac 16 \pi^2$ to be redundant and ask that they not be mentioned unless you have some wickedly compelling reason to include it. By 'non-trivially,' I mean that I do not want converging series, integrals, etc. where it is obvious that $c\pi$ or $c\pi^2$ with $c \in \mathbb{Q}$ can simply be 'factored out' in some way such that it looks like $c\pi^2$ was included after-the-fact so that said series, integral, etc. would equal $\frac 16 \pi^2$. For instance, $\sum \frac{\pi^2}{6\cdot2^n} = \frac 16 \pi^2$, but clearly the appearance of $\frac 16\pi^2$ here is contrived. (But, if you have an answer that seems very interesting but you're unsure if it fits the 'non-trivial' bill, keep in mind that nobody will actually stop you from posting it.)  I hope this is specific enough. This was my attempt at formally saying 'I want to see all the interesting ways we can make $\frac 16 \pi^2$.' With all that being said, I will give my favorite example as an answer below! :$)$  There used to be a chunk of text explaining why this question should be reopened here. It was reopened, so I removed it.	Apariciones inesperadas de $\pi^2 /~6$.	"El número $\frac 16 \pi^2$ aparece sorprendentemente a menudo y con frecuencia en lugares inesperados". - Julian Havil, Gamma: Explorando la constante de Euler. Me gustaría saber dónde más esta constante aparece no trivial. Esto es un amplio, así que aquí están los detalles de mi pregunta: podemos llenar la función zeta aberta a valores enteros arbitrarios para hacer una reapertura interesante.	integration,sequences-and-series,riemann-zeta,big-list,pi
A.253	How would I show the result below using contour integration?	How would I show the result below using contour integration? $$\int_{-\infty}^{\infty} \frac{\cos bx - \cos ax}{x^2} dx = \pi (a-b)$$ where a>b>0 using contour integration. Any help would be greatly appreciated, thanks!	¿Cómo mostrar el resultado de abajo usando la integración de contornos?	¿Cómo mostraría el resultado a continuación usando la integración de contornos? $$\int_{-\infty}^{\infty} \frac{\cos bx - \cos ax}{x^2} dx = \pi (a-b)$$ donde a>b>0 usando la integración de contornos. Cualquier ayuda sería muy apreciada, gracias!	integration,complex-analysis,trigonometry,fourier-analysis,contour-integration
A.254	Integration question hard	Can I get some hints on how to solve this integral? $$ I=\int_0^\pi \frac{x \ dx}{1-sinx \ cosx} $$	La cuestión de la integración es difícil	¿Puedo obtener algunas sugerencias sobre cómo resolver esta integral? $$ I=\int_0^\pi \frac{x \ dx}{1-sinx \ cosx} $$	integration,definite-integrals
A.255	Integral of $e^{-\frac{u^2}{2}}$	This is the first time I came across the problem of finding integral of $\propto$. I have a joint distribution $$f_{X,Y}(x,y) \propto \exp\left(13xy - 94x^2 - \frac{1}{2}y^2\right)$$  where $ -\infty< x <\infty, -\infty< y <\infty $ I attempted to find $f_X(x)$ as follows:  \begin{align*} f_X(x) &\propto \int_{-\infty}^\infty e^{13xy - 94x^2 - \frac{1}{2}y^2}{\rm d}y\\ &\propto \int_{-\infty}^\infty e^{-\frac{1}{2}(y - 13x)^2 - \frac{19x^2}{2}}{\rm d}y\\ &\propto \frac{1}{e^{\frac{19x^2}{2}}} \int_{-\infty}^\infty e^{-\frac{u^2}{2}}{\rm d}u \end{align*} where $ u = (y - 13x)^2 $ Similarly, I derived $$ f_Y(y) \propto \frac{1}{e^{\frac{19x^2}{376}}} \int_{-\infty}^\infty e^{-u^2}{\rm d}u $$ where $ u = \sqrt{94}x - \frac{13y}{2\sqrt{94}} $ Could you please show me how to proceed to the destination solutions? Thanks in advance.	Integral de la $e^{-\frac{u^2}{2}}$	Esta es la primera vez que me encontré con el problema de encontrar la integral de $\propto$. Tengo una distribución conjunta $$f_{X,Y}x,y) \propto \exp\left(13xy - 94x^2 - \frac{1}{2}y^2\right) $$ donde $ -\infty< x <\infty, -\infty< y <\infty $ Intenté encontrar $f_X(x)$ de la siguiente manera: \begin{align*} f_X(x) &\propto \int_{-\infty}^\\infty e^13xy - 94x^2 - \frac{2}{2}y^2}{\rm d}y\\ &\propto \int_{2}^5}\infty e\frac{1}{2} d2}y - 13x^2} - \19x\infinch\infinch\infinch\infinch\infinch\infinch\infinch\infinch\infinch\infinch\infinch\infinch\in}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}{3}}{3}{3}}{3}{3}{3}{3}}}}{3}}}{3}{3}{3}{3}}{3}{3}}{3}{3}{3}}}}{3}{3}{3}{3}{3}{3}{3}}{3}}{3}}}}{3}3}{3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3}3	integration,probability-distributions,definite-integrals
A.256	Why do we have to factorize the function before taking its limit	I am learning about limits and there is something that I cant quite understand: If we have the function:  $$ f(x) =\frac{x^2-1}{x-1} $$  Let's say that we want to see which value for y (image) the function approaches as x (domain) gets closer to 1. On a nutshell, we have to take this following limit:  $$ \lim_{x\to1}\frac{x^2-1}{x-1} $$  As soon as we look to this function, we realize that the function is not continuous at x = 1 (By the way, can I say that?).  I know the algorithm to figure out the solution of the limit: First, there is the need of eliminating the function discontinuity. Usually, it is just a matter of factorizing the function into a new function which the exactly same image as the one before with one crucial difference: The function is continuous for all real numbers  My doubts:Is my way to think about it correct? Can I think like that? Take the example above:    $$ f(x) = \frac{x^2-1}{x-1} $$  After factorizing, we get: $$ f(x) = {x+1} $$ If we plot both functions, they are the same, although the second one has its continuity all along the real numbers domain Thanks in advance	¿Por qué tenemos que factorizar la función antes de tomar su límite	Estoy aprendiendo sobre límites y hay algo que no entiendo muy bien: si tenemos la función: $$ f(x) =\frac{x^2-1}{x-1} $$ Digamos que queremos ver qué valor de y (imagen) la función se acerca a la medida que x (dominio) se acerca a 1. En pocas palabras, tenemos que tomar este límite: $$ \lim_{x\to1}\frac{x^2-1}{x-1} $$ Tan pronto como miramos a esta función, nos damos cuenta de que la función no es continua en x = 1 (por cierto, puedo decir eso?). Sé el algoritmo para encontrar la solución del límite: primero, es la necesidad de eliminar la discontinuidad. Por lo general, es una cuestión de desglosar la función con la misma función que tiene la misma diferencia que la imagen real: XXx=1 {\displaystyle XXx=x} ¿Puedo pensar que, si tenemos un segundo número de la función con el mismo número de f f {\displaystyle XXx=x} ¿Puedo pensar que, por ejemplo, todos los números de la imagen real de la imagen anterior, XXx=x=x=x1 {\displaystyle XXx}	limits
A.257	Is "taking a limit" a function? Is it a procedure? A ternary operation?	I was sitting in analysis yesterday and, naturally, we took the limit of some expression. It occurred to me that "taking the limit" of some expression abides the rules of a linear transformation $$\lim_{x \rightarrow k}\ c(f(x)+g(x)) = c \lim_{x \rightarrow k} f(x) + c\ \lim_{x \rightarrow k} g(x),$$ and (my group theory is virtually non existent) appears also to be a homomorphism: $$\lim_{x \rightarrow k} (fg)(x) = \lim_{x \rightarrow k} f(x)g(x), $$ etc. Anyway, my real question is, what mathematical construct is the limit?	¿Es "tomar un límite" una función? ¿Es un procedimiento?	Estaba sentado en el análisis ayer y, naturalmente, tomamos el límite de alguna expresión. Me ocurrió que "tomar el límite" de alguna expresión se adhiere a las reglas de una transformación lineal $$\lim_{x \rightarrow k}\ c(f(x) + g(x)) = c \lim_{x \rightarrow k} f(x) + c\ \lim_{x \rightarrow k} g(x),$$ y (mi teoría de grupo es prácticamente inexistente) parece ser también un homomorfismo: $$\lim_{x \rightarrow k} (fg) x) = \lim_{x \rightarrow k} fx) g) x), etc.	limits,terminology
A.258	How to prove $\lim_{x \to \infty} \frac{x^k}{e^x}=0$ ? (k is any positive number)	Originally, i was trying to find the value of $$\lim_{h \to 0} \frac{e^{-\frac{1}{h^2}}}{h}$$ to find out differentiabiltiy of  $f(x) = \begin{cases} e^{-1/x^2} & \text{ if } x \ne 0 \\ 0 & \text{ if } x = 0 \end{cases}$  at 0. In this case,  $$\lim_{h \to 0} \frac{e^{-\frac{1}{h^2}}}{h}=\lim_{x \to \infty} \frac{x}{e^{x^2}}=\lim_{x \to -\infty} \frac{x}{e^{x^2}}$$ So when I applied L'Hospital's rule, then its value was 0. And I thought that No matter how big $k$ is,  $$\lim_{x \to \infty} \frac{x^k}{e^x}$$ will be equal to zero because exponential's increase speed is much faster than polynomial's. Definitely, we can also apply L'hospital's rule at here, but I think it is not proper qualitative explanation for the fact that exponential is much bigger than polynomial. Is there any other approach which explains why  about this problem? (In fact, I tried to use $\epsilon-\delta$ but how can i show that there exist some $M$ s.t. for every $M then  $x^k<\epsilon e^x$?) (And I also tried to use inequality like $e^x>x+1$  for all $x>0$ but it only worked for $k<1$)	¿ Cómo probar $\lim_{x \to \infty} \frac{x^k}{e^x}=0$ ? (k es cualquier número positivo)	Originalmente, estaba tratando de encontrar el valor de $$\lim_{h \to 0} \frac{e^{-\frac{1}{h^2}}}{h}$$ para averiguar la diferenciabilidad de $f(x) = \begin{cases} e^{-1/x^2} & \text{ if } x \ne 0 \\ 0 & \text{ if } x = 0 \end{cases}$ en 0. En este caso, $$\lim_{h \to 0} \frac{e^{-\frac{1}{h^2}}}{h}=\lim_{x \to \infty} \frac{x}{e^{x \to -\infty}{e^{\infty} \frac{x} {e^{x}{x}{x}{x}{x}{x}{x}}{x}{x}{x}}{x}{x}{x}{x}{x}{x}{x}{x}}{x}{x}{x}{x}}{x}{x}{x}}{x}{x}}{x}}{x}{x}}{x}{x}}{x}}{x}{x}}{x}{x}}{x}{x}}{x}{x}}{x}}{x}{x}}{x}}{x}{x}}{x}{x}}{x}{x}}{x}}{x}{x}}{x}}{x}}{x}{x}}{x}{x}}{x}{x}}{x}}{x}}{x}{x}}{x}{x}}{x}}{x}{x}{x}}{x}{x}}{x}{x}}{x}}{x}}{x}{x}}}{x}{x}{x}}{x}}{x}{x}}{x}{x}}{x}{x}}{x}{x}{x}}}{x}{x}{x}}{x}{x}{x}}{x}{x}}{x}}{x}}{x}}{x}{x}{x}}{x}{x}{x}}{x}{x}}{x}{x}}{x}{x}}}{x}{x}{x}{x}{x}}}{x}}{x}{x}{x}{x}{x}}{x}{x}{x}}{x}{x}{x}}{x}}{x}{x}{x}{x}}{x}{x}{x}{x}{x}{x}}{x}}}{x}{x}{x}{x}}{x}{x}}{x}{x}{x}{x}}}}{x}{x}{x}{x}}{x}{x}}{x}{x}{x}{x}{x}{x}{x}{x}}{x}{x}{x}{x}}}{x}{x}{x}{x}{x}{x}{x}}}{x}{x}{x}{x}{x}{x}{x}{x}{x}{x}{x}{x}}}}}{x}{x}{x}{x}{x}{x}{x}{x}}{x}{x}}}{x}{x}{x}{x}}{x}{x}}}{x}{x}}{x}{x}{x}{x}}}}{x}{x}{x}{x}{x}{x}{x}{x}{x}{x}{}{x}{}{}{x}}}{x}{x}{x}{x}{x}}}{x}{x}}{x}{x}}}{}{x}{x}{x}{x}}{}{x}{x}{x}{x}}}{x}}}}}{x}{x}	limits,derivatives,exponential-function,epsilon-delta,differential
A.259	Why does $n^c$ grow faster than $2^n$?	For every finite case, I can find a $c$ where $2^n = n^c$, so why is this true? $$\lim_{n \rightarrow \infty} \frac{2^n}{n^c} = 0$$ From the finite cases it seems like $2^n$ grows faster because we can find a $c$ to match it at any $n$.	¿Por qué el $n^c$ crece más rápido que el $2^n$?	Para cada caso finito, puedo encontrar un $c$ donde $2^n = n^c$, así que por qué es esto cierto? $$\lim_{n \rightarrow \infty} \frac{2^n}{n^c} = 0$$ De los casos finitos parece que $2^n$ crece más rápido porque podemos encontrar un $c$ para coincidir con él en cualquier $n$.	limits
A.260	limit with two variables	The limit I need to calculate is $\lim_{(x,y)\rightarrow (0,0)}\frac{xy^{2}}{x^{4}+y^{2}}$. Using polar coordinates I get: $lim_{r\rightarrow 0}\frac{r\cos(\theta)\sin^{2}(\theta)}{r^{2}\cos^{4}(\theta)+\sin^{2}(\theta)}$. Now if $\sin(\theta)\neq 0$ then the limit is $0$. How do I handle the case where $\theta=0$ or $\theta = \pi$? And is there a better way to approach this limit?	límite con dos variables	El límite que necesito calcular es $\lim_{(x,y)\rightarrow (0,0)}\frac{xy^{2}}{x^{4}+y^{2}}$. Usando las coordenadas polares obtengo: $lim_{r\rightarrow 0}\frac{r\cos(\theta)\sin^{2}(\theta)}{r^{2}\cos^{4}(\theta)+\sin^{2}(\theta)}$. Ahora si $\sin(\theta)\neq 0$ entonces el límite es $0$. ¿Cómo manejo el caso donde $\theta=0$ o $\theta = \pi$? ¿Y hay una mejor manera de acercarse a este límite?	limits,multivariable-calculus
A.261	Show that $\det(T_n)=\sum_{k=0}^{n}\alpha^{n-k}\beta^k$	Let the matrix $T_n\in M(n\times n,\mathbb{F})$, where $\mathbb{F}$ denotes a field, be defined by $T_n=(t_{ij})$ with $$t_{ij}= \begin{cases}        \alpha\beta &  1\leq i\leq n-1,\;j=i+1 \\       \alpha+\beta & 1\leq i\leq n,\; j=i \\       1 & 2\leq i\leq n,\; j=i-1 \\       0 &\textrm{otherwise}    \end{cases} $$ Show that  $$\det(T_n)=\sum_{k=0}^{n}\alpha^{n-k}\beta^k$$  My approach: I tried a proof via induction and while the basis step is trivial, I can't seem to solve the induction step since the matrix is never in upper or lower triangular form but always a block matrix, which makes this seemingly difficult as when calculating the determinant of block matrices, one usually calculates the product of all the "diagonal blocks". I would very much appreciate help, thank you very much.	Muéstrate eso $\det(T_n)=\sum_{k=0}^{n}\alpha^{n-k}\beta^k$	Dejemos que la matriz $T_n\in M(n\times n,\mathbb{F})$, donde $\mathbb{F}$ denota un campo, sea definida por $T_n=(t_{ij})$ con $$t_{ij}= \begin{cases} \alpha\beta & 1\leq i\leq n-1,\;j=i+1 \\ \alpha+\beta & 1\leq i\leq n,\; j=i \\ 1 & 2\leq i\leq n,\; j=i-1 \\ 0 & \textrm{otherwise} \end{cases} $$ Muestre que $$\det(T_n)=\diabeta_{k=0}^^{n}\alpha{n-k}\k$$ enfoque: Intenté una prueba por inducción y mientras que la base es siempre trivial, no puedo resolver el paso de inducción ya que el producto de la matriz generalmente es en forma de arriba o de abajo \text{extrm} $$ Muestra que $$\det) =\diabeta_{k=0}^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^	linear-algebra,matrices,induction,determinant
A.262	Positve part and negative part of a real number	Let $a$ be a real number . The positive part of $a$, denoted by $a^+$ is given by expression $$a^+ = \text{if } a\geq 0 \text{ then $a$ else } 0$$ The negative part of $a$, denoted by $a^-$ is given by expression $$a^- = \text{if } a\geq 0 \text{ then $0$ else } -a$$ Both $a^+$ and $a^-$  are non negative and the following relationship hold $$ a = a^+ - a^-$$ Above is the text from my compiler optimization book and I cannot understand the relationship explained. How can $a$ be a real number and have positive and negative parts?	Parte positiva y parte negativa de un número real	La parte positiva de $a$, denotada por $a^+$, es dada por la expresión $$a^+ = \text{if } a\geq 0 \text{then $a$ else } 0$$ La parte negativa de $a$, denotada por $a^-$ es dada por la expresión $$a^- = \text{if } a\geq 0 \text{then $0$ else } -a$$ Tanto $a^+$ como $a^-$ no son negativos y la siguiente relación tiene $$ a = a^+ - a^-$$	linear-programming
A.263	Formal relationship between rules of inference and the material conditional	I am not $100\%$ clear as to what constitutes the difference between a rule of inference and the material conditional, at least in classical logic. I am using the truth-functional definition of the material conditional, commonly visualised through its truth table, but I'm not entirely sure what the formal definition of a rule of inference is. The wikipedia article defines it to be a particular kind of logical form, which seems to be a term from philosophical logic that I'm not familiar with, but reading that article didn't really answer my question. It pertains more to the mathematical side of things, and I am specifically interested in the interplay between the concepts on the syntactic and semantic level. As far as I can tell, any rule of inference can be 'captured' by a corresponding material conditional: if we take modus ponens as a well-known example, what is the difference between $$(a\land (a\to b))\to b$$ and $${a\to b,\text{ } a \over b}?$$ On a functional level, both statements seem to be expressing the same thing. What determines the need to use two separate terms and notations, and what, if anything, separates them?	Relación formal entre las reglas de inferencia y la condición material	No estoy claro $100\%$ sobre lo que constituye la diferencia entre una regla de inferencia y la conditional material, al menos en la lógica clásica. Estoy usando la definición verdadero-funcional de la conditional material, comúnmente visualizada a través de su tabla de verdad, pero no estoy completamente seguro de cuál es la definición formal de una regla de inferencia. El artículo de Wikipedia la define como un tipo particular de forma lógica, que parece ser un término de lógica filosófica que no estoy familiarizado con, pero leer ese artículo no hizo realmente mi pregunta. Pertenece más a la respuesta al lado matemático de las cosas, y estoy específicamente interesado en la interacción entre los conceptos a nivel sintáctico y semántico. En la medida en que puedo, la regla de inferencia puede ser 'expresada' por un nivel conditional: ¿Qué se puede decir si tomamos un ejemplo de una cosa que corresponde a la misma función, si se utiliza un modelo a\a y b\a, b\a, b\a, b\a, b\a, b\a, b\a, b\a, b\a, b\a, b\a, b\a, b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b	logic,soft-question,formal-systems
A.264	Modulo Power Arithmetic	While performing some arithmetic operations, i am stuck at one point.I want to know is it possible to write ($a^b)\%p$ as ($a^{(b\%p)})\%p$?	Aritmética de la potencia de módulo	Mientras realizo algunas operaciones aritméticas, estoy atascado en un punto. Quiero saber si es posible escribir ($a^b)\%p$ como ($a^{(b\%p)})\%p$?	modular-arithmetic
A.265	How to show that $(a/b)^2$ in this situation cannot be an integer	Let $a$,$b$ be relatively prime integers which are both greater than or equal to $2$ . Show that $(a/b)^2$ cannot be an integer. I have tried to use contradiction to prove this result, but I am not sure that my idea is correct or not. Below is my idea (not a complete proof). Suppose $(a/b)^2$ be an integer. We have $a/b$ is an integer. Then, we have $a=bk$ where $k$ is an integer since $b$ divides $a$. Since $a,b$ are relatively prime, therefore $b$ must be $1$. Hence, contradiction arises. I am not sure that my idea is correct or not, could anyone help me to check it? If my idea is wrong, could you give me a idea to do this question?	¿Cómo demostrar que $(a/b)^2$ en esta situación no puede ser un número entero	Si tenemos $a$,$b$ como número entero, $a=bk$ es un número entero, pues $b$ divide $a$. Como $a,b$ es un número entero, por lo tanto $b$ debe ser $1$. Por lo tanto, surge una contradicción. No estoy seguro de si mi idea es correcta o no, ¿me puede ayudar alguien a comprobarla?	number-theory,gcd-and-lcm
A.266	What happens when we (incorrectly) make improper fractions proper again?	Many folks avoid the "mixed number" notation such as $4\frac{2}{3}$ due to its ambiguity. The example could mean "$4$ and two thirds", i.e. $4+\frac{2}{3}$, but one may also be tempted to multiply, resulting in $\frac{8}{3}$. My questions pertain to what happens when we iterate this process -- alternating between changing a fraction to a mixed number, then "incorrectly" multiplying the mixed fraction. The iteration terminates when you arrive at a proper fraction (numerator $\leq$ denominator) or an integer. I'll "define" this process via sufficiently-complicated example: $$\frac{14}{3} \rightarrow 4 \frac{2}{3} \rightarrow \frac{8}{3} \rightarrow 2 \frac{2}{3} \rightarrow \frac{4}{3} \rightarrow 1\frac{1}{3}\rightarrow \frac{1}{3}.$$  Does this process always terminate?  For which $(p,q)\in\mathbb{N}\times(\mathbb{N}\setminus\{0\})$ does this process, with initial iterate $\frac{p}{q}$, terminate at $\frac{p \mod q}{q}$?	¿Qué sucede cuando (incorrectamente) hacemos fracciones incorrectas correctas de nuevo?	Muchas personas evitan la notación de "número mixto" como $4\frac{2}{3}$ debido a su ambigüedad. El ejemplo podría significar "$4$ y dos tercios", es decir, $4+\frac{2}{3}$, pero también se puede ser tentado a multiplicar, lo que resulta en $\frac{8}{3}$. Mis preguntas se refieren a lo que sucede cuando iteramos este proceso - alternando entre cambiar una fracción a un número mixto, luego "incorrectamente" multiplicando la fracción mixta. La iteración termina cuando llegues a una fracción adecuada (numerador $\leq$ denominador) o un número entero. ¿Definiré este proceso a través de un ejemplo suficientemente complicado: $$\fracright{14}{3} \rightarrow 4 \frac{2}{3} \arrow \frac{8}{3} \arrow \fracrow 2} \fracrow 3} \fracrow 2} \fracrow 3} \fracrow 1} \fracrow 1} \fracrow 1} \fracrow 1} \fracrow 1} \fracrow 1} \fracrow 1} \fracrow 1} ¿Por qué siempre termina este proceso $4+\frac{2}{3}$} \fracrow 1} \fracrow 1} \fracrow 1} \fracrow 1} $4+\frac{2}{3}$} \fracrow 1} \fracrow 1} 1} 1} 1?	number-theory,elementary-number-theory,recreational-mathematics,fractions
A.267	Dual of Lagrange Dual	For linear programming, it's well known that the dual of the dual is the primal. I'm wondering if it is the case for Lagrange duality, and I'm having a hard time showing this. Notationally, let the primal problem be: $$\text{minimize } \quad f_0(x)$$ $$\text{subject to } \quad f_i(x) \leq 0, \quad i = 1, \dots, m$$ And the dual be: $$\text{minimize } \quad -g(\lambda) = - \inf_x L(x, \lambda)$$ $$\text{subject to } \quad -\lambda \leq 0$$ Where $L(x,\lambda) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x)$ is the Lagrangian. I suspect it isn't true in general that the dual of dual is the primal. However, intuitively when I hear the term dual I assume that the dual of the dual should be the primal, so this got me confused.	Dual de Lagrange Dual	Para la programación lineal, es bien sabido que el dual del dual es el primal. Me pregunto si es el caso de la dualidad de Lagrange, y me cuesta demostrar esto. Notacionalmente, el problema primal sea: $$\text{minimize } \quad f_0(x) $$ $$\text{subject to } \quad f_i(x) \leq 0, \quad i = 1, \dots, m$$ Y el dual sea: $$\text{minimize } \quad -g(inflambda) = - \\_x L, \lambda) $$ $$\text{subject to } \quad -\lambdaq 0$$ Sin embargo, donde es el término primario XX. No soy del dual en general, \quad i = 1, \dots, m$$ Y el dual sea: $$\text{minimize } \quad -g(inflambda) = - \x, \lambda) $$ $$\text{subject to } \quad -\lambdaq 0$$ $L(x,\lambda) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x)$ donde es el primario XX. Sin embargo, no soy del dual en general, lo que tengo que el dual dual es el dual, así que tengo que confuso, que cuando me confuso, que el dual dual dual es el dual debe ser intuitivo.	optimization,convex-optimization,linear-programming,duality-theorems
A.268	If $Z\thicksim\text{Poisson}(\lambda)$, find the expected value of $\frac{1}{1+Z}.$	The Problem: Suppose that $Z\thicksim\text{Poisson}(\lambda)$. Find the expected value of $\dfrac{1}{1+Z}.$ We have that \begin{align*} E\left[\frac{1}{1+Z}\right]&=\sum_{k=0}^\infty\frac{1}{1+k}\frac{e^{-\lambda}\lambda^k}{k!}=e^{-\lambda}\sum_{k=0}^\infty\frac{\lambda^k}{(k+1)!}=\frac{e^{-\lambda}}{\lambda}\left[\sum_{k=0}^\infty\frac{\lambda^k}{k!}-1\right]\\ &=\frac{e^{-\lambda}}{\lambda}[e^\lambda-1]=\frac{1}{\lambda}-\frac{e^{-\lambda}}{\lambda}, \end{align*} where we used the Taylor series for the exponential function.  Do you agree with my approach above? Any feedback is most welcomed. Thank you very much for your time.	Si $Z\thicksim\text{Poisson}(\lambda)$, encontrar el valor esperado de $\frac{1}{1+Z}.$	El problema: Supongamos que $Z\thicksim\text{Poisson}(\lambda)$. Encontrar el valor esperado de $\dfrac{1}{1+Z}.$ Tenemos que \begin{align*} E\infty\frac{\frac{1}{1+Z}\right]&=\sum_{k=0}^\infty\frac{1}{1+k}\frac{e^{-\lambda}\lambda^k}{k!}=e^{-\lambda}\sum_{k=0}^\infty\frac{\lambda^k}{\lambda^k}{\lambda^k}{\lambda^k}{\lambda^k}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lambda}{\lamb}{\lambda}{\lambda}{\lambda}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}}{b}{b}{b}{b}{b}}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}}{b}{b}{b}{b}}{b}{b}{b}{b}{b}{b}{b}}{b}{b}{b}{b}{b}{b}{b}{b}}{b}{b}{b}{b}}}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{b}{"B}}{b}}{b}}{b}{b}{"hb}{b}}{"hb}}{"hb}{"{"{"{"{"{"{"{"}}}}}}}}}}}}}{"{"{"{"{"{"{"}}}}}}}}{"{"{"{"{"{"{"{"}}}}}}}}{"{"{"{"{"{"}}}}}}}}}}}}{"{"{"{"{"{"{"{"{"{"}}}}}}}}}}}}}{"{"{"{"{"}}} "{"} "{"} "{"} "{"} "{"} "{"} "{"} "{"} "{"} "{"} "{	probability,solution-verification,expected-value,poisson-distribution
A.269	conditional probability in a family	Let a family have two children. It is known that one of the children is a boy. What is the probability that both the children are boys. So for this we build the sample space $S=\{(b,b)(b,g)(g,g)\}$ Let our event E be the case where both children are boys $E=\{ (b,b) \}$ Let the conditional be F $F=\{(b,g),(b,b)\}$ Hence $P(E|F)=\frac{P(E\cap F)}{P(F)}=\frac{1/3}{2/3}=\frac{1}{2}$ But the answer in my book is given as $\frac{1}{3}$ and I can't seem to understand why.	probabilidad condicional en una familia	Si una familia tiene dos hijos, se sabe que uno de los niños es un niño, ¿cuál es la probabilidad de que ambos niños sean niños? Así que para esto construimos el espacio de muestra $S=\{(b,b)(b,g)(g,g)\}$ Que nuestro evento E sea el caso donde ambos niños son niños $E=\{ (b,b) \}$ Que la condición sea F $F=\{(b,g),(b,b)\}$ por lo tanto $P(E|F)=\frac{P(E\cap F)}{P(F)}=\frac{1/3}{2/3}=\frac{1}{2}$ Pero la respuesta en mi libro es dada como $\frac{1}{3}$ y no puedo entender por qué.	probability,conditional-probability
A.270	Expected number of heads before it turns up tails five times	A fair coin is flipped repeatedly until it turns up tails five times. What is the expected number of heads before that happens? Based on the link given in the comment, I have found it can be solved using the recursion $E(n)=\frac{1}{2}(E(n)+1)+\frac{1}{2}(E(n-1))$ which is equivalent to $E(n)=E(n-1)+1$. Is it correct?	El número esperado de cabezas antes de que aparezca cola cinco veces	Una moneda justa se vuelca repetidamente hasta que aparece cinco veces. ¿Cuál es el número esperado de cabezas antes de que eso suceda?	probability,expected-value
A.271	Probability of $\limsup_{n\to \infty} \{X_n X_{n+1}>0\}$ where $\{X_n\}$ are independent Gaussian r.v.'s with mean 0	Let $\{X_n\}$ be a sequence of independent Gaussian random variables with $\mathbb{E}\, X_n = 0$ for all $n \geq 1$. Find the probability of the event $$ \limsup_{n\to \infty} \big\{ X_n X_{n+1}> 0 \big\} $$ My first thought is that it should be 1 since Gaussians are always positive for a finite value. I was thinking of applying Borel-Cantelli and was trying something along the lines of \begin{align*} \mathbb{P} \big( \limsup_{n\to \infty} \big\{ X_n X_{n+1}> 0 \big\}\big) &= \mathbb{P}\big( X_n X_{n+1} > 0 \,\,\, i.o. \big) \\ &\leq \mathbb{P}\big( \big\{ X_n X_{n+1}> 0 \,\,\, i.o \big\} \cap \big\{ X_{n+1} > 0 \,\,\, i.o\big\} \big)\\ &= \mathbb{P}\big( \big\{ X_n X_{n+1}> 0 \,\,\, i.o \big\}\big) \,\,\mathbb{P}\big( \big\{ X_{n+1} > 0 \,\,\, i.o\big\} \big) \,\,\,\, \text{(by independence)} \end{align*} I'm not sure I'm thinking of this problem right, though.	Probabilidad de $\limsup_{n\to \infty} \{X_n X_{n+1}>0\}$ donde $\{X_n\}$ son r.v.s gaussianas independientes con media 0	Que $\{X_n\}$ sea una secuencia de variables aleatorias gaussianas independientes con $\mathbb{E}\, X_n = 0$ para todas las $n \geq 1$. Encuentra la probabilidad del evento $$ \limsup_{n\to \infty} \big\{X_{n+1}> 0 \big\} $$ Mi primer pensamiento es que debería ser 1 ya que los gaussianos siempre son positivos para un valor finito. Estaba pensando en aplicar Borel-Cantelli y estaba intentando algo a lo largo de las líneas de \begin{*} \mathbb{P} \\big\limsup_{n\to \infty} \big\{x_{n+1} \big\} \big\\big} \big\P} \big\\n_{n+1} \big\\big\n} \big\\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n	probability-theory,random-variables,borel-cantelli-lemmas
A.272	Why is $\sqrt{ab}$ = $\sqrt{a}\sqrt{b}$ not true when a and b are both negative?	Apparently $\sqrt{ab}$ = $\sqrt{a}\sqrt{b}$ is only true if a and b are both positive or if a is negative and b is positive or if a is positive and b is negative. In other words, a and b can't both be negative. Is it possible to algebraically prove this? Or is it just a result of the way the square root function is defined?  I know of 1 way to prove this radical property, but I'm still not sure why it won't work for negative numbers. Let x = $\sqrt{ab}$. Let y = $\sqrt{a}\sqrt{b}$ Square both sides for both equations. $x^2 = (\sqrt{ab})^2 = ab$ $y^2 = (\sqrt{a}\sqrt{b})^2 = (\sqrt{a}\sqrt{b})(\sqrt{a}\sqrt{b}) = (\sqrt{a})^2(\sqrt{b})^2 = ab$ $\therefore x^2 = y^2$ $x^2-y^2=0$ $(x+y)(x-y)=0$ $\therefore x = y$ or $x = -y$ Or $\therefore y = x$ or $y = -x$  A lot of people will go through this line of reasoning (shown below) in order to justify why a and b can't both be negative.  Considering that mathematicians define $i^2=-1$ or $i = \sqrt{-1}$ $1 = \sqrt{(-1)(-1)} = \sqrt{-1}\sqrt{-1} = (i)(i) = i^2 = -1  $ But this is only a specific instance where this property fails us. This isn't a  rigorous or at least satisfying proof of why $\sqrt{ab}$ = $\sqrt{a}\sqrt{b}$ can only be true if a and b are not both negative. Note: I just started learning about complex and imaginary numbers and I am no means an expert in  mathematical proofs, so if you do know the answer to this question please try (if possible) your best to answer the question without using too much complex or high-order math that I won't be able to understand.	¿Por qué $\sqrt{ab}$ = $\sqrt{a}\sqrt{b}$ no es verdad cuando a y b son ambos negativos?	Aparentemente $\sqrt{ab}$ = $\sqrt{a}\sqrt{b}$ es verdad sólo si a y b son ambos positivos o si a es negativo y b es positivo o si a es positivo y b es negativo. En otras palabras, a y b no pueden ser ambos negativos. ¿Es posible probar esto algebraicamente? ¿O es sólo el resultado de la forma en que se define la función de raíz cuadrada? Sé de una manera de probar esta propiedad radical, pero todavía no estoy seguro de por qué no funcionará para números negativos. Vamos a x = $\sqrt{ab}$. Vamos a y = $\sqrt{a}\sqrt{b}$ Cuadrados de ambos lados de ambas ecuaciones. $x^2 = (\sqrt{ab})^2 = ab$ $y^2 = (\sqrt{a}\sqrt{b})^2 = (\sqrt{a}\sqrt{b})(\sqrt{a}\sqrt{b}) = (\sqrt{a})^2(\sqrt{b})^2 = ab$ $\therefore x^2 = y^2$ $x^2-y^2=0$ $(x+y)(x-y)=0$ $\therefore x = y$ o $x = -y$ O $\sqrt{ab}$0 o $\sqrt{ab}$1 Muchas personas pasarán por esta línea de razonamiento (mostrada abajo) con el fin de justificar a y b no pueden ser negativos. Considerando que los matemáticos $\sqrt{ab}$2 o $\sqrt{ab}$313 por favor, este es sólo una prueba específica de la cuestión de la que no sea posible. Pero si el experto no sabe la respuesta de la matemática compleja, por qué no es posible que esto sea una prueba específica de la que no sea una propiedad de la realidad, por lo menos que sea que sea posible, si usted no puede aprender una respuesta a la matemática compleja o no es demasiado rígida y no sé por lo que sea posible.	radicals
A.273	Can fractional/decimal radicals/roots exist?	For questions like "What is the 1/2th root of x would the answer be $x^2$? My logic is that since $$ \sqrt[\cfrac{1}{2}]{x}=x^{1/{(\cfrac{1}{2}})} $$ Which simplifies to $x^2$. So as a general rule it could be $$ \sqrt[\cfrac{1}{a}]{x}=x^{1/{(\cfrac{1}{a}})} =x^a $$ And with a different denominator $$\sqrt[\cfrac{b}{a}]{x}=x^{1/{(\cfrac{b}{a}})} =x^{\cfrac{a}{b}}$$ This corresponds to how decimal/fractional exponents denote radicals (their inverse) while fractional radicals are easier shown with exponents. Example : (2/3rd root of 4) $$\sqrt[\cfrac{2}{3}]{4}=4^{1/{(\cfrac{2}{3}})} =4^{\cfrac{3}{2}}= 8$$ Example (22/7th root of π) : $$\sqrt[\cfrac{22}{7}]{π}=π^{1/{(\cfrac{22}{7}})} =π^{\cfrac{7}{22}} \approx 1.439$$ Example (1/2th root of 1/4) : $$\sqrt[\cfrac{1}{2}]{\cfrac{1}{4}}=\cfrac{1}{4}^{1/(\cfrac{2}{1})} =\cfrac{1}{4}^{(\cfrac{2}{1})} =\cfrac{1}{4}^{2} =\cfrac{1}{16} $$	¿Pueden existir radicales/raíces fraccionarias/decimales?	Para preguntas como "¿Cuál es la raíz de la mitad de x sería la respuesta $x^2$? Mi lógica es que desde $$ \sqrt[\cfrac{1}{2}]{x}=x^{1/{(\cfrac{1}{2}}}} $$ que se simplifica a $x^2$. Así que como regla general podría ser $$ \sqrt[\cfrac{1}{a}{x}=x^{1/{\cfrac{1}}{1}}{1}}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}}{2}{2}{2}{2}{2}{2}}{2}{2}{2}{2}{2}}{2}{2}{4}{2}{2}{2}{2}{2}}{2}{2}}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}}{2}{2}{2}}{2}{2}}{2}{2}}{2}{2}{2}{2}{2}{2}{2}}{4}{2}{2}{2}{2}{2}{2}{4}}{2}{2}{2}{2}{2}}{2}{2}{2}{2}{2}}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}}{2}{2}{2}{2}{2}{2}{4}{2}{2}{2}}{4}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{4}}{2}{2}{2}{2}}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{4}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{4}{2}{4}{2}{2}{2}{2}{2}{2}{2}}}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{4}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{2}{3}{2}{2}{3}{3}}{3}{3}{3}{3}}}}}{3}{3}	radicals,decimal-expansion,radical-equations
A.274	Why the Heaviside distribution $H$ doesn't belong to any Sobolev space $H^{s}(\mathbb{R})$	I prooved that the Dirac distribution $\delta_{0}$ is in the Sobolev space $H^{s}\left(\mathbf{R}^{n}\right)=\left\{f \in \mathcal{S}^{\prime}\left(\mathbf{R}^{n}\right)\left|\left(1+|\xi|^{2}\right)^{s / 2} \mathcal{F} f \in L^{2}\left(\mathbf{R}^{n}\right)\right\}\right.$ for every  $s<-n / 2$  but I steel  wrestling to proof that the  Heaviside distribution $H$  $\forall x \in \mathbb{R}, H(x)=\left\{\begin{array}{lll}{0} & {\text { si }} & {x<0} \\ {1} & {\text { si }} & {x \geq 0}\end{array}\right.$ Doesn't belong to any Sobolev space $H^{s}(\mathbb{R})$, could you elaborate on that? Thanks in advance!	¿Por qué la distribución de Heaviside $H$ no pertenece a ningún espacio Sobolev $H^{s}(\mathbb{R})$	He probado que la distribución Dirac $\delta_{0}$ está en el espacio Sobolev $H^{s}\left(\mathbf{R}^{n}\right)=\left\{f \in \mathcal{S}^{\prime}\left(\mathbf{R}^{n}\right)\left|\left(1+|\xi|^{2}\right)^{s / 2} \mathcal{F} f \in L^{2}\left(\mathbf{R}^{n}\right)\right\}\right.$ para cada $s<-n / 2$ pero estoy luchando para probar que la distribución Heaviside $H$ $\forall x \in \mathbb{R}, H(x)=\left\{\begin{array}{lll}{0} & {\text { si }} & {x<0} \\ {1} & {\text { si }} & {x \geq 0}\end{array}\right.$ no pertenece a ningún espacio Sobolev $H^{s}(\mathbb{R})$, ¿podría explicar eso?	real-analysis,functional-analysis,fourier-analysis,sobolev-spaces,distribution-theory
A.275	Proving an Integral Identity with Increasing Bounds	How can I show that  $$ \lim_{A\rightarrow \infty} \int_0^A \frac{\sin(x)}{x}dx\;=\;\frac{\pi}{2}?$$ I know that can use the fact that, for $x>0$,  $$x^{-1}\;=\;\int_0^\infty e^{-xt}dt$$ but I'm not sure how to begin.	Demostrar una identidad integral con límites crecientes	¿Cómo puedo mostrar que $$ \lim_{A\rightarrow \infty} \int_0^A \frac{\sin(x)}{x}dx\;=\;\frac{\pi}{2}?$$ Sé que puede usar el hecho de que, para $x>0$, $$x^{-1}\;=\;\int_0^\infty e^{-xt}dt$$ pero no estoy seguro de cómo empezar.	real-analysis,integration,analysis
A.276	Let $k\in\mathbb{N}$ and $a>1$. Show that $\lim_{n\to\infty} \frac{n^k}{a^n}=0$.	I think what I need to do is find the value of $n$ where $n^k. I know that this value occurs whenever $n>k\log_an$, however I don't understand how to interpret this result into a general $N$ to pick as a maximum for the sequence convergence. What am I missing here?	Vamos a $k\in\mathbb{N}$ y $a>1$. Muestre que $\lim_{n\to\infty} \frac{n^k}{a^n}=0$.	Creo que lo que necesito hacer es encontrar el valor de $n$ donde $n^k. I know that this value occurs whenever $n>k\log_an$, however I don't understand how to interpret this result into a general $N $ para elegir como máximo para la convergencia de secuencia. ¿Qué me falta aquí?	real-analysis
A.277	Is the AM-GM inequality the only obstruction for getting a specific sum and product?	This might be silly, but here it goes. Let $P,S>0$ be positive real numbers that satisfy $\frac{S}{n} \ge \sqrt[n]{P}$.  Does there exist a sequence of positive real numbers $a_1,\dots,a_n$ such that $S=\sum a_i,P=\prod a_i$?  Clearly, $\frac{S}{n} \ge \sqrt[n]{P}$ is a necessary condition, due to the AM-GM inequality. But is it sufficient? For $n=2$, the answer is positive, as can be seen by analysing the discriminant of the associated quadratic equation. (In fact, the solvability criterion for the quadratic, namely- the non-negativity of the discriminant, is equivalent to the AM-GM inequality for the sum and the product). What about $n>3$?	¿Es la desigualdad entre AM y GM la única obstrucción para obtener una suma y un producto específicos?	Esto podría ser tonto, pero aquí está. Dejemos que $P,S>0$ sean números reales positivos que satisfacen $\frac{S}{n} \ge \sqrt[n]{P}$. ¿Existe una secuencia de números reales positivos $a_1,\dots,a_n$ tal que $S=\sum a_i,P=\prod a_i$? Claramente, $\frac{S}{n} \ge \sqrt[n]{P}$ es una condición necesaria, debido a la desigualdad AM-GM. Pero es suficiente? Para $n=2$, la respuesta es positiva, como se puede ver analizando el discriminante de la ecuación cuadrática asociada. (De hecho, el criterio de solubilidad para el cuadrático, es decir, la no-negatividad del discriminante, es equivalente a la desigualdad AM-GM para la suma y el producto). ¿Qué pasa con $n>3$?	real-analysis,polynomials,systems-of-equations,a.m.-g.m.-inequality
A.278	Is there a differentiable function such that $f(\mathbb Q) \subseteq \mathbb Q$ but $f'(\mathbb Q) \not \subseteq \mathbb Q$?	Is there a differentiable function $f:\mathbb R \rightarrow \mathbb R$ such that $f(\mathbb Q) \subseteq \mathbb Q$, but $f'(\mathbb Q) \not \subseteq \mathbb Q$? A friend of mine asserted this without giving any examples. I seriously doubt it, but I had hard time trying to disprove it since analysis isn't really my thing. I can't even think of any class of differentiable functions with $f(\mathbb Q) \subseteq \mathbb Q$ other than the rational functions.	¿Existe una función diferenciable tal que $f(\mathbb Q) \subseteq \mathbb Q$ pero $f'(\mathbb Q) \not \subseteq \mathbb Q$?	¿Existe una función diferenciable $f:\mathbb R \rightarrow \mathbb R$ tal como $f(\mathbb Q) \subseteq \mathbb Q$, pero $f'(\mathbb Q) \not \subseteq \mathbb Q$? Un amigo mío afirmó esto sin dar ningún ejemplo. lo dudo seriamente, pero tuve dificultades para tratar de refutarlo ya que el análisis no es realmente mi cosa. Ni siquiera puedo pensar en ninguna clase de funciones diferenciables con $f(\mathbb Q) \subseteq \mathbb Q$ que no sean las funciones racionales.	real-analysis
A.279	If $\lim_{x\to 0}\left(f(x)+\frac{1}{f(x)}\right)=2,$ show that $\lim_{x\to 0}f(x)=1$.	Question: Suppose $f:(-\delta,\delta)\to (0,\infty)$ has the property that $$\lim_{x\to 0}\left(f(x)+\frac{1}{f(x)}\right)=2.$$ Show that $\lim_{x\to 0}f(x)=1$.  My approach: Let $h:(-\delta,\delta)\to(-1,\infty)$ be such that $h(x)=f(x)-1, \forall x\in(-\delta,\delta).$ Note that if we can show that $\lim_{x\to 0}h(x)=0$, then we will be done. Now since we have $$\lim_{x\to 0}\left(f(x)+\frac{1}{f(x)}\right)=2\implies \lim_{x\to 0}\frac{(f(x)-1)^2}{f(x)}=0\implies \lim_{x\to 0}\frac{h^2(x)}{h(x)+1}=0.$$ Next I tried to come up with some bounds in order to use Sandwich theorem to show that $\lim_{x\to 0} h(x)=0,$ but the bounds didn't quite work out. The bounds were the following: $$\begin{cases}h(x)\ge \frac{h^2(x)}{h(x)+1},\text{when }h(x)\ge 0,\\h(x)<\frac{h^2(x)}{h(x)+1},\text{when }h(x)<0.\end{cases}$$ How to proceed after this?	Si $\lim_{x\to 0}\left(f(x)+\frac{1}{f(x)}\right)=2,$ muestra que $\lim_{x\to 0}f(x)=1$.	Pregunta: Supongamos que $f:(-\delta,\delta)\to (0,\infty)$ tiene la propiedad de que $$\lim_{x\to 0}\left(f(x) +\frac{1}{f(x)}\right)=2.$$ Muestre que $\lim_{x\to 0}f(x)=1$. Mi enfoque: Que $h:(-\delta,\delta)\to(-1,\infty)$ sea tal que $h(x)=f(x)-1, \forall x\in(-\delta,\delta).$ Note que si podemos mostrar que $\lim_{x\to 0}h(x)=0$, entonces lo haremos. Ahora que tenemos $$\lim_{x\to 0}\left(f(x) +\frac{1}{f(x)}\right)=2\implica \lim_{x\to 0}frac{f(\x) {f}^2}{f-1x)}=0\implica \lim_{x\to 0}frac{h2}{h2}{h2}{h2}{h2}{h2}}{h1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}	real-analysis,calculus,limits
A.280	Why do engineers use derivatives in discontinuous functions? Is it correct?	I am a Software Engineering student and this year I learned about how CPUs work, it turns out that electronic engineers and I also see it a lot in my field, we do use derivatives with discontinuous functions. For instance in order to calculate the optimal amount of ripple adders so as to minimise the execution time of the addition process: $$\text{ExecutionTime}(n, k) = \Delta(4k+\frac{2n}{k}-4)$$ $$\frac{d\,\text{ExecutionTime}(n, k)}{dk}=4\Delta-\frac{2n\Delta}{k^2}=0$$ $$k= \sqrt{\frac{n}{2}}$$ where $n$ is the number of bits in the numbers to add, $k$ is the amount of adders in ripple and $\Delta$ is the "delta gate" (the time that takes to a gate to operate). Clearly you can see that the execution time function is not continuous at all because $k$ is a natural number and so is $n$. This is driving me crazy because on the one hand I understand that I can analyse the function as a continuous one and get results in that way, and indeed I think that's what we do ("I think", that's why I am asking), but my intuition and knowledge about mathematical analysis tells me that this is completely wrong, because the truth is that the function is not continuous and will never be and because of that, the derivative with respect to $k$ or $n$ does not exist because there is no rate of change. If someone could explain me if my first guess is correct or not and why, I'd appreciate it a lot, thanks for reading and helping!	¿Por qué los ingenieros usan derivados en funciones discontinuas?	Soy estudiante de Ingeniería de Software y este año aprendí sobre cómo funcionan las CPUs, resulta que los ingenieros electrónicos y también lo veo mucho en mi campo, utilizamos derivados con funciones discontinuas. Por ejemplo, para calcular la cantidad óptima de adiciones de ondas para minimizar el tiempo de ejecución del proceso de adición: $$\text{ExecutionTime}(n, k) = \Delta(4k+\frac{2n}{k}-4) $$\frac{d\text{Execution}{d},}}{dk}=4\Delta-d\frac{2n\Delta}{k2}=0$$= \sqrt{n}{2\frac}}{2}}}, preguntando por qué es el número de la función de adición en la ejecución, podemos cambiar el número de la función de la función de la adición, pero no podemos explicar por qué esto es correcto y porque si alguien está leyendo la verdad, ¡no puedo entenderlo porque esto es una verdad, ¡y creo que si mi respuesta es correcta y no es una verdad, ¡y no puedo entenderlo porque esto es una verdad, y que el tiempo de la función de la adición es una verdad es una verdad, y que es que es una verdad es que es una verdad es que se puede cambiar, y que es que no es una verdad es una verdad, porque si se puede, y que es que es que es que es una verdad es una verdad es que es una verdad es que es una verdad es que es una verdad es que es que es una verdad es la verdad es que es la verdad es la verdad es la verdad es que es la verdad es, y que no es que es que es una verdad es que es que es una verdad es una verdad es que no es una verdad es la verdad es la verdad es la verdad, porque si se puede que es que es que es que es que es que es que es que es una verdad es que es una verdad es que es una verdad es que es una verdad es que es una verdad es que es una verdad es que es que es una verdad es una verdad es que es una verdad es que es una verdad es que es una verdad es que es una verdad es una verdad es que es que es una verdad es una verdad es que es una verdad es que es una verdad es que es una verdad es una verdad.	real-analysis,calculus,functions,derivatives,optimization
A.281	Alternate methods to prove that $n^{\frac{1}{n}} \rightarrow 1$ where $n \in \mathbb{N}$	So, I was trying to prove that $n^{\frac{1}{n}} \rightarrow 1$ where $n \in \mathbb{N}$. Here's what I did: Since $n^{1/n}>1$, let us suppose $n=(1+k)^n$ for $n>1$ and some $k>0$. Now, I used the binomial expansion and wrote: $$\begin{align} n&=1+nk+\frac{n(n-1)}{2}k^2+....+k^n \geq1+\frac{n(n-1)}{2}k \\ &\Rightarrow n-1 \geq \frac{n(n-1)}{2}k^2 \\ &\Rightarrow k^2 \leq \frac{2}{n} \end{align}$$ So now, we can always find an $n>0$ such that $\frac{2}{\epsilon^2}. Now, as $|n^{\frac{1}{n}}-1|\geq0$, we have, $n^{\frac{1}{n}}-1=k\leq(\frac{2}{n})^{\frac{1}{2}}<\epsilon$ And in this way, I proved that $n^{\frac{1}{n}}\rightarrow1$. I wanted to know how can I prove this without using Binomial expansion. I tried to do this using the Bernoulli's Inequality,  but couldn't get too far. Any help/hint would be highly appreciable.	Metodos alternativos para demostrar que $n^{\frac{1}{n}} \rightarrow 1$ donde $n \in \mathbb{N}$	Así que, estaba tratando de probar que $n^{\frac{1}{n}} \rightarrow 1$ donde $n \in \mathbb{N}$. Esto es lo que hice: Desde $n^{1/n}>1$, supongamos $n=(1+k)^n$ para $n>1$ y algunos $k>0$. Ahora, usé la expansión binomial y escribí: $$\comenzar{align} n&=1+nk+\frac{n-1)}{2}k^2+....+k^n \geq1+\frac{n-1)}{2}k \\ &&rightarrow n-1 \geq \frac{n-1)}{2}k^2 \\ &rightarrow \^2 \leq \frac{2}{n}{end}$$\\\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n	real-analysis,sequences-and-series,convergence-divergence
A.282	How to prove the value o $\zeta(2)$ by Functional Analysis?	I have a question about $\sum_{n=1}^{\infty} 1/n^2$ = $\pi^2/6$ I know it can be proven with standard 1 variable analysis (working on Taylor series of $\arcsin$ or something like that) or basic complex analysis. But someone told me it has also great prove using Functional Analysis. He suggested it is proved on standard first course of FA, but it was not in my case. Can You write here the proof using FA or leave a link in comment? Thanks in advance.	¿Cómo probar el valor o $\zeta(2)$ por análisis funcional?	Tengo una pregunta sobre $\sum_{n=1}^{\infty} 1/n^2$ = $\pi^2/6$ sé que se puede probar con el análisis de variables estándar 1 (trabajando en la serie de Taylor de $\arcsin$ o algo así) o análisis complejo básico. Pero alguien me dijo que también tiene una gran prueba usando el análisis funcional. Sugirió que se prueba en el primer curso estándar de FA, pero no fue en mi caso. ¿Puedes escribir aquí la prueba usando FA o dejar un enlace en el comentario? Gracias por adelantado.	real-analysis,complex-analysis,functional-analysis,sums-of-squares
A.283	Determine whether $(x_n)$ converges or diverges	Given $x_1 := a > 0$ and $x_{n+1} := x_n + \frac{1}{x_n}$ for $n \in \mathbb{N}$, determine whether $(x_n)$ converges or diverges.  Since $x_1 > 0$,  it seems obvious that the sequence is strictly increasing and always positive because we are always adding a positive number to each subsequent element in the sequence.  The trickier part is to show whether $(x_n)$ is bounded or not. If $(x_n)$ is bounded, then $\exists M \in \mathbb{R}$ such that  \begin{align}|x_n| \leq M ~\forall n \in \mathbb{N}\tag{1} \end{align} Alternatively, I think this means that $M$ could be a supremum of the sequence and another way to rewrite $(1)$ is given any $\epsilon > 0$ \begin{align} x_n + \epsilon \leq M \tag{2}\end{align} Choose $\epsilon = \frac{1}{x_n}$. Then  \begin{align} x_{n+1} = x_n + \frac{1}{x_n} \leq M \implies x_n + \epsilon \leq M \tag{3}\end{align} Thus I conclude that the inequality holds $\forall n \in \mathbb{N}$ and that $(x_n)$ is convergent. Thus by the Monotone Sequence Convergence Theorem, $(x_n)$ is convergent.  The part I am not sure about is my reasoning to show that $x_n$ being bounded is correct or not.	Determina si el $(x_n)$ converge o diverge	Dado que $x_1 := a > 0$ y $x_{n+1} := x_n + \frac{1}{x_n}$ para $n \in \mathbb{N}$, determinar si $(x_n)$ converge o diverge. Desde $x_1 > 0$, parece obvio que la secuencia es estrictamente creciente y siempre positiva porque siempre estamos añadiendo un número positivo a cada elemento subsecuente en la secuencia. La parte más complicada es mostrar si $(x_n)$ está limitado o no. Si $(x_n)$ está limitado, entonces $\exists M \in \mathbb{R}$ tal que \begin{align}x_n \leq M ~\forall n \in \mathbb{N}\tag{1} \end{align} Alternativamente, creo que esto significa que $M$ podría ser una suprema de la secuencia y otra forma de reescribir $(1)$ se da cualquier $\epsilon > 0$ \begin{x_n} + \egnq M \tag{2\leq} Convergente. Así que la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la convergencia de la	real-analysis,sequences-and-series,convergence-divergence
A.284	Why decimals of rational numbers behave periodically?	I am interesting in the proof of that every rational number cannot have in decimal form infinite number of digits that don't repeat (or the other way around). So, then is enough to prove following statement: For any $n \in \mathbb{N}$ rational number $\frac{1}{n}$ can be represented in decimal form such that it's digits, if there are infinitely many, are repeating. If this is true, then it is true for any $\frac{m}{n} = \frac{1}{n} + \frac{1}{n} + ... + \frac{1}{n}$ ($m$ times).	¿Por qué las decimales de los números racionales se comportan periódicamente?	Me interesa la prueba de que cada número racional no puede tener en forma decimal un número infinito de dígitos que no se repiten (o viceversa). Así que, entonces es suficiente para probar la siguiente afirmación: Para cualquier número racional $n \in \mathbb{N}$ $\frac{1}{n}$ puede ser representado en forma decimal de tal manera que sus dígitos, si hay infinitamente muchos, se repiten. Si esto es cierto, entonces es cierto para cualquier $\frac{m}{n} = \frac{1}{n} + \frac{1}{n} + ... + \frac{1}{n}$ ($m$ veces).	real-numbers,rational-numbers,decimal-expansion
A.285	How to determine the sum of a series that is neither geometric nor arithmetic but quadratic or cubic?	How to determine the formula of the sum of a series given its $n$th-term formula like: $$U_n= n^2+n$$ or $$U_n= 6n^2 -12n + 5$$	¿Cómo determinar la suma de una serie que no es ni geométrica ni aritmética sino cuadrática o cúbica?	Cómo determinar la fórmula de la suma de una serie dada su fórmula de término $n$ como: $$U_n= n^2+n$$ o $$U_n= 6n^2 -12n + 5$$	sequences-and-series
A.286	Knowing$\sum a_{k}$ converges, how to prove that $\lim _{n \rightarrow+\infty} n a_{n}=0$.	Let $a_{n}$ be decreasing and positive. Then $\sum a_{k}$ converges implies $\lim _{n \rightarrow+\infty} n a_{n}=0$. I think since $na_n$ is positive, the only thing to do is to find an upper bound for the sequence. But I don't know how to split the sequence to form the upper bound.	Saber que $\sum a_{k}$ converge, cómo probar que $\lim _{n \rightarrow+\infty} n a_{n}=0$.	Si el número $a_{n}$ es negativo, entonces el número $\sum a_{k}$ converge con el número $\lim _{n \rightarrow+\infty} n a_{n}=0$. Creo que dado que el número $na_n$ es positivo, lo único que hay que hacer es encontrar un límite superior para la secuencia.	sequences-and-series,limits
A.287	What is the closed form of $\sum_{i=1}^n\frac{2i}{2^i}$	I looked at $\frac{\sum 2i}{\sum2^i}$ (division), however both expressions are not equal. I am looking for an expression like $\sum_{i=1}^n\frac{2i}{2^i}=5n$ for example.	¿Cuál es la forma cerrada de $\sum_{i=1}^n\frac{2i}{2^i}$	Miré $\frac{\sum 2i}{\sum2^i}$ (división), sin embargo, ambas expresiones no son iguales. Estoy buscando una expresión como $\sum_{i=1}^n\frac{2i}{2^i}=5n$ por ejemplo.	sequences-and-series
A.288	Alternating Harmonic Series Spin-off	We know that the series $\sum (-1)^n/n$ converges, and clearly every other alternating harmonic series with the sign changing every two or more terms such as $$\left(1+\frac{1}{2}+\frac{1}{3}\right)-\left(\frac{1}{4}+\frac{1}{5}+\frac{1}{6}\right)+\left(\frac{1}{7}+\frac{1}{8}+\frac{1}{9}\right)-\cdots$$ must converge. My question here is that does the series below also converge? $$\sum\frac{\textrm{sgn}(\sin(n))}{n}\quad\textrm{or}\quad\sum\frac{\sin(n)}{n|\sin(n)|}$$ Loosely speaking, the sign changes every $\pi$ terms. I'd be surprised if it doesn't converge. Wolfram Mathematica, after a couple of minutes of computing, concluded the series diverges but I can't really trust it. My first approach (assuming the series converges) was that if we bundle up terms with the same sign like the example above every bundle must have three or four terms, and since the first three terms of all bundles make an alternating series I was going to fiddle with the remaining fourth terms but they don't make an alternating series so I guess there's no point in this approach. edit: I don't think we can use Dirichlet's test with $$b_n=\textrm{sgn}(\sin(n)).$$ The alternating cycle here is $\pi$ and I don't believe it would bound the series. For example if the cycle was a number very slightly smaller than $3+1/4$, then $B_n$ (sum of $b_n$) would get larger and larger every four bundles for some time. I believe this should happen for $\pi$ as well since it is irrational. I'm not entirely sure why but $|B_n|\leq3$ for most small $n$ though I guess it's because $\pi-3$ is slightly smaller than $1/7$? Anyway $B_{312\ 692}=4$, $B_{625\ 381}=5$, $B_{938\ 070}=6$, $B_{166\ 645\ 135}=-7$, and $B_{824\ 054\ 044}=8$. $|B_n|$ does not hit $9$ up to $n=1\ 000\ 000\ 000$ with $B_{1\ 000\ 000\ 000}=-2$.	Alternación de la serie de cambios de la serie de cambios	Sabemos que la serie $\sum (-1)^n/n$ converge, y claramente todas las demás series armónicas alternativas con el signo cambiando cada dos o más términos como $$\left{8}+\dirfrac{1}\9}\right) {2}+\frac{1}{3}\right) -\left\\frac{1}{4}+\frac{1}{5}+\frac{1}{6}\right}\left}\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\frac{1}{1}{1}{7}\frac{1}{7}+\frac{1}{8}+\frac{1}{9}{1}{1}}{2}\right}\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\right\	sequences-and-series
A.289	Find $x^n+y^n+z^n$ general solution	If we know $$x+y+z=1$$$$x^2+y^2+z^2=2$$$$x^3+y^3+z^3=3$$ Is it possible to calculate the general solution for $a_n=x^n+y^n+z^n$? I know $a_5=6$ but the way to get it is more an algorithm than an actual solution.	Encuentra la solución general $x^n+y^n+z^n$	Si sabemos $$x+y+z=1$$x^2+y^2+z^2=2$$$$x^3+y^3+z^3=3$$ ¿Es posible calcular la solución general para $a_n=x^n+y^n+z^n$? Sé $a_5=6$ pero la forma de obtenerlo es más un algoritmo que una solución real.	sequences-and-series
A.290	Best method for proving that $7\times11^{2n+1}-3^{4n-1}$ is divisible by $10$	I am asked to prove by induction that $7\times11^{2n+1}-3^{4n-1}$ is divisible by $10$. I wonder whether there is a more direct method, for example factorizing by $10$. If an expression is divisible by $10$, does this mean that I can factorize it by $10$? Thanks in advance	Mejor método para demostrar que $7\times11^{2n+1}-3^{4n-1}$ es divisible por $10$	Me preguntan si hay un método más directo, por ejemplo factorizando por $10$. Si una expresión es divisible por $10$, ¿esto significa que puedo factorizarla por $10$? Gracias por adelantado	sequences-and-series,elementary-number-theory,divisibility
A.291	Summation of $n$th partial products of the square of even numbers diverges, but for odd numbers they converge in this series I'm looking at. Why?	So I have the two following series: $$\sum_{n=1}^\infty \frac{\prod_{k=1}^n(2k)^2}{(2n+2)!}$$ $$\sum_{n=0}^\infty \frac{\prod_{k=0}^n(2k+1)^2}{(2n+3)!}$$ I figured out the $n$th partial products: $$\prod_{k=1}^n(2k)^2=4^n(n!)^2$$ $$\prod_{k=0}^n (2k+1)^2=\frac{((2n+1)!)^2}{4^n(n!)^2}$$ So putting these back into my series they become the following: $$\sum_{n=1}^\infty \frac{\prod_{k=1}^n(2k)^2}{(2n+2)!}=\sum_{n=1}^\infty\frac{4^n(n!)^2}{(2n+2)!}$$ Now this diverges as expected by the limit test test. However when I look at my other series: $$\sum_{n=0}^\infty \frac{\prod_{k=0}^n(2k+1)^2}{(2n+3)!}=\sum_{n=0}^\infty\frac{( (2n+1)!)^2}{4^n(n!)^2(2n+3)!}$$ By the limit test maybe diverges or maybe doesn't, and the ratio test is inconclusive. Since I wasn't sure what to use for the a comparison test I threw this into wolfram alpha and it told me it converges which is baffling to me since both series are very similar if we write them out: $$\sum_{n=1}^\infty \frac{\prod_{k=1}^n(2k)^2}{(2n+2)!}=\frac{2^2}{4!}+\frac{2^24^2}{6!}+\frac{2^24^26^2}{8!}\cdot\cdot\cdot\cdot$$ $$\sum_{n=0}^\infty \frac{\prod_{k=0}^n(2k+1)^2}{(2n+3)!}=\frac{1^2}{3!}+\frac{1^23^2}{5!}+\frac{1^23^25^2}{7!}+\cdot\cdot\cdot$$ They both have the nth parial product of the even/odd integers squared in the numerator, and are over a factorial that is two greater than $n$, so I'm not sure why one is diverging and the other is converging. Is wolframalpha wrong, as it can be at times? Or is there someething here that I am missing?	La suma de los productos parciales del cuadrado de números pares difiere, pero para números impares convergen en esta serie que estoy viendo. ¿Por qué?	Así que tengo las dos siguientes series: $$\sum_{n=1}^\infty \frac{\prod_{k=1}^n2k}^n2k}^n2}{(2n+2}!} $$ $$\sum_{n=0}^infty \frac{\dot_{k=0}^n2k+1)^2}{2n+3}{2n+3}!} $$\infty \frac{\product_{k=1}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2n}{2}{2n}{2}}{2}{2}}{2}}{2}{2}{2}}}{2}{2}}{2}}{2}}{2}{2}}{2}{2}}}{2}{2}}{2}}{2}}}{2}{2}{2}{2}}}{2}{2}{2}{2}}{2}}}}{2}{2}{2}}{2}}}}}}}}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2}2	sequences-and-series,factorial,products
A.292	Find the limit of the sequence $ \frac{x^n}{n^k}$ as $n \to \infty$ for all values of$ x > $0 and $k = 1, 2,\cdots$	I have tried using the ratio lemma to tackle this question and also the fact $(n+1)^k \geq 1 + nk$ and I haven't reached an answer. How should I go about solving this problem?	Encuentra el límite de la secuencia $ \frac{x^n}{n^k}$ como $n \to \infty$ para todos los valores de $ x > $0 y $k = 1, 2,\cdots$	He intentado utilizar el lema de la relación para abordar esta pregunta y también el hecho $(n+1)^k \geq 1 + nk$ y no he llegado a una respuesta. ¿Cómo debo resolver este problema?	sequences-and-series,limits,analysis,exponentiation,ratio
A.293	Summation $\sum_{j=2}^{n-1}j^2$ Properties	I'm dealing with something like $\sum_{j=2}^{n-1}j^2$. I know I can do this $\sum_{j=1}^{n-1}j^2 - \sum_{j=1}^{1}j^2$. Would that be equal to $\frac{j(j+1)(2j+1)}{6} - j^2$ or I'm missing some properties with $n-1$? If so, which ones?	Resumen $\sum_{j=2}^{n-1}j^2$ Propiedades	Estoy tratando con algo como $\sum_{j=2}^{n-1}j^2$. sé que puedo hacer esto $\sum_{j=1}^{n-1}j^2 - \sum_{j=1}^{1}j^2$. ¿Eso es igual a $\frac{j(j+1)(2j+1)}{6} - j^2$ o me faltan algunas propiedades con $n-1$?	sequences-and-series,summation
A.294	Why is there no hyper-hypercohomology?	I am looking for a reference to answer the question in the title. Let me try to clarify a little what I mean: If a single sheaf $\mathscr F$ has a resolution $\mathscr G^\bullet$ by not necessarily injective objects, then the usual cohomology of $\mathscr F$ is isomorphic to the hypercohomology of $\mathscr G^\bullet$:  $$ H^i(X, \mathscr F) \cong \mathbb H^i(X,\mathscr G^\bullet). $$ Now, if one was starting with a complex of sheaves $\mathscr F^\bullet$ and a "resolution" thereof, i.e. a complex of complexes $(\mathscr G^\bullet)^\bullet$, then one should touch on a concept that could be called hyper-hypercohomology.  Yet, I never heard of its existence and I'm pretty sure it does not give you anything new, as soon as you work in the derived category. I just find myself unable to pin down why exactly this is the case.  Any ideas anyone?	¿Por qué no hay hiper-hipercohomología?	Busco una referencia para responder a la pregunta en el título. Déjame intentar aclarar un poco lo que quiero decir: si una sola hoja $\mathscr F$ tiene una resolución $\mathscr G^\bullet$ por objetos no necesariamente inyectivos, entonces la cohomología habitual de $\mathscr F$ es isomórfica a la hipercohomología de $\mathscr G^\bullet$: $$ H^i(X, \mathscr F) \cong \mathbb H^i(X, \mathscr G^\bullet). $$ Ahora, si uno estaba comenzando con un complejo de hoja $\mathscr F^\bullet$ y una "resolución", es decir, un complejo de complejos $(\mathscr G^\bullet)^\bullet$, entonces uno debería considerar un concepto que podría llamarse hiper-hipercohomología. Sin embargo, nunca escuché exactamente de su existencia y estoy bastante seguro de que no le da nada nuevo, tan pronto como usted trabaja en la categoría.	sheaf-cohomology,derived-categories
A.295	Help calculating series	I need help with understanding how to solve this task, because I'm a bit lost at the moment. Use the powerseries  $$f(x)=\frac{1}{1-x}$$ to decide the sum of the series  $\sum_{n=1}^{\infty} n(n+1)x^n$    and $\sum_{n=1}^{\infty} \frac{n(n+1)}{3^n}$ I don't understand how to manipulate the sums to use the power series of the function.	Ayuda para calcular series	Necesito ayuda para entender cómo resolver esta tarea, porque estoy un poco perdido en este momento. Use las series de potencias $$f(x) =\frac{1}{1-x}$$ para decidir la suma de las series $\sum_{n=1}^{\infty} n(n+1)x^n$ y $\sum_{n=1}^{\infty} \frac{n(n+1)}{3^n}$ No entiendo cómo manipular las sumas para usar la serie de potencias de la función.	summation,power-series
A.296	A little confused about the Taylor series of $e^x$	We know that $$ e^x=\sum_{n=0}^{\infty}\frac{x^n}{n!},x\in \mathbb R, $$ which can be written out $$ e^x=\frac {x^0}{0!}+\frac {x^1}{1!}+\frac {x^2}{2!}+\cdots, $$ but $0^0$ isn't well defined.	Un poco confundido con la serie de Taylor de $e^x$	Sabemos que $$ e^x=\sum_{n=0}^{\infty}\frac{x^n}{n!},x\in \mathbb R, $$ que puede ser escrito fuera $$ e^x=\frac {x^0}{0!}+\frac {x^1}{1!}+\frac {x^2}{2!}+\cdots, $$ pero $0^0$ no está bien definido.	taylor-expansion,exponential-function
A.297	difficult question	I am confused about a homework problem I have, and don't really know where to begin. I need to prove this. Any idea of where I can start. The statement is that Find all integers n that satisfies $\phi(n)=320$ where $\phi$ is the Euler’s Phi function.	pregunta difícil	Estoy confundido sobre un problema de tarea que tengo, y no sé realmente por dónde empezar. Necesito probar esto. Cualquier idea de dónde puedo comenzar. La declaración es que encontrar todos los enteros n que satisface $\phi(n)=320$ donde $\phi$ es la función Euler  Phi.	totient-function
A.298	Variable transformation of a Dirac delta function	I am struggling to understand the variable transformation of a Dirac delta function. More specifically, a transformation of the following type, $$\delta(a\chi(z)-b) \rightarrow \delta(z-c)$$ Here, $a, b$ and $c$ are constants. The specific relationship between $\chi(z)$ and $z$ is, $$\chi(z)=\int{\frac{1}{H(z)}dz}$$ where $H(z)$ is a non-zero, positive and smoothly varying function of $z$. In the context of my Physics problem, for the sake of the interested audience, $H(z)$ is the Hubble parameter of the Universe while $\chi(z)$ is the comoving distance and $z$ is the redshift of any time in the past. So, let me add what I have done so far:  I start by defining the Dirac delta function in the form a unit step function $\Theta (a\chi(z)-b)$as, $$\frac{d}{d(a\chi(z))}\Theta(a\chi(z)-b)=\delta(a\chi(z)-b)$$ Then converting this in the form of z using the chain rule as, $$\frac{d}{dz}\Theta(a\chi(z)-b)\frac{dz}{d(a\chi(z))}$$ Using the relation with $H(z)$, we can write the equation as, $$\frac{d}{dz}\Theta(a\chi(z)-b)\frac{H(z)}{a}$$ Also, $\chi(z)$ can also be replaced by the integral as well, so that left side containing the unit step function can be written as, $$\frac{H(z)}{a}\frac{d}{dz}\Theta(\ a\int_0^z{\frac{1}{H(z')}dz'}-b)$$. After this, I am not sure what else to try. Hopefully, this addition helps. Also, please point out an error if you see one.	Transformación variable de una función delta Dirac	Estoy luchando para entender la transformación variable de una función delta de Dirac. Más específicamente, una transformación del siguiente tipo, $$\delta(a\chi(z) -b) \rightarrow \delta(z-c)$$ Aquí, $a, b$ y $c$ son constantes. La relación específica entre $\chi(z)$ y $z$ es, $$\chiz) =\int{\frac{1}{H(z)}dz}$$ donde $H(z)$ es una función no cero, positiva y fluida de $z$. En el contexto de mi problema de física, para el error de la audiencia interesada, $H(z)$ es el parámetro Hubble del Universo mientras que $\chi(z)$ es la distancia de llegada y $z$ es la distancia roja de cualquier momento en la cadena. Así que, hasta ahora, lo que tengo que convertir es, por favor, añadir que podemos definir la función de la cadena de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea de la línea	transformation,dirac-delta,change-of-variable
A.299	Prove $\cos \frac{\pi}5-\cos \frac{2 \pi}5=\frac12$ but without finding $\cos \frac{ \pi}5$	I can find the value of $\cos \left(\frac{ \pi}{5}\right)$, but is there a way to prove the equality without finding it? I tried looking for both algebraic and geometric methods, but couldn't find anything	Prueba $\cos \frac{\pi}5-\cos \frac{2 \pi}5=\frac12$ pero sin encontrar $\cos \frac{ \pi}5$	Puedo encontrar el valor de $\cos \left(\frac{ \pi}{5}\right)$, pero ¿hay una manera de probar la igualdad sin encontrarlo? Traté de buscar métodos algebraicos y geométricos, pero no pude encontrar nada	trigonometry,proof-writing,alternative-proof
A.300	Uniformly continuous or not?	So I supposed to find out if $$f(x)=\frac{1}{1+\ln^2 x}$$ is uniformly continuous on $I=(0,\infty)$ So I have been thinking a lot. Could I say that $f$ is continuous on $[0,1]$ and therefore uniformly continuous here? Or is this not valid, because $\ln$ is not defined at $x=0$? And then say that the derivate is bounded at $[1,\infty]$?	¿Uniforme o no?	Así que se supone que debo averiguar si $$f(x) =\frac{1}{1+\ln^2 x}$$ es uniformemente continuo en $I=(0,\infty)$ Así que he estado pensando mucho. ¿Podría decir que $f$ es continuado en $[0,1]$ y por lo tanto uniformemente continuo aquí? ¿O esto no es válido, porque $\ln$ no se define en $x=0$?	uniform-continuity
A.301	Inequality between norm 1,norm 2 and norm $\infty$ of Matrices	Suppose $A$ is a $m\times n$ matrix. Then Prove that, $\begin{equation*} \|A\|_2\leq \sqrt{\|A\|_1 \|A\|_{\infty}} \end{equation*}$ I have proved the following relations: $\begin{align*} \frac{1}{\sqrt{n}}\|A\|_{\infty}\leq \|A\|_2\leq\sqrt{m}\|A\|_{\infty}\\ \frac{1}{\sqrt{m}}\|A\|_{1}\leq \|A\|_2\leq\sqrt{n}\|A\|_{1} \end{align*}$ Also I feel that somehow Holder's inequality for the special case when $p=1$ and $q=\infty$ might be useful.But I couldn't prove that. Edit: I would like to have a prove that do not use the information that $\|A\|_2=\sqrt{\rho(A^TA)}$ Usage of inequalities like Cauchy Schwartz or Holder is fine.	Desigualdad entre la norma 1, la norma 2 y la norma $\infty$ de las matrices	Supongamos que $A$ es una matriz $m\times n$. Entonces prueba que, $\begin{equation*} \|A\|_2\leq \sqrt{\|A\|_1 \|A\|_{\infty}} \end{equation*}$ he probado las siguientes relaciones: $\begin{align*} \frac{1}{\sqrt{n}}\|A\|_{\infty}\leq \|A\|_2\leq\sqrt{m}\|A\|_{\infty}\\ \frac{1}{\sqrt{m}}\|A\|_{1}\leq \|A\|_2\leq\sqrt{n}\|A\|_{1} \end{align*}$ También siento que de alguna manera la desigualdad de Holder para el caso especial cuando $p=1$ y $q=\infty$ podría ser útil.Pero no pude probar eso.	linear-algebra,matrices,inequality,norm,holder-inequality
A.302	$n$-th root of a complex number	I am confused about the following problem. With $w=se^{i{\phi}}$, where $s\ge 0$ and $\phi \in \mathbb{R}$, solve the equation $z^n=w$ in $\mathbb{C}$ where $n$ is a natural number. How many solutions are there? Now my approach is simply taking the $n$-th root which gives $$z=\sqrt[n]{s}e^{\frac{i\varphi}{n}}$$ However, it seems that this problem is asking us to show the existance of the $n$-th root. Can I assume that the $n$-th root of a complex number already exists? Moreoover, would I be correct to say that there is only one solution which is given above?	$n$ raíz de un número complejo	Estoy confundido sobre el siguiente problema. Con $w=se^{i{\phi}}$, donde $s\ge 0$ y $\phi \in \mathbb{R}$, resolver la ecuación $z^n=w$ en $\mathbb{C}$ donde $n$ es un número natural. ¿Cuántas soluciones hay? Ahora mi enfoque es simplemente tomar la raíz $n$ que da $$z=\sqrt[n]{s}e^{\frac{i\varphi}{n}}$$ Sin embargo, parece que este problema nos está pidiendo que demos la existencia de la raíz $n$ . ¿Puedo asumir que la raíz $n$ de un número complejo ya existe? Además, sería correcto decir que solo hay una solución que se da arriba?	real-analysis,calculus,complex-analysis,analysis
A.303	Number of non-commutative Lie algebras of dimension 2	Theorem- Up to isomorphism, the only noncommutative Lie algebra of dimension 2 is that with basis $x , y$ and bracket determined by $[x,y] = x$. I understand that all vector spaces of dimension 2 over the field $K$ are isomorphic to each other. So the number of lie algebras of dimension 2 in a field $K$ is determined by the number of possible bilinear operations [ ]$:\ V \ X \ V  \rightarrow V$ satisfying the conditions $a)$ $[x,x]=0$ for all $x\in V$ $b)$ $[x,[y,z]]+[y,[z,x]]+[z,[x,y]]=0$ for all $x,y,z \in V$ The bilinear operations on the other hand is determined by the elements to which the pair of base elements are mapped to in the bilinear operation. And since in a lie algebra $[x,x]=[y,y]=0$ and $[x,y]=-[x,y]$ we ony need to determine $[x,y]$. Now how do we prove that $[x,y]=x$ and $[y,x]=-x$ always and why can't it be [y,x]=y or any other vector ?	Número de álgebra de Lie no commutativa de dimensión 2	Teorema- Hasta el isomorfismo, el único álgebra de Lie no commutativa de dimensión 2 es que con base $x , y$ y corchilla determinada por $[x,y] = x$. Entiendo que todos los espacios vectoriales de dimensión 2 sobre el campo $K$ son isomorfos entre sí. Así que el número de álgebra de mentira de dimensión 2 en un campo $K$ se determina por el número de posibles operaciones bilineares [ ]$:\ V \ X \ V  \rightarrow V$ satisfaciendo las condiciones $a)$ $[x,x]=0$ para todos los $x\in V$ $b)$ $[x,[y,z]]+[y,[z,x]]+[z,[x,y]]=0$ para todos los $x , y$0 Las operaciones bilineares por el otro lado se determinan por los elementos a los que se cartografian el par de elementos base en la operación bilinear. Y dado que en una álgebra de mentira $x , y$1 y $x , y$2 necesitamos determinar $x , y$3. Ahora ¿cómo probamos que $x , y$4 y $x , y$5 siempre y por qué no puede ser [yx, y] cualquier otro vector?	lie-algebras,noncommutative-algebra
A.304	Elementary proof that a non-orientable manifold of real dimension $2$ does not admit a quasi-complex structure.	Is there an easy proof that a non-orientable real surface $X$ does not admit a quasi-complex structure? The proof I know is to observe that any quasi-complex structure on a real surface $X$ necessarily satisfies the integrability condition $$[T_X^{0,1}, T_X^{0,1}] \subset T_X^{0,1}$$ of the Newlander-Nirenberg theorem, because $T_X^{0,1}$ is a $1$-dimensional complex vector bundle, and the bracket $[-,-]$ is alternating, i.e. it vanishes on $T_X^{0,1}$. So by the Newlander-Nirenberg theorem, $X$ admits a complex structure, and complex manifolds have to be orientable. However, the Newlander-Nirenberg theorem is a deep theorem and feels a bit overkill. Also I don't really see why there cannot be a quasi-complex structure. Is there a more elementary proof to convince myself?	Prueba elemental de que un variedad no orientable de dimensión real $2$ no admite una estructura cuasi compleja.	¿Existe una prueba fácil de que una superficie real no orientable $X$ no admite una estructura cuasicompleja? La prueba que conozco es observar que cualquier estructura cuasicompleja en una superficie real $X$ satisface necesariamente la condición de integrabilidad $$[T_X^{0,1}, T_X^{0,1}] \subconjunto T_X^{0,1}$$ del teorema de Newlander-Nirenberg, porque $T_X^{0,1}$ es un conjunto vectorial complejo de $1$ dimensiones, y el paréntesis $[-,-]$ está alternándose, es decir, desaparece en $T_X^{0,1}$. Así que por el teorema de Newlander-Nirenberg, $X$ admite una estructura compleja, y los múltiples complejos deben ser orientables. Sin embargo, el teorema de Newlander-Nirenberg es una prueba y un poco más profunda. ¿Por qué no puedo convencerme de que hay una estructura cuasicompleja?	algebraic-geometry,reference-request,complex-geometry
A.305	What will be the value of floor function of $\lim\limits_{N\to\infty}\left\lfloor\sum\limits_{r=1}^N\frac{1}{2^r}\right\rfloor$	What would be the value of floor function of $\lim\limits_{N\to\infty}\left\lfloor\sum\limits_{r=1}^N\frac{1}{2^r}\right\rfloor$ would it be $1$ or would it be $0$ ? The formula I use for this is that of infinite summation series that is $\frac{a}{1-r}$ but I have no clue how to find out what the floor value of the above expression would be. P.s I am a high school student so please explain in simple terms, and yes I do know basic calculus. EDIT: I'm sorry it was given $\lim_{N \to \infty}$ in the problem	Cuál será el valor de la función de piso de $\lim\limits_{N\to\infty}\left\lfloor\sum\limits_{r=1}^N\frac{1}{2^r}\right\rfloor$	¿Cuál sería el valor de la función de piso de $\lim\limits_{N\to\infty}\left\lfloor\sum\limits_{r=1}^N\frac{1}{2^r}\right\rfloor$ sería $1$ o sería $0$? La fórmula que uso para esto es la de la serie de sumación infinita que es $\frac{a}{1-r}$ pero no tengo idea de cómo averiguar el valor de piso de la expresión anterior sería. P.s Soy estudiante de secundaria así que por favor expliquen en términos simples, y sí, sé cálculo básico.	summation
A.306	On the irrationality of Euler Mascheroni constant	I saw one of the expansions of Euler Mascheroni constant in terms of Meissel Mertens constant as a consequence of Mertens theorem. $$ B = \gamma + \sum_p \left\{ \log\left( 1 - \frac 1p\right) + \frac 1p\right\}$$ This is that expansion. Now I don't understand why is it difficult to prove the irrationality of Euler Mascheroni constant. Since we have infinitely many prime numbers, the sum over all those primes in the above equation, if converges must be a irrational, then why is it not considered as a proof of irrationality?	Sobre la irracionalidad de la constante de Euler Mascheroni	Vi una de las expansiones de la constante de Euler Mascheroni en términos de constante de Meissel Mertens como consecuencia del teorema de Mertens. $$ B = \gamma + \sum_p \left\{ \log\left\(1 - \frac 1p\right) + \frac 1p\right\}$$ Esta es esa expansión. Ahora no entiendo por qué es difícil probar la irracionalidad de la constante de Euler Mascheroni. Dado que tenemos infinitos números primos, la suma de todos esos primos en la ecuación anterior, si las convergencias deben ser irracionales, entonces ¿por qué no se considera como una prueba de irracionalidad?	irrational-numbers,euler-mascheroni-constant
A.307	Carmichael function and the largest multiplicative order modulo n	By definition, the Carmichael function maps$a $positive integer $n$ to the smallest positive integer $t$ such that $a^t\equiv1\pmod n$ for all integers $a$ with $\gcd(a,n)=1$. It is denoted as $\lambda(n)$. The Wikipedia page on Carmichael function states that $\lambda(n)=\max\{\operatorname{ord}_n(a):\gcd(a,n)=1\}$. My question is: why is this true? In other words, why is it the case that there always exists an integer $x$ coprime to $n$ with $\operatorname{ord}_n(x)=\lambda(n)$?	Función Carmichael y el mayor orden multiplicativo modulo n	Por definición, la función Carmichael mapea el número entero positivo $n$ al número entero positivo más pequeño $t$ de tal manera que $a^t\equiv1\pmod n$ para todos los números enteros $a$ con $\gcd(a,n)=1$. Se denota como $\lambda(n)$. La página de Wikipedia sobre la función Carmichael afirma que $\lambda(n)=\max\{\operatorname{ord}_n(a):\gcd(a,n)=1\}$. Mi pregunta es: ¿por qué es esto cierto?	elementary-number-theory,carmichael-function
A.308	Riemann's definition of the zeta function	I am having trouble understanding Riemann's definition of the zeta function, and I will need to give a brief summary here before I can get to my question. In his 1859 paper, Riemann derived the integral representation $$\zeta(s)=\sum_{n=1}^\infty\frac{1}{n^s}=\frac{1}{\Gamma(s)}\int_0^\infty \frac{x^{s-1}}{e^x-1}dx$$ that is valid for $\mbox{Re}(s)\gt 1$, and then modified the integral in order to define a function that is defined for all complex values of $s$, except $s=1$, where it has a simple pole. The extension is given by $$\zeta(s)=\frac{\Gamma(1-s)}{2\pi i}\int_C \frac{(-z)^s}{e^z-1}\frac{dz}{z}$$ where $C$ is a "Hankel contour", that is, a path that travels from $+\infty $ at a small distance $\epsilon$ above the positive $x$-axis, circles around the origin once in counterclockwise direction with a small radius $\delta$, and returns to $+\infty$ traveling at distance $\epsilon$ below the positive real axis. Taking the limit as $\epsilon\rightarrow 0$ and $\delta \rightarrow 0$ one can see that the integral $$\int_C \frac{(-z)^s}{e^z-1}\frac{dz}{z}$$ becomes $$(e^{i\pi s}-e^{-i\pi s})\int_0^\infty\frac{x^{s-1}}{e^x-1}dx$$ and then the rest follows easily from known identities satisfied by the Gamma function.  While the original real integral over $[0,\infty)$ is clearly divergent if $\mbox{Re}(s)\leq 1$, the contour integral over $C$ is defined for all complex $s$, because the path stays away from the singularity at $s=0$ and from the branch cut along the positive $x$-axis. My problem is understanding why the integral over $C$ does not depend on $\epsilon$ and $\delta$, so that we can keep them at a safe positive distance from the singularities for the definition, but we can take the limit for the purpose of evaluating the integral. I know that by Cauchy's theorem we can modify a path of integration (without changing the value of the integral) starting and ending at the same point as long as we do not cross any singularity, but this path starts and ends at infinity, so I am not sure how to rigorously proceed using Cauchy's theorem. Even if I start the path at $R+i\epsilon$ and end it at $R-i\epsilon$ for some large $R$, the path starting and ending points change as $\epsilon$ changes.	La definición de la función zeta de Riemann	Tengo problemas para entender la definición de la función zeta de Riemann, y tendré que dar un breve resumen aquí antes de poder llegar a mi pregunta. En su artículo de 1859, Riemann derivó la representación integral $$\zeta(s) =\sum_{n=1}^\infty\frac{1}{n^s}=\frac{1}{\Gamma(s)}\int_0^\infty \frac{x^{s-1}}{e^x-1}dx$$} que es válida para $\mbox{Re}(s)\gt 1$, y luego modificó la integral para definir una función que se define para todos los valores complejos de $s$, $s=1$, donde tiene un polo simple. La extensión se da por los puntos singulares que terminan en los puntos singulares ({n=1}{z}{g}{1}{1}{1}{1}}{z}}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}}{1}{1}}{1}}{1}{1}}{1}{1}}{1}}{1}{1}}}{1}{1}}{1}{1}}}{1}{1}}{1}{1}}}{1}{1}}}{1}{1}}{1}}{1}}{1}{1}}}{1}{1}}}{1}}{1}}{1}{1}{1}}}{1}{1}}}{1}{1}}{1}}{1}{1}}}{1}}}{1}{1}}}{1}}}{1}{1}}}{1}{1}}}}{1}}}}{1}{1}}{1}}{1}}{1}}}{1}}}{1}{1}}}{1}}{1}}{1}}}{1}}}{1}}}}{1}{1}}}{1}}}{1}{1}}}{1}}}{1}}}}{1}{1}{1}{1}}}}{1}{1}}}{1}{1}}}}{1}}}}}{1}{1}{1}{1}}}}{1}{1}}{1}}{1}}{1}}{1}}{1}{1}}{1}}{1}{1}{1}}{1}}{1}{1}{1}}}}{1}{1}}}}{1}{1}}{1}}{1}{1}{1}{1}}}{1}{1}{1}{1}}}{1}{1}}{1}{1}}{1}{1}}{1}{1}}{1}{1}{1}{1}{1}}}{1}{1}{1}{1}{1}}{1}{1}}{1}{1}{1}{1}{1}{1}}{1}}{1}{1}{1}{1}{1}}{1}{1}{1}{1}{1}{1}{1}{1}}{1}{1}{1}{1}}}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}}{1}{1}}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}}{1}{1}}}{1}{1}{1}{1}{1}{1}{1}}{1}{1}{1}{1}{1}}}{1}{1}	contour-integration,riemann-zeta
A.309	Number of solutions of equation over a finite field	I have a question regarding the number of solutions of a equation over a finite field $\mathbb{F}_p$. First of all, consider the equation $x^3=a$ over $\mathbb{F}_p$, where $p$ is a prime such that $p\equiv 2 (\text{mod }3)$. The book that I'm currently reading says that this equation has exactly one solution in $\mathbb{F}_p$ for every $a\in \mathbb{F}_p$, because $\gcd(3,p-1)=1$, but the book does not prove this. Unfortunately, this doesn't convince me enough. Is there is a convincing elementary straightforward proof justifying why is this true?	Número de soluciones de la ecuación sobre un campo finito	Tengo una pregunta sobre el número de soluciones de una ecuación sobre un campo finito $\mathbb{F}_p$. En primer lugar, considere la ecuación $x^3=a$ sobre $\mathbb{F}_p$, donde $p$ es un primo tal que $p\equiv 2 (\text{mod }3)$. El libro que estoy leyendo actualmente dice que esta ecuación tiene exactamente una solución en $\mathbb{F}_p$ para cada $a\in \mathbb{F}_p$, porque $\gcd(3,p-1)=1$, pero el libro no prueba esto. Desafortunadamente, esto no me convence lo suficiente. ¿Hay una prueba convincente elemental directa que justifique por qué esto es cierto?	number-theory,elementary-number-theory,finite-fields
A.310	Finding positive integer solutions to $\frac{4}{x}+\frac{10}{y}=1$	Find the positive integer solutions for: $\frac{4}{x} + \frac{10}{y} = 1$  I had calculated the solutions manually but it was a very tedious process. Is there any better way to do this?	Encontrar soluciones de números enteros positivos a $\frac{4}{x}+\frac{10}{y}=1$	Encuentra las soluciones de números enteros positivos para: $\frac{4}{x} + \frac{10}{y} = 1$ había calculado las soluciones manualmente pero fue un proceso muy tedioso. ¿Hay alguna mejor manera de hacer esto?	elementary-number-theory,solution-verification
A.311	Given a function $f(x)=\frac{9^{x}}{9^x+3}$, what is $f(\frac{1}{27})+ f(\frac{2}{27}) + f(\frac{3}{27})+ ...+ f(\frac{26}{27})$?	While I was going through past Olympiad math papers, I found this question without any explanation. Here is the question:  Given a function $f(x)=\frac{9^{x}}{9^x+3}$, what is $f(\frac{1}{27})+ f(\frac{2}{27}) + f(\frac{3}{27})+ ...+ f(\frac{26}{27})$?  The answer was 13. I took a really bad approach and converted $\frac{9^{x}}{9^x+3}$ to $1+\frac{9^{x}}{3}$, which I then noticed was wrong. I also accidentally multiplied $9^{\frac{1}{27}}$ with $9^{\frac{2}{27}}$, $9^{\frac{2}{27}}$ with $9^{\frac{3}{27}}$, and so on, before realizing that the functions were added and not multiplied. I suspect that there is something to the power of $\frac{n}{27}$, because 9 is a multiple of 27. However, I am not completely sure. Is there a law that tells me how I can solve this question? Since this is a Math Olympiad question, there is probably a maximum time limit of five minutes to do this question. This means that I probably won’t have time for tedious mathematical calculations with a calculator and online tools, or something like that. Please give me a quick, fast solution that is probably suitable for an 8th grader, at most a solution at a 10th grader level.	Dada una función $f(x)=\frac{9^{x}}{9^x+3}$, ¿qué es $f(\frac{1}{27})+ f(\frac{2}{27}) + f(\frac{3}{27})+ ...+ f(\frac{26}{27})$?	Mientras revisaba los documentos anteriores de matemáticas de la Olimpiada, encontré esta pregunta sin ninguna explicación. Aquí está la pregunta: Dado una función $f(x)=\frac{9^{x}}{9^x+3}$, ¿qué es $f(\frac{1}{27})+ f(\frac{2}{27}) + f(\frac{3}{27})+ ...+ f(\frac{26}{27})$? La respuesta fue 13. Tomé un enfoque muy malo y convertí $\frac{9^{x}}{9^x+3}$ a $1+\frac{9^{x}}{3}$, lo que luego noté que estaba mal. También accidentalmente multiplicé $9^{\frac{1}{27}}$ con $9^{\frac{2}{27}}$, $9^{\frac{2}{27}}$ con $9^{\frac{3}{27}}$, etc., antes de darme cuenta de que las funciones se agregaron y no se multiplicaron. Sospecho que hay algo con la potencia de $\frac{n}{27}$, porque 9 es un múltiplo de 27. Sin embargo, no estoy completamente seguro. ¿Hay una ley que me diga cómo puedo resolver esta pregunta?	functions,contest-math,power-series,fractions
A.312	Proving $\left\lfloor \frac{\left\lfloor a/b \right\rfloor}{c} \right\rfloor=\left\lfloor\frac{a}{bc}\right\rfloor$ for positive integer $a$, $b$, $c$	How can we prove the following? $$\left\lfloor \frac{\left\lfloor \dfrac{a}{b} \right\rfloor}{c} \right\rfloor = \left\lfloor \frac{a}{bc} \right\rfloor$$ for $a,b,c \in \mathbb{Z}^+$  I don’t know if I’m doing something wrong, but I can’t prove it even though I’m pretty sure it’s true. Obviously, because the concept of algebra isn’t aware of the fact that we are restricting the variables to positive integers, and given my assumption that the equality doesn’t necessarily hold for non-integers, an element of non-algebraic problem solving is needed, i.e. making a change to the expression given our knowledge of that condition, which then allows for algebraic maneuvers that show that the equality holds. I think that’s what I’m missing. Thanks.	Prueba de $\left\lfloor \frac{\left\lfloor a/b \right\rfloor}{c} \right\rfloor=\left\lfloor\frac{a}{bc}\right\rfloor$ para el número entero positivo $a$, $b$, $c$	¿Cómo podemos probar lo siguiente? $$\left\lfloor \frac{\left\lfloor \dfrac{a}{b} \right\rfloor}{c} \right\rfloor = \left\lfloor \frac{a}{bc} \right\rfloor$$ para $a,b,c \in \mathbb{Z}^+$ No sé si estoy haciendo algo mal, pero no puedo probarlo aunque estoy bastante seguro de que es cierto. Obviamente, debido a que el concepto de álgebra no es consciente del hecho de que estamos restringyendo las variables a números enteros positivos, y dado mi suposición de que la igualdad no se aplica necesariamente a los no integrales, un elemento de solución no algebraica problema es necesario, es decir, gracias a un cambio de nuestro conocimiento de esa condición, que permite entonces que la expresión algebraica que hace falta para los eversos que yo creo que muestra que se mantiene.	elementary-number-theory,proof-writing,ceiling-and-floor-functions
A.313	Let $a,b\in G$, a finite abelian group and $|a|=r, |b|=s$ with $\gcd(r,s)=1$. Prove that $|ab|=rs$.	Let $a,b\in G$, a finite abelian group and $|a|=r, |b|=s$ with $\gcd(r,s)=1$. Prove that $|ab|=rs$.  My attempt: Let $|ab|=n$. Since $G$ is ableian, $(ab)^n=a^nb^n=1$. Thus $r\mid n$ and $s\mid n$. Together with $\gcd(r,s)=1$, it follows that $rs\mid n$. This is where I'm stuck; need to show that $rs=n$. Any hints on how to proceed? Edit: I've come up with a solution that is a somewhat different approach to what has been provided in the hints. Here it goes: Since $G$ is abelian, $n\mid{\rm lcm}(r,s)$. But since $\gcd(r,s)=1$, ${\rm lcm}(r,s)=rs$ by an elementary result in number theory. Thus $n\mid rs$. Together with $rs\mid n$, we have that $n=rs$, which is what we want to prove.	Vamos a $a,b\in G$, un grupo abeliano finito y $|a|=r, |b|=s$ con $\gcd(r,s)=1$.	Así que $r\mid n$ y $s\mid n$. Junto con $\gcd(r,s)=1$, se sigue que $a,b\in G$0. Aquí es donde estoy atrapado; necesito mostrar que $a,b\in G$1. ¿Alguna pista sobre cómo proceder? Editar: He encontrado una solución que es un enfoque algo diferente a lo que se ha proporcionado en las pistas. Aquí va: Desde $G$ es abeliano, $a,b\in G$2. Pero desde $\gcd(r,s)=1$, $a,b\in G$3 por un resultado elemental en teoría de números. Así $a,b\in G$4. Junto con $a,b\in G$0, tenemos que $a,b\in G$5, que es lo que queremos probar.	group-theory,finite-groups,abelian-groups
A.314	Closed span of a sequence in Hilbert spaces.	Suppose that you have an orthonormal basis $\{e_n\}$ in a Hilbert space such that $\sum \|e_n-x_n\| < 1$. Is this condition enough to prove that the closed span of $\{x_n\}$ is $H$? My efforts to prove this have not led anywhere promising. I have tried showing that the only vector perpendicular to all of the $x_n$ would be $0$. Not sure which way I can proceed. Does anyone have an idea how to approach this? Thank you.	Espacio cerrado de una secuencia en espacios Hilbert.	Supongamos que tienes una base ortónormal $\{e_n\}$ en un espacio de Hilbert tal que $\sum \|e_n-x_n\| < 1$. ¿Es esta condición suficiente para probar que el espacio cerrado de $\{x_n\}$ es $H$? ¿Mis esfuerzos para probar esto no han llevado a nada prometedor. He intentado mostrar que el único vector perpendicular a todos los $x_n$ sería $0$. No estoy seguro de qué manera puedo proceder. ¿Alguien tiene una idea de cómo abordar esto?	functional-analysis,hilbert-spaces
A.315	Backwards Induction (Exercise 2.2.6) Analysis 1 by Terence Tao	I am new to the study of analysis and I decided to start with Terence's book in my endeavor. I want to show my "proof" of backwards induction since I have some difficulty in understanding this. I want to now if my proof is correct or have some error, because if have,$a $can't infer that. Any feedback is appreciated.   Let $n$ be a natural number, and let $P(m)$ be a property pertaining to the natural numbers such that whenever $P(m\text{++})$ is true, then $P(m)$ is true. Suppose that $P(n)$ is also true. Prove that $P(m)$ is true for all natural numbers $m ≤ n$; this is known as the principle of backwards induction. (Hint: apply induction to the variable $n$.)  First i want to show $P(m)$ is true $\forall$ $0\geq m$. H1: $\forall m$ $P(m\text{++})\implies P(m)$ H2: $P(0)$ C: $P(m)$ is true $\forall$ $0\geq m$. $0\geq m$ means $0=m+a$ for some natural number $a$, then $m=a=0$ for corollary 2.2.9. But $P(0)$ is true for H2, then the case $n=0$ is proved. Suppose now that works for $n$ and prove $n\text{++}$. then: H1: $\forall m$ $P(m\text{++})\implies P(m)$ H2: $P(n)\implies P(m)$ $\forall$ $n\geq m$ H3: $P(n\text{++})$. In H1, for $m=n$ we have $P(n\text{++})\implies P(n)$ and for H2 we now $P(n)\implies P(m)$ (specifically for $n=m$), then $P(n\text{++})\implies P(m)$ for $n\text{++}>m$. We need to prove that works for $n\text{++}=m$ but for that $P(n\text{++})$ is true for H3. We conclude that $P(n\text{++})\implies P(m)$ $\forall$ $n\text{++}\geq m$.	Inducción hacia atrás (Ejercicio 2.2.6) Análisis 1 de Terence Tao	Quiero mostrar mi "prueba" de inducción hacia atrás ya que tengo alguna dificultad para entender esto. Quiero ahora si mi prueba es correcta o tiene algún error, porque si lo he hecho,$a $no puede inferir eso. Cualquier retroalimentación es apreciada. Que $n$ sea un número natural, y que $P(m)$ sea una propiedad relativa a los números naturales de tal manera que siempre que $P(m\text{++})$ sea verdad, entonces $P(m)$ sea verdad. Supongamos que $P(n)$ también es verdad. Pruebe que $P(m)$ es verdad para todos los números naturales $m ≤ n$; esto se conoce como el principio de inducción hacia atrás. (Intenciones: aplicar inducción a la variable $n$.) Primero quiero mostrar $P(m)$ es verdad $\forall$8. H1: $\forall m$ H2: $a $1 H: $a $5 $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ H: $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ $\forall$ XXX	real-analysis,solution-verification,induction
A.316	Multiplicative of group of odd numbers modulo power of two	I want to understand the group structure of the group of units in the ring $\mathbb{Z}/2^m \mathbb{Z}$ for positive integers $m$. I expect this has been answered before here on MSE, but so far the automatic suggestions didn't turn it up. Here is what I understand: it is an abelian group, hence a product of cyclic ones. Also the order of this group is $2^{m-1}$ so that the orders of the factors in the product are all powers of two by Lagrange's theorem. Now these conditions are restrictive enough to compute the first few cases by hand. We have $(\mathbb{Z}/2 \mathbb{Z})^* = C_1$, $(\mathbb{Z}/4 \mathbb{Z})^* = C_2$, $(\mathbb{Z}/8 \mathbb{Z})^* = C_2 \times C_2$, $(\mathbb{Z}/16 \mathbb{Z})^* = C_2 \times C_4$, $(\mathbb{Z}/32 \mathbb{Z})^* = C_2 \times C_8$. I'm starting to believe that for $m > 1$ we have that $(\mathbb{Z}/2^m \mathbb{Z})^* = C_2 \times C_{2^{m-2}}$ but is there a simple conceptual explanation for that (if true)?	Multiplicador del grupo de números impares modulo potencia de dos	Quiero entender la estructura de grupo del grupo de unidades en el anillo $\mathbb{Z}/2^m \mathbb{Z}$ para los números enteros positivos $m$. Espero que esto haya sido contestado antes aquí en MSE, pero hasta ahora las sugerencias automáticas no lo han hecho. Aquí es lo que entiendo: es un grupo abeliano, por lo tanto un producto de los cíclicos. También el orden de este grupo es $2^{m-1}$ de modo que los órdenes de los factores en el producto son todos poderes de dos por el teorema de Lagrange. Ahora estas condiciones son lo suficientemente restrictivas como para calcular los primeros casos a mano. Tenemos $(\mathbb{Z}/2 \mathbb{Z})^* = C_1$, $(\mathbb{Z}/4 \mathbb{Z})^* = C_2$, $(\mathbb{Z}/8 \mathbb{Z})^* = C_2 \times C_2$, $(\mathbb{Z}/16 \mathbb{Z})^* = C_2 \times C_4$, $(\mathbb{Z}/32 \mathbb{Z})^* = C_2 \times C_8$. Estoy empezando a creer que para $m > 1$ tenemos ese $\mathbb{Z}/2^m \mathbb{Z}$0 pero ¿hay una explicación conceptual simple para eso (si es verdad)?	elementary-number-theory
A.317	$\int \frac{1}{\left(x^2+1\right)^n}dx$	Let be $n\in \mathbb{Z_+}$. Compute the following integral: $$\int \frac{1}{\left(x^2+1\right)^n}dx$$ I obtained that for $$n=1$$ the value of the integral is $$\tan^{-1}x+C$$ and for $$n=2$$ $$x\left(\frac{1}{2\left(x^2+1\right)}+\frac{\tan \:^{-1}}{2x}\right)+C$$ How to do the rest of the cases?	$\int \frac{1}{\left(x^2+1\right)^n}dx$	Calcule la siguiente integral: $$\int \frac{1}{\left(x^2+1\right)^n}dx$$ Obtuve que para $$n=1$$ el valor de la integral es $$\tan^{-1}x+C$$ y para $$n=2$$ $$x\left(\frac{1}{2\left(x^2+1\right)}+\frac{:^{-1}}{2x}\right) +C$$ ¿Cómo hacer el resto de los casos?	integration
A.318	How do you prove $e^{x} \geq \left(1+\frac{x}{n}\right)^{n}$ for $n \geq 1$	How do you prove $e^{x} \geq \left(1+\frac{x}{n}\right)^{n}$ for $n \geq 1$? I can prove this for natural numbers only via induction, but how do you prove this for any real $n \geq 1$? We start with the base case $n=1$. We have $e^x \geq 1+x$ by a variety of methods. For the induction step, assume $e^{x} \geq \left(1+\frac{x}{n}\right)^{n}$. Notice that taking the derivative of $(1+\frac{x}{n+1})^{n+1}$ gives us $(1+\frac{x}{n+1})^{n}$ and thus $(1+\frac{x}{n+1})^{n} < \left(1+\frac{x}{n}\right)^{n} \leq e^x = \frac{d}{dx} e^x$. I'm not sure how to extend this to the non-integer case. Any help would be appreciated.	¿Cómo se prueba $e^{x} \geq \left(1+\frac{x}{n}\right)^{n}$ para $n \geq 1$	¿Cómo se prueba $e^{x} \geq \left(1+\frac{x}{n}\right)^{n}$ para $n \geq 1$? Puedo probar esto para números naturales sólo a través de la inducción, pero cómo se prueba esto para cualquier $n \geq 1$ real? Comenzamos con el caso base $n=1$. Tenemos $e^x \geq 1+x$ por una variedad de métodos. Para el paso de inducción, suponga $e^{x} \geq \left(1+\frac{x}{n}\right)^{n}$.	calculus
A.319	A wrong argument for $\mathbb{R}$ being countable	We assume $A$ is the set of all countable subsets of the set of real numbers. We know $A$ is a partially ordered set $(A, \subseteq)$. Suppose $$A_1 \subseteq A_2 \subseteq \ldots \subseteq A_n \subseteq A_{n+1} \subseteq \ldots$$ is a chain in $A$. We can prove $B=\bigcup_{n \in \Bbb{N}} A_n$ is a countable set. For each natural number $m$, we have $A_m \subseteq B$. So $B$ is an upper bound for $A$. This shows each chain in $A$ has an upper bound according to Zorn's lemma. $A$ has a maximal element $X$, and we know $X$ is a countable set. Now we prove $X = \Bbb{R}$. If $X \neq \Bbb{R}$, then there is an $x \in \Bbb{R}$ such that $x \notin X$. Let $Y=X \cup \{x\}$. It's obvious that $Y$ is a countable subset of the real numbers and $X \subsetneq Y$. This contradicts $X$ being a maximal element. Thus, $X = \Bbb{R}$ and $\Bbb{R}$ is a countable set. What is wrong with this argument?	Un argumento equivocado para que $\mathbb{R}$ sea contable	Suponemos que $A$ es el conjunto de todos los subconjuntos contables del conjunto de números reales. Sabemos que $A$ es un conjunto parcialmente ordenado $(A, \subseteq)$. Suponemos que $$A_1 \subseteq A_2 \subseteq \ldots \subseteq A_n \subseteq A_{n+1} \subseteq \ldots$$ es una cadena en $A$. Podemos demostrar que $B=\bigcup_{n \in \Bbb{N}} A_n$ es un conjunto contable. Para cada número natural $m$, tenemos $A_m \subseteq B$. Así que $B$ es un límite superior para $A$. Esto muestra que cada cadena en $A$ tiene un límite superior de acuerdo con el lema de Zorn. $A$ tiene un elemento máximo $X$, y sabemos que $X$ es un conjunto contable. Ahora probamos que $X = \Bbb{R}$. Si $A$0, entonces hay un argumento de que $A$1 es que $A$2.	elementary-set-theory,cardinals
A.320	An inverse trigonometric integral	So my integral is $$\int_{0}^{1}\frac{\sin^{-1}(x)}{x}$$ To avoid confusion let me re-write the integral as $$\mathcal I = \int_0^1 \frac{\arcsin(x)}{x}$$ I started off with a trig-substitution that is let $x = \sin(t)$ and $t = \arcsin(x)$ which means that $dx = \cos(t) dt$ So our integrand becomes $$\mathcal I = \int_0^{\frac{\pi}{2}} \frac{t}{\sin(t)} \cos(t) dt\tag{Bounds have changed}$$ $$= \int_0^{\frac{\pi}{2}} t\space\cot(t) dt$$ Then using Integration by Parts,$\space$$u = t$ $\implies du = dt$ and $dv = \cot(t)$ $\implies v = \ln(\sin(t))$ So our integrand thus becomes, $= t\space\ln(\sin(t))$ from $0$ to $\frac{\pi}{2}$ $$-\int_0^{\frac{\pi}{2}} \ln(sin(t))dt\tag{t*ln(sin(t)) = 0}$$ From here, I don't know how to proceed further. Any help/hint is appreciated :) Thanks in advance	Una integral trigonómica inversa	Así que mi integral es $$\int_{0}^{1}\frac{\sin^{-1}(x)}{x}$$ Para evitar la confusión, permítanme reescribir la integral como $$\mathcal I = \int_0^1 \frac{\arcsin(x)}{x}$$ Comencé con una trigosubstitución que es dejar $x = \sin(t)$ y $t = \arcsin(x)$ lo que significa que $dx = \cos(t) dt$ Así que nuestro integrando se convierte en $$\mathcal I = \int_0^{\frac{\frac{\frac}{2}} \cotc{t}{\cossin}} {dt} \dt} dt\tag{Bounds have changed}$$ $$= \int_0{\frac{\pi}{t2}} t\t\s\t\s\t} } }Toda gracias por la continuación de $$} Así que cualquier integración por las partes, y así que $$\t\s} y $$\s} así que se utiliza para ayudar a $$\s}	integration,definite-integrals,trigonometric-integrals
A.321	Solve Equation $ax+by=d$ where $d \neq \gcd(a,b)$ using Bézout	I want to solve this equation: $3x+4y=14$ I present you what I have so far: $\gcd(3,4)=1$ which is not $14$. I notice that: $3(6) + 4(-1) =14$ So using Bézout : $3(6-4k) + 4(-1+3k) = 14 (1)$, where $k$ integer. So we have $k>1/3$ and $k<3/2$. So $k = 1$. By replacing $k$ in equation $(1)$ we get: $a=2, b=2$, which indeed solves the equation. However, I dont get my previous solution $(a,b)=(4,-1)$ which is also correct. Am I applying Bézout wrong? Or am I not supposed to find the solution that I used to find the new ones, if they exist? Do I have $2$ solutions and that's it or am I missing something? Thank you.	Resolver la ecuación $ax+by=d$ donde $d \neq \gcd(a,b)$ usando Bézout	Quiero resolver esta ecuación: $3x+4y=14$ Te presento lo que tengo hasta ahora: $\gcd(3,4)=1$ que no es $14$. Observo que: $3(6) + 4(-1) =14$ Así que usando Bézout: $3(6-4k) + 4(-1+3k) = 14 (1)$, donde $k$ es un número entero. Así que tenemos $k>1/3$ y $k<3/2$. Así que $k = 1$. Al reemplazar $k$ en la ecuación $3x+4y=14$0 obtenemos: $3x+4y=14$1, que realmente resuelve la ecuación. Sin embargo, no obtengo mi solución anterior $3x+4y=14$2 que también es correcta. ¿Estoy aplicando Bézout incorrectamente? ¿O no se supone que encuentre la solución que solía encontrar para encontrar las nuevas, si existen? ¿Tengo $3x+4y=14$3 soluciones y eso es o estoy perdiendo algo? Gracias.	elementary-number-theory,solution-verification
A.322	How do I calculate the sum of sum of triangular numbers?	As we know, triangular numbers are a sequence defined by $\frac{n(n+1)}{2}$. And it's first few terms are $1,3,6,10,15...$. Now I want to calculate the sum of the sum of triangular numbers. Let's define $$a_n=\frac{n(n+1)}{2}$$ $$b_n=\sum_{x=1}^na_x$$ $$c_n=\sum_{x=1}^nb_x$$ And I want an explicit formula for $c_n$. After some research, I found the explicit formula for $b_n=\frac{n(n+1)(n+2)}{6}$. Seeing the patterns from $a_n$ and $b_n$, I figured the explicit formula for $c_n$ would be $\frac{n(n+1)(n+2)(n+3)}{24}$ or $\frac{n(n+1)(n+2)(n+3)}{12}$. Then I tried to plug in those two potential equations, If $n=1$, $c_n=1$, $\frac{n(n+1)(n+2)(n+3)}{24}=1$, $\frac{n(n+1)(n+2)(n+3)}{12}=2$. Thus we can know for sure that the second equation is wrong. If $n=2$, $c_n=1+4=5$, $\frac{n(n+1)(n+2)(n+3)}{24}=5$. Seems correct so far. If $n=3$, $c_n=1+4+10=15$, $\frac{n(n+1)(n+2)(n+3)}{24}=\frac{360}{24}=15$. Overall, from the terms that I tried, the formula above seems to have worked. However, I cannot prove, or explain, why that is. Can someone prove (or disprove) my result above?	¿Cómo calculo la suma de la suma de números triangulares?	Ahora quiero calcular la suma de la suma de los números triangulares. Vamos a definir $$a_n=\frac{n(n+1)}{2}$$ $$b_n=\sum_{x=1}^na_x$$ $$c_n=\sum_{x=1}^nb_x$$ Y quiero una fórmula explícita para $c_n$. Después de algunas investigaciones, encontré la fórmula explícita para $b_n=\frac{n(n+1)(n+2)}{6}$. Viendo los patrones de $a_n$ y $b_n$, pensé que la fórmula explícita para $c_n$ sería $\frac{n(n+1)(n+2)(n+3)}{24}$ o $\frac{n(n+1)(n+2)(n+3)}{12}$.	sequences-and-series,triangular-numbers
A.323	How to use the Euclidean Algorithm to find the inverse of $\overline{x^2 -x}$ in $(\mathbb{R} [x]/(x^4 + 1))^*$?	I've tried a lot with the Euclidean Algorithm, but I still can't figure it out. Do you know how I can use the Euclidean Algorithm to find the inverse of $\overline{x^2 -x}$ in $(\mathbb{R} [x]/(x^4 + 1))^*$? Thanks in advance!	¿Cómo usar el algoritmo euclidiano para encontrar la inversa de $\overline{x^2 -x}$ en $(\mathbb{R} [x]/(x^4 + 1))^*$?	He intentado mucho con el algoritmo euclidiano, pero todavía no puedo averiguarlo. ¿Sabes cómo puedo usar el algoritmo euclidiano para encontrar la inversa de $\overline{x^2 -x}$ en $(\mathbb{R} [x]/(x^4 + 1))^*$? Gracias por adelantado!	abstract-algebra,ring-theory,inverse,euclidean-algorithm
A.324	The Double Basel Problem	I have been playing with the series which I had been calling the 'Double Basel problem' for the past couple of hours $$ \sum_{n=1}^{\infty} \sum_{m=1}^\infty \frac{1}{{n^2 +m^2}}. $$ After wrestling with this for awhile, I managed to generalize a result demonstrated here. This identity is: $$ \sum_{m=1}^{\infty}\frac{1}{x^2+m^2} = \frac{1}{2x}\left[ \pi \coth{\pi x} - \frac{1}{x}\right]. $$ Hence the original series becomes: $$ \sum_{n=1}^{\infty} \frac{1}{2n}\left[\pi \coth{\pi n} - \frac{1}{n} \right]. $$ I have no idea where to go next with this problem.  I seriously doubt that this series is convergent; however, I have been unable to prove it.  Can you prove that this series is divergent? If it converges what is its value?  Thanks so much!	El problema de Basilea	He estado jugando con la serie que había estado llamando el "problema de doble Basilea" durante las últimas horas $$ \sum_{n=1}^{\infty} \sum_{m=1}^\infty \frac{1}{{n^2 +m^2}}. $$ Después de luchar con esto durante un tiempo, logré generalizar un resultado demostrado aquí. Esta identidad es: $$ \sum_{m=1}^{\infty}\frac{1}{x^2+m^2} = \frac{1}{2x}\left{ \pi \coth{\x} - \frac{1}{x}\right}. $$ Así que la serie original: $$ \_{n}\n} ¡Gracias a la convergencia de la serie es tan divergente que no puedo probar que esta serie es tan divergente con la serie $$\n} {n} {n} {n} {n} {n} } {n} {n} {n} {n} } {n} {n} {n} } {n} {n} } {n} {n} } } {n} {n} {n} } } {n} {n} {n} } } } {n} {n} {n} {n} } } } {n} {n} {n} } } } } } {n} {n} {n} {n}} {n}} {n}} {n}}} {n}} {n}}} {n}}} {n}}} {n}} {n}}}} {n}}} {n}}}{n}{n}{n}{n}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}}{}{}{}{}{}{}}{}{}{}}}{}{}}{}{}{}{}{}{}{}{}{}{}{}{}}}{}{}{}{}{}{}{}}{}{}{}{}{}{}{}}{}}{}{}{}{}{}{}{}{}}}}{}{}{}{}{}{}{}{}{}{}}}{}{}{}}{}{}}}{}{}{}{}{}{}}{}{}{}}{}{}{}}{}{}{}}}{}}{}{}{}}{}{}{}{}{}{}}}}{}{}{}{}{}}{}}}{}{}}}{}{}{}{}{}{}{}{}{}{}{}}{}{}{}}{}{}{}}}{}{}{}{}}{}{}}}{}{}{}}}{}{}{}{}{}{}{}{}{}}}{}{}{}{}{}{}{}{}}}}}{}{}{}{}{}{}{}{}}}{}{}{}}{}{}{}}}}{}{}}}{}{}{}}{}{}{}}}{}{}{}}}{}{}{}}{}{}}}}}{}{}{}{}{}{}{}{}{}}{}{}{}}{}{}{}{}{}}}}{}{}}}}}{}{}{}{}}{}{}{}{}}{}{}{}{}}}{}{}}{}{}{}{}{}}{}{}{}{}{}{}}}}{}{}}}}{}{}{}	sequences-and-series,fourier-series,harmonic-numbers
A.325	Find consecutive composite numbers	How to find 100 consecutive composite numbers? After many attempts I arrived at the conclusion that to find $m$ consecutive composite numbers we can use this $n!+2, n! +3, ..., n! + n$ where $n! + 2$ is divisible by $2$, $n! + 3$ is divisible by $3$ and so on... and where $m$ = $n-1$ Thus $n!+2, n! +3, ..., n! + n$ tells that there are $(n-1)$ consecutive numbers. However, there seems to be some gaps or incompetence. For example: $4!+2, 4! +3, 4! +4$ $→$ $26, 27, 28$. Although it's right there are for sure smaller numbers such as $8, 9, 10$ and $14, 15 ,16.$ Is there another method for solving such a problem mathematically? Is it a correct method or have I misunderstood it?	Encuentra números compuestos consecutivos	¿Cómo encontrar 100 números compuestos consecutivos? Después de muchos intentos llegué a la conclusión de que para encontrar $m$ números compuestos consecutivos podemos usar este $n!+2, n! +3, ..., n! + n$ donde $n! + 2$ es divisible por $2$, $n! + 3$ es divisible por $3$ y así sucesivamente... y donde $m$ = $n-1$ Así que $n!+2, n! +3, ..., n! + n$ dice que hay $(n-1)$ números consecutivos. Sin embargo, parece que hay algunas lagunas o incompetencia. Por ejemplo: $4!+2, 4! +3, 4! +4$ $m$0 $m$1. Aunque es cierto que hay números más pequeños como $m$2 y $m$3 ¿Existe otro método para resolver tal problema matemáticamente? ¿Es un método correcto o lo he entendido mal?	number-theory,prime-numbers
A.326	Every projective module is a direct summand of free module.	I was reading "Serial Rings" by Gennadi Puninski. There it is written that , "Since every module is a homomorphic image of a free module, every projective module is a direct summand of free module".(ie. if $P$ is a  projective module, there exists a free module F such that, $ F=P \oplus T$ for some module $T$.) But I can't understand how "Every module is a homomorphic image of a free module" implies that "Every projective module is a direct summand of free module". (I have found a proof for "Every projective module is a direct summand of free module" but the first part of the above mentioned sentence wasn't used there.)	Cada módulo proyectivo es una suma directa de módulos libres.	Estaba leyendo "Serial Rings" de Gennadi Puninski. Allí se escribe que , "Dado que cada módulo es una imagen homomorfa de un módulo libre, cada módulo proyectivo es una suma directa de módulo libre".	modules,direct-sum,projective-module,free-modules
A.327	Determinant not equal to volume error (closed)	The determinant of a $3\times 3$ matrix $\begin{vmatrix} 1 & 1 &1 \\  x & y & z \\ x^2 & y^2 &z^2 \\ \end{vmatrix} $ is the volume of a parallelopiped with its three sides as the vectors whose tails rest on origin and heads at the coordinates $(1,x,x^2),(1,y,y^2)$ and $(1,z,z^2)$ $^{[1]} $. The determinant of this matrix can be simplified to $(x-y)(y-z)(z-x)$.  Proof: Subtracting column$1 $from column 2, and putting that in column  2, $\begin{equation*} \begin{vmatrix} 1 & 1 &1 \\  x & y & z \\ x^2 & y^2 &z^2 \\ \end{vmatrix}  =  \begin{vmatrix} 1 & 0 &1 \\  x & y-x & z \\ x^2 & y^2-x^2 &z^2 \\ \end{vmatrix}  \end{equation*}$ $ = z^2(y-x)-z(y^2-x^2)+x(y^2-x^2)-x^2(y-x) $ rearranging the terms, $ =z^2(y-x)-x^2(y-x)+x(y^2-x^2)-z(y^2-x^2) $ taking out the common terms $(y-x)$ and $(y^2-x^2)$, $ =(y-x)(z^2-x^2)+(y^2-x^2)(x-z) $ expanding the terms $(z^2-x^2)$ and $(y^2-x^2)$ $ =(y-x)(z-x)(z+x)+(y-x)(y+x)(x-z) $ $ =(y-x)(z-x)(z+x)-(y-x)(z-x)(y+x) $ taking out the common term $(y-x)(z-x)$ $ =(y-x)(z-x) [z+x-y-x] $ $ =(y-x)(z-x)(z-y) $ $ =(x-y)(y-z)(z-x) $  As the $x$ coordinate of the heads of these three vectors is $1$, the head of these vectors lies in a plane perpendicular to the $x$-axis and a distance of $1$ unit away from the origin. (If we connect these three points, we get a triangle.) This plane will cut the parallelopiped into two equal triangular pyramids whose base lies in the plane. The perpendicular distance from the base of the pyramid to the tip is $1$ unit. The volume of the required parallelogram is the sum of the volume of the two triangular pyramids. $\text{volume of a pyramid}=\frac{1}{3}bh$. The height is $1$ units. The area of a triangle is, by Shoelace formula, $$A = \frac{1}{2} \begin{vmatrix} 1 & 1 &1 \\  x_1 & x_2 & x_3 \\ y_1 & y_2 & y_3 \\ \end{vmatrix} $$ where the vertices of the triangle are $(x_1,y_1),(x_2.y_2),(x_3,y_3)$ $^{[2]}$ The vertices of the required traingle has the coordinates $(x,x^2),(y,y^2)$ and $(z,z^2)$. So the area of the triangle, $$A=\frac{1}{2}\begin{vmatrix} 1 & 1 &1 \\  x & y & z \\ x^2 & y^2 &z^2 \\ \end{vmatrix}$$ which, as shown above, can be simplified to $\frac{1}{2} (x-y)(y-z)(z-x)$ So, the volume is $$\frac{1}{3}bh=\frac{1}{3}\times\frac{1}{2}(x-y)(y-z)(z-x)\times 1$$ $$= \frac{1}{6}(x-y)(y-z)(z-x)  $$ But, shouldn't the volume be equal to the determinant which is $(x-y)(y-z)(z-x)$ ?  References [1]Youtube video by 3Blue1brown: https://youtu.be/Ip3X9LOh2dk?t=345 [2]Wikipedia article:https://en.wikipedia.org/wiki/Shoelace_formula	Determinante no igual al error de volumen (cerrado)	El determinante de una matriz $3\times 3$ $\begin{vmatrix} 1 & 1 &1 \\  x & y & z \\ x^2 & y^2 &z^2 \\ \end{vmatrix} $ es el volumen de una paralelopiped con sus tres lados como los vectores cuyas colas se apoyan en el origen y las cabezas en las coordenadas $(1,x,x^2),(1,y,y^2)$ y $(1,z,z^2)$ $^{[1]} $. El determinante de esta matriz se puede simplificar a $(x-y)(y-z)(z-x)$. Prueba: Subtraer la columna $1 $ de la columna 2, y ponerlo en la columna 2, $\begin{equation*} \begin{vmatrix} 1 & 1 &1 \\  x & y & z \\ x^2 & y^2 &z^2 \\ \end{vmatrix}  =  \begin{vmatrix} 1 & 0 &1 \\  x & y-x & z \\ x^2 & y^2-x^2 &z^2 \\ \end{vmatrix}  \end{equation*}$ $ = z^2(y-x)-z(y^2-x^2)+x(y^2-x^2)-x^2(y-x) $ reorganizando los términos, $3\times 3$0 extrayendo los términos comunes $3\times 3$1 y $3\times 3$2, $3\times 3$3 expandiendo los términos $3\times 3$4 y $3\times 3$2 $3\times 3$5 \\16} {{}{}{}{}{}{}{}{}{}{}{}{}{}{}}{}{}{}}{}{}}{}{}}{}{}}{}}{}{}}{}{}}{}}{}}{}{}}{}}{}}{}}{}}{}}{}}{}}{}}{}}{}}{}}{}}}{}}{}}}{}}{}}}{}}{}}{}}{}}}{}}{}}}{}}{}}}{}}{}}{}}}{}}{}}{}}}{}}{}}{}}}{}}{}}}{}}}{}}}{}}{}}}{}}{}}{}}}{}}{}}}{}}{}}}}{}{}}{}}}{}}}{}}{}}}{}{}}}}{}{}}}}{}{}}}}{}}{}}}{}}}}{}}{}}}{}}{}}}{}{}}}}{}{}}}}{}{}}}}{}{}}}}{}{}}}{}}}}{}{}{}}}}}{}{}}}{}}{}}}}{}}}{}}{}}}}}{}{}}}{}{}}}}{}{}}}}{}}{}}}{}{}}}}{}{}}}}}{}{}}}}{}{}}}}}}{}{}}}{}}{}}{}}{}}}}}{}{}{}}}}}{}{}}}}{}{}}}{}}}{}{}{}}}}}}{}{}}}}}{}{}{}{}}}}}}}{}{}{}}}}}}{}{}{}}}}}{}{}{}{}}}}}}}{}{}{}}}{}}}}{}{}}}}{}{}}}}{}{}{}}}}{}{}}}}{}{}}}{}{}{}}}}}{}{}{}{}}}{}}}}{}{}{}}}{}{}}{}{}{}}}{}{}}}}}{}}}}{}{}}}}{}{}}}}}{}}}{}{}{}{}{}}}}}{}{}}}{}{}}}}}{}{}}}}{}{}}}}{{}{}}}}{}{}}}}{}{}}}}{}{}}}}}{{}{}{{}}}}}}{{}}{}{}{}}}}{{}}}}}{{}}}}}{}}{{{}}{}}}}}}{}}}}}{{{{{}}}}}}}}}}{{{{{{{}}}}}}}}}}{{{{{{}}}}}}}}}}}}}}}{{{{{	geometry,determinant
A.328	Proving $\sum_{k=1}^{n}\cos\frac{2\pi k}{n}=0$	I want to prove that the below equation can be held.  $$\sum_{ k=1 }^{ n  } \cos\left(\frac{  2 \pi k }{  n  } \right) =0, \qquad n>1 $$  Firstly I tried to check the equation with small values of $n$ $$  \text{As } n=2 $$ $$  \cos\left(\frac{  2 \pi \cdot 1   }{  2  } \right) + \cos\left(\frac{  2 \pi \cdot 2   }{  2   } \right)  $$ $$ = \cos\left(\pi\right)  + \cos\left(2 \pi\right)    $$ $$ = -1+ 1 =0  ~~ \leftarrow~~ \text{Obvious}  $$ But $$  \text{As}~~ n=3  $$ $$  \cos\left(\frac{  2 \pi \cdot  1   }{  3   } \right) +\cos\left(\frac{  2 \pi  \cdot  2   }{  3   } \right) + \cos\left(\frac{  2 \pi  \cdot  3   }{  3   } \right)  $$ $$ = \cos\left(\frac{  2 \pi  }{  3  } \right) + \cos\left(\frac{  4 \pi  }{  3  } \right) + \cos\left( 2\pi \right)  $$ $$ = \cos\left(\frac{  2 \pi  }{  3  } \right) + \cos\left(\frac{  4 \pi  }{  3  } \right) + 1  =?$$ What formula(s) or property(s) can be used to prove the equation?	Prueba de la $\sum_{k=1}^{n}\cos\frac{2\pi k}{n}=0$	Quiero probar que la ecuación de abajo puede ser sostenida. $$\sum_{ k=1 }^{ n } \cos\left\(frac{ 2 \pi \cdot 2 }{ n } \right) =0, \qquad n>1 $$ Primero intenté comprobar la ecuación con pequeños valores de $n$ $$ \text{As } n=2 $$ $$ \cos\left((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((	sequences-and-series,trigonometry,trigonometric-series
A.329	How do I show that if $A$ is compact and $U \supseteq A$ is open, then there is an open $V$ with $A \subseteq V \subseteq \overline{V} \subseteq U$?	This question is from Wayne Patty's Topology Section 5.2.  Consider $A$ be a compact subset of a regular space and let $U$ be an open set such that $A\subseteq U$. Prove that there is an open set $V$ such that $A \subseteq  V \subseteq \overline{V} \subseteq U$.  Let $p \in A$ which implies $p \in U$. Then a result is given in   the book (Theorem 5.11): A $T_1$-space $(X, \mathcal T)$ is regular if and only if for each member $p$ of $X$ and each neighbourhood $U$ of $p$, there is a neighbourhood $V$ of $p$ such that $\overline{V}\subseteq U$. So, I got $ V \subseteq \overline{V} \subseteq U$. But I am unable to prove that $A\subseteq V \subseteq \overline{V}$. I thought that I should let $V\subseteq \overline{V} \subseteq A$ but I am not able to find a contradiction. Can you please help with that?	¿Cómo puedo mostrar que si $A$ es compacto y $U \supseteq A$ es abierto, entonces hay un $V$ abierto con $A \subseteq V \subseteq \overline{V} \subseteq U$?	Esta pregunta es de la Topología de Wayne Patty Sección 5.2. Considerar $A$ como un subconjunto compacto de un espacio regular y dejar $U$ como un conjunto abierto tal que $A\subseteq U$. Pruebe que hay un conjunto abierto $V$ tal que $A \subseteq  V \subseteq \overline{V} \subseteq U$. Que $p \in A$ que implica $p \in U$. Entonces se da un resultado en el libro (Teorema 5.11): Un $T_1$-espacio $(X, \mathcal T)$ es regular si y sólo si para cada miembro $A$0 de $A$1 y cada vecindario $U$ de $A$0, hay un vecindario $V$ de $A$0 tal que $A$2. Así que, tengo $A$3. Pero no puedo probar que $A$4. Pensé que debería dejar $A$5 pero no puedo encontrar una contradicción. ¿Puedes ayudarme con eso?	general-topology,separation-axioms
A.330	Shilov's Linear Algebra - Chapter 1, Problem 9	Calculate the $n$-th order determinant: $$\Delta= \begin{vmatrix} x&a&a&\ldots&a\\ a&x&a&\ldots&a\\ a&a&x&\ldots&a\\ \cdot&\cdot&\cdot&\ldots&\cdot\\ a&a&a&\ldots&x \end{vmatrix}$$ The answer is $\Delta=[x+a(n-1)](x-a)^{n-1}$. If we add all the other columns to the first column, we get the first multiplicative factor of the answer, and are left with the following determinant: $$\begin{vmatrix} 1&a&a&\ldots&a\\ 1&x&a&\ldots&a\\ 1&a&x&\ldots&a\\ \cdot&\cdot&\cdot&\ldots&\cdot\\ 1&a&a&\ldots&x \end{vmatrix}$$ How can we calculate this determinant to obtain the answer?	El álgebra lineal de Shilov - Capítulo 1, Problema 9	Calcule el determinante de orden $n$: $$\Delta= \begin{vmatrix} x&a&a&\ldots&a\\ a&x&a&\ldots&a\\ a&a&x&\ldots&a\\ \cdot&\cdot&\cdot&\ldots&\cdot&a&&&\ldots&a&x \end{vmatrix} $$ La respuesta es $\Delta=[x+a(n-1)](x-a)^{n-1}$. Si sumamos todas las otras columnas a la primera columna, obtenemos el primer factor multiplicativo de la respuesta, y quedamos con el determinante: $$\begin{vmatrix} 1&a&a&\ldots&a\\ 1&x&a&ldots&a&a&a&ndots 1&a&x&a&a&c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\c\d\c\c\d\d\c\d\d\d\c\d\c\d\c\d\d\c\d\d\d\c\d\d\c\d\d\d\d\d\c\d\d\d\d\d\c\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\d\\\d\d\\\\d\d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\d\\\\\\d\\\\\\\\\\\\	linear-algebra,determinant
A.331	Finding roots of $4^x+6^x=9^x$ by hand	The function $f(x)=4^x+6^x-9^x$ is such that $f(0)=1>0, f(1)=1>0, f(2)=-29$ and next $g(x)=(4/9)^x+(6/9)^x-1 \implies f'(x)<0$ for all real values of $x$. So $g(x)$ being monotonic the equation $$4^x+6^x=9^x$$ has exactly one real solution. The question is whether this real root can be found analytically by hand.	Encontrar las raíces de $4^x+6^x=9^x$ a mano	La función $f(x)=4^x+6^x-9^x$ es tal que $f(0)=1>0, f(1)=1>0, f(2)=-29$ y $g(x)=(4/9)^x+(6/9)^x-1 \implies f'(x)<0$ siguiente para todos los valores reales de $x$. Así que $g(x)$ siendo monótono la ecuación $$4^x+6^x=9^x$$ tiene exactamente una solución real. La pregunta es si esta raíz real se puede encontrar analíticamente a mano.	real-analysis
A.332	Every number can be expressed as a product of (least prime factor)*(largest integer dividing n less than n) [EDITED]	Let $L:{\Bbb N} \to {\Bbb N}$ such that $L(n) = {\text{least prime factor p of n}}$. Let $g:{\Bbb N} \to {\Bbb N}$ such that $g(n) = {\text{biggest positive integer d such that d|n and 1}} \leqslant {\text{d < n}}$. Show that:$$g(n) = \frac{n}{{L(n)}},\forall n \in {\Bbb N}{\text{ such that }}n \geqslant 2$$ My proof: Since $n \geqslant 2$, $n$ is either composite or prime. If $n$ is prime(i.e $n = p$ where $p$ is prime), then $$g(n) = 1 = \frac{p}{p} = \frac{n}{{L(n)}}$$ This is because $L(n)$ is defined as least prime factor of n. If$n $is composite, by the Fundamental Theorem of Arithmetic: "Any positive integer bigger than 1 can be expressed as a product of primes." Let $p$ be the smallest prime of the product $$n = {p_1}^{{\alpha _1}}p_2^{{\alpha _2}}...{p_m}^{{\alpha _m}},{\text{ }}i < j,{\text{ }}{p_i} < {p_j}{\text{ and }}i,j \in {{\Bbb Z}^ + }{\text{ and }}{\alpha _i} \in {{\Bbb Z}^{ \geqslant 0}}$$ That is, pick $p = p_1$. Notice that $p$ is necessarily $L(n)$ because since $p = p_1$ implies that $p|n$ and is the smallest prime that divides n. Therefore, $$p_1 = p = L(n)$$ Then, if $x = p = L(n)$, then $1 < x < n$ and $x|n$ (by definition). This implies that $$\exists y \in {{\Bbb Z}^ + }:y = \frac{n}{x} = \frac{n}{{L(n)}} = {p_1}^{{\alpha _1} - 1}{p_2}^{{\alpha _2}}...{p_m}^{{\alpha _m}}$$ But $y|n$ such that $y < n$. Implies that $y$ is the greatest integer less than$n $such that $y|n$. Now let $d = g(n)$. Since $$\frac{n}{d} = \frac{n}{{g(n)}} = m$$ then $m$ is prime and $m = p$. BWOC, If $n=md$ and $m = ab$ where $1 < a,b < m \Rightarrow n = abd \Rightarrow ad|n$. Since $1. But we found another factor of $n$ ($ad$) that divides $n$! This contradicts the definition of $d=g(n)$. Also, since $d = g(n)$ is the biggest factor of n, implies that $m = \frac{n}{d} = \frac{n}{g(n)}$ is the smallest prime factor of n. So $m = L(n) = p$. Hence, we have that $$x = m = p = L(n) = \frac{n}{g(n)} \Rightarrow g(n) = \frac{n}{p} =\frac{n}{L(n)} = y$$ or just $$g(n) = \frac{n}{L(n)}$$ Q.E.D.	Cada número puede expresarse como el producto de (factor prim mínimo) *(el mayor número entero dividido por n menos de n) [EDITED]	Muestre que: $$g(n) = \frac{n}{{{{{{L(n)}} {{{{{{L}}}}}}}} {{{{L}}}}}} {{{\text{n}} {{{Bbb N}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{n}}{\text{\text{n}}{\text{\text{n}}{\text{\text{n}}{\text{\text{n}}{\text{\text{n}}{\text{\text{n}}{\text{\text{\text{n}}{\text{\text{\text{n}}{\text{\text{n}}{\text{\text{\text{{n}}}}{\text{\text{\text{\text{\text{n}}{\text{\text{\text{\text{n}}}}}}{\text{\text{\text{\text{\text{\text{\text}}}}}{\text{\text{\text{\text{\text{\text{\text}}}}}}{\text{\text{\text{\text}}}}}{\text{\text{\text{\text}}}}}{\text{\text{\text}}{\text}}}{\text{\text{\text{\text}}}}{\text{\text}}}{\text{\text{\text}}}}{\text{\text{\text}}}}{\text{\text{\text}}}{\text{\text}}}{\text{\text{\text}}}}{\text{{{\text}}}}}{{{{{{\text}}}}}}}{{{{{{{{{\\\\t}}{\t}}{\t}}{\t}}{\t}}{{\t}}{\t}}{\t}}{{\t}}{\t}}{\t}}{{{{{{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{{{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}{\t}}}}}}{\t}}{\t}}{\t}}{n}{T}}{T}}{T}}{T}}{T}}{T}}{T}}}}{T}}{T}}{T}}{T}}{T}}{T}}{T}}{TD}}{T}}{T}}{T}}{T}}{TD}}{T}}{T}}{T}}{TD}}{T}}{T}}{T}}{TD}}{TD}}{TD}}}}{TD}}{TBb}}{TBb}}{T}}}}}}{TD}}{T}}{TD}}}}{T}}{TDAWN}}{T}}{T	elementary-number-theory
A.333	Bivariate normal density	$( X, Y)$ have a bivariate normal density centered at the origin with $E(X^2)$ = $E(Y^2) = 1$, and $E(XY) = p$ . In polar coordinates $(X, Y)$ becomes $(R,\Phi)$ where $R^2 = X^2 + Y^2$. Prove that $\Phi$ has a density given by $$\frac{\sqrt{1-p^2}}{2\pi(1-2p\sin(\varphi)\cos(\varphi))}$$ And is uniformly distributed iff $p = 0$. (To this point everything is clear) what i do not understand is how to conclude that $P\{XY > 0\} =  \frac{1}{2} +\pi^{-1} \arcsin (p)$ and $P\{XY < 0\}= \pi^{-1} \arccos (p)$.	Densidad normal bivariable	$( X, Y)$ tiene una densidad normal bivariada centrada en el origen con $E(X^2)$ = $E(Y^2) = 1$ y $E(XY) = p$ . En las coordenadas polares $(X, Y)$ se convierte en $(R,\Phi)$ donde $R^2 = X^2 + Y^2$. Pruebe que $\Phi$ tiene una densidad dada por $$\frac{\sqrt{1-p^2}}{2\pi(1-2p\sin(\varphi)\cos(\varphi))}$$ Y está distribuido uniformemente if $( X, Y)$0. (Hasta ahora todo está claro) lo que no entiendo es cómo concluir que $( X, Y)$1 y $( X, Y)$2.	probability,probability-theory,probability-distributions
A.334	logarithm proof for $a^{log_a(b)}=b$	I have tried proving for $a^{log_a(b)}=b$ , but I feel is incorrect, so how can I prove this? I have proved it as follows: $log_aa^{log_a(b)}=log_ab$ $log_a(b)log_aa= log_ab$ $log_a(b)= log_ab$	prueba de logaritmo para $a^{log_a(b)}=b$	He intentado probar para $a^{log_a(b)}=b$ , pero siento que es incorrecto, así que ¿cómo puedo probar esto?	logarithms
A.335	Matrix exponential converges to a matrix	Let $A$ be a square matrix. To show: Matrix exponential converges to some matrix $X$. $$ \lim_{N \rightarrow \infty} \sum_{k=0}^{N}\frac{A^k}{k!} =X  $$ In some proofs that I have seen it is stated that because (for a sub-multiplicative norm) $$ 0 \le  \sum_{k=0}^{\infty} \left\Vert  \frac{A^k }{k!} \right\Vert  \le  \sum_{k=0}^{N} \frac{\Vert A \Vert ^k }{k!} then the series $\sum_{k=0}^{N}\frac{A^k}{k!}$ has to be convergent. That however isn't clear to me. To me more intuitive way to show convergence would be to show that $$ \lim_{N \rightarrow \infty} \left\Vert \sum_{k=0}^{N} \frac{A^k}{k!} -X \right\Vert  =0$$ and use some intuitive matrix norm for which it is clear that all elements of $\frac{A^k}{k!} -X$ converge to zero. Any hints?	La matriz exponencial converge a una matriz	Vamos a hacer $A$ una matriz cuadrada. Para mostrar: la matriz exponencial converge a alguna matriz $X$. $$ \lim_{N \rightarrow \infty} \sum_{k=0}^{N}\frac{A^k}{k!} =X $$ En algunas pruebas que he visto se afirma que porque (para una norma sub-multiplicativa) $$ 0 \le \sum_{k=0}^{\infty} \left\\frac{A^k }{k!} \right\Vert \Vert \Vert \_sum{k=0}{N} \frac{\Vert A \k }{k!} entonces la serie $\sum_{k=0}^{N}\frac{A^k}{k!}$ tiene que ser intuivo. Sin embargo, eso no está claro para mí. ¿Para mostrarme una convergencia más intuiva para mostrar que cualquier convergencia de los elementos de la norma $$ {\n} y la matriz $$ {\n} \n} {\n} {\n} {\n} {\n} \n} {\n} {\n} {\n} {\n} {\n} {\n} {\n} {\n} {\n} {\n}\n}\n}\n}\n}	matrix-exponential
A.336	For each $n \in \mathbb{N}$, specify matrices $A, B \in \mathbb{R}^{n \times n}$ for which $A B \neq B A$ is true.	I have got the following task: (1) For each $n \in \mathbb{N}$, specify matrices $A, B \in \mathbb{R}^{n \times n}$ for which $A B \neq B A$ is true. (2) Determine $$ M:=\left\{A \in \mathbb{R}^{2 \times 2}: A B=B A \quad \forall B \in \mathbb{R}^{2 \times 2}\right\} $$ thus the matrices $A \in \mathbb{R}^{2 \times 2}$, which commute with all matrices $B \in \mathbb{R}^{2 \times 2}$. Could someone please help me with this or give me an approach? That would be very helpful. Thanks.	Para cada $n \in \mathbb{N}$, especifique las matrices $A, B \in \mathbb{R}^{n \times n}$ para las cuales $A B \neq B A$ es verdadero.	Tengo la siguiente tarea: (1) Para cada $n \in \mathbb{N}$, especifique matrices $A, B \in \mathbb{R}^{n \times n}$ para las cuales $A B \neq B A$ es verdad. (2) Determine $$ M:=\left\{A \in \mathbb{R}^{2 \times 2}: A B=B A \quad \forall B \in \mathbb{R}^{2 \times 2}\right\} $$ así las matrices $A \in \mathbb{R}^{2 \times 2}$, que se desplazan con todas las matrices $B \in \mathbb{R}^{2 \times 2}$. ¿Puede alguien por favor ayudarme con esto o darme un enfoque? Eso sería muy útil. Gracias.	linear-algebra,matrices
A.337	Suppose that all the tangent lines of a regular plane curve pass through some fixed point. Prove that the curve is part of a straight line.	Question. Suppose that all the tangent lines of a regular plane curve pass through some fixed point. Prove that the curve is part of a straight line. Prove the same result if all the normal lines are parallel. I am working on differential geometry from the book by Pressley and I have a doubt in the solution of the above question whose (brief) solution is given by: Solution: We can assume that the curve $\gamma$ is unit-speed and that the tangent lines all pass through the origin (by applying a translation to $\gamma$). Then, there is a scalar $\lambda(t)$ such that $\gamma'(t) = \lambda(t)\gamma(t)$ for all $t$. Then, $\gamma '' = \lambda'\gamma   + \lambda \gamma' = (\lambda' + \lambda^2)\gamma$. Can anyone please explain me how does this line follow : " Then, there is a scalar $\lambda(t)$ such that $\gamma'(t) = \lambda(t)\gamma(t)$ for all $t$." Thanks in advance.	Supongamos que todas las líneas tangentes de una curva plana regular pasan a través de algún punto fijo.	Pregunta. Supongamos que todas las líneas tangentes de una curva plana regular pasan a través de algún punto fijo. Pruebe que la curva es parte de una línea recta. Pruebe el mismo resultado si todas las líneas normales son paralelas. Estoy trabajando en geometría diferencial del libro de Pressley y tengo dudas en la solución de la pregunta anterior cuya (breve) solución es dada por: Solución: Podemos suponer que la curva $\gamma$ es unidad de velocidad y que las líneas tangentes pasan a través del origen (aplicando una traducción a $\gamma$).	differential-geometry,curves,tangent-line
A.338	Find all integer solutions of equation $y = \frac{a+bx}{b-x}$	How to find all integer solutions for the equation $y = \frac{a+bx}{b-x}$, where a and b are known integer values? P.S. x and y must be integer at the same time	Encuentra todas las soluciones de números enteros de la ecuación $y = \frac{a+bx}{b-x}$	¿Cómo encontrar todas las soluciones de números enteros para la ecuación $y = \frac{a+bx}{b-x}$, donde a y b son valores de números enteros conocidos?	elementary-number-theory,diophantine-equations
A.339	Extension of Euclid's lemma	This is$a $somewhat obvious fact that is intuitively obvious to me, but I haven't been able to construct a proof of it. Euclid's lemma states for for $p$ a prime and $ab$ a product of integers (let's take everything to be positive for simplicity), if $p \mid ab$, then $p \mid a$ or $p \mid b$. This is clear, and I know how to prove it. Let's extend it somewhat. Suppose that $a$ and $b$ are two relatively prime integers, and we have $a \mid bc$ for some other integer $c$. Then $a \not \mid b$, so it must divide $c$. This fact is obvious to me, but I can't figure out how to prove it. Does anyone have any hints or advice? Do I need the assumption of positivity? (For my purposes at the moment, I only need them to be positive, but there is value in having the most general result possible). EDIT: Updated attempt: We have that $a,b$ are relatively prime, so there exist $r,s \in \mathbb{Z}$ such that $ar + bs = 1$ by Bézout's lemma. Multiply through by $c$ to get $arc + bsc = c$. Then $a \mid arc$ and $a \mid bsc$, so $a \mid c$. How is that?	Extensión del lema de Euclides	Este es un hecho algo obvio que es intuitivamente obvio para mí, pero no he sido capaz de construir una prueba de ello. El lema de Euclides dice para $p$ un primo y $ab$ un producto de enteros (consideremos que todo es positivo para la simplicidad), si $p \mid ab$, entonces $p \mid a$ o $p \mid b$. Esto es claro, y sé cómo demostrarlo. Vamos a extenderlo un poco. Supongamos que $a$ y $b$ son dos números enteros relativamente primos, y tenemos $a \mid bc$ para algún otro número entero $a $0. Entonces $a $1, por lo que debe dividir $a $0. Esto es obvio para mí, pero no puedo averiguar cómo probarlo. ¿Tiene algún indicio o consejo? ¿Necesito la suposición de positividad? (Para mis propósitos en este momento, sólo necesito ser relativamente, pero tiene el resultado general de tener el valor ED15. Entonces, ¿cómo tenemos que $a $2 y $a $6 existen por el hecho de que $a $2? ¿Cómo podemos tener $a $2? $a $6: $a $2: $a $6: $a $6: $a $2: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: $a $6: XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX: XXX XXX XXX: XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX XXX: XXX: XXX XXX: XXX XXX: XXX: XXX XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX: XXX:	elementary-number-theory
A.340	I have the following problem: Let $|x_{n+1} - x_n| < 1/3^n$. Show that $(x_n)$ is a Cauchy sequence.	We have that $(x_n)$ is a sequence of real numbers. And the relation on the title: $$ |x_{n+1} - x_n| < \frac{1}{3^n}. $$ We must prove that this is a Cauchy sequence. I know that an Cauchy sequence follows the definition: given $\epsilon>0$, exists $n_0 > 0$, such that $m,n > n_o \Rightarrow |x_m - x_n|< \epsilon$ But I don't know how to use both informations to prove the exercise. If someone please may help me, I'd be very thankful.	Tengo el siguiente problema: Vamos a $|x_{n+1} - x_n| < 1/3^n$. Muestre que $(x_n)$ es una secuencia Cauchy.	Tenemos que $(x_n)$ es una secuencia de números reales. Y la relación en el título: $$ ∙x_{n+1} - x_n ≠ < \frac{1}{3^n}. $$ Debemos probar que esta es una secuencia Cauchy. Sé que una secuencia Cauchy sigue la definición: dado $\epsilon>0$, existe $n_0 > 0$, así que $m,n > n_o \Rightarrow |x_m - x_n|< \epsilon$ Pero no sé cómo usar ambas informaciones para probar el ejercicio. Si alguien me puede ayudar, estaría muy agradecido.	real-analysis,sequences-and-series
A.341	Do all arithmetic sequences with coprime coefficients contain a prime?	Given $a, b \in Z^+$, where $\gcd(a, b) = 1$, we can define an arithmetic sequence $c_i = a + i \cdot b$. The sequence is thus $\{a, a+b, a+2b, \cdots\}$. Do all such sequences contain a prime? Do they contain an infinite number of primes? Example: $a=2, b=3$. Then, $c_1 = a+b = 5$, which is prime. Meanwhile, $a=4, b=2$ does not have primes, but $\gcd(a, b) = 2 \neq 1$, so this isn't a counterexample.	¿Todas las secuencias aritméticas con coeficientes de coprimos contienen un primo?	Dado $a, b \in Z^+$, donde $\gcd(a, b) = 1$, podemos definir una secuencia aritmética $c_i = a + i \cdot b$. La secuencia es así $\{a, a+b, a+2b, \cdots\}$. ¿Todas estas secuencias contienen un número primo? ¿Contienen un número infinito de números primos? Ejemplo: $a=2, b=3$. Entonces, $c_1 = a+b = 5$, que es primo. Mientras tanto, $a=4, b=2$ no tiene números primos, pero $\gcd(a, b) = 2 \neq 1$, por lo que este no es un contraejemplo.	elementary-number-theory,arithmetic-progressions,coprime
A.342	Four students are giving presentations	In four sections of a course, running (independently) in parallel, there are four students giving presentations that are each Exponential in length, with expected value of$10 $minutes each. How much time do we expect to be needed until all four of the presentations are completed? I'm a little thrown off by this question since it's in the chapter of order statistics in my book. But I believe that this is just gamma distribution. If each student has expected value of $10$ minutes each. Shouldn't the time needed till all four of the presentations are completed be $40$ minutes? $(10 \cdot 4 = 40)$ Or is it the following. Calculate the density of the fourth order statistics $$f(x_4) =\frac{2}{5}e^{\frac{-x}{10}}\left(1-e^{\frac{-x}{10}}\right)^3.$$ Then $$E(X_4) = \int_0^\infty\frac{2x}{5}e^\frac{-x}{10}\left(1-e^\frac{-x}{10}\right)^3 \,dx= 125/6.$$ So is the answer $40$ minutes or $125/6$ minutes? Any help is greatly appreciated.	Cuatro estudiantes están dando presentaciones	En cuatro secciones de un curso, que se ejecutan (independientemente) en paralelo, hay cuatro estudiantes dando presentaciones que son exponenciales de longitud, con un valor esperado de $10 $ minutos cada uno. ¿Cuánto tiempo esperamos necesitar hasta que se completen las cuatro presentaciones? Me alejo un poco de esta pregunta ya que está en el capítulo de estadísticas de orden en mi libro. Pero creo que esto es sólo una distribución gamma. Si cada estudiante ha tenido un valor esperado de $10$ minutos cada uno. ¿No debería el tiempo necesario para completar las cuatro presentaciones ser $40$ minutos? $(10 \cdot 4 = 40)$ O es la. Calcule la densidad de la cuarta orden estadística $$fx_4) =\frac{2}{5}{\frac{-x}{10}\left{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}{1}}{3}{5}{5}{5}{5}{5}}{5}{5}}{5}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}{5}}}{5}{5}}{5}{5}}{5}}{5}}{5}}{5}}{5}}{5}}{5}{5}}{5}{5}}{5}{5}}}{5}{5}}{5}}{5}{5}}{5}{5}}{5}{5}}{5}}{5}{5}{5}{5}}{5}}{5}{5}}}{5}{5}}{5}{5}}}{5}{5}}{5}}{5}}}{5}}}}{5}}{5}{5}}{5}}}}}{5}{5}}}{5}{5}}}}}{5}{5}{5}}}}}{5}{5}}{5}}}}{5}{5}}}}}{5}}{5}{5}}}}{5}{5}}}{5}}}}}{5}{5}}}}}}{5}{5}}}}{5}{5}{5}}}}{5}}}}{5}{5}}}}}{5}{5}}}}}}}{5}}}}{5}{5}{5}{5}}}}}}}{5}{5}}}}}}}{5}{5}}}{5}{5}{5}{5}}}{5}}}}}}{5}{5}}}{5}}}}{5}{5}{5}}{5}{5}}}{5}}}}}}{5}}{5}{5}}{5}{5}}}}}}{5}{5}}}}{5}{5}}}}}{5}{5}}}}{5}}}{5}{5}}}{5}{5}}{5}}}}{5}{5}}}{5}}}}{5}}{5}{5}}}{5}}}}}}}}}}}{5}{5}{5}{5}{5}{5}}}}{5}{5}{5}{5}{5}{5}}}}}}{5}}}}}{5}{5}}{5}{5}}}}{5}{5}{5}}}}}{5}{5}}}{5}}{5}{5}{5}}}}}{5}{5}}}}}}{5}	solution-verification,exponential-distribution,order-statistics,gamma-distribution
A.343	When two dice are identical, why are ordered pairs considered for determining probability of getting sum x?	Problem statement : +++++++++++++++ Given two identical unbiased dice, determine the probability of getting sum as 7. Event  = Sum of dots on the top face of both dice is 7. $E = {(1,6),\ (2,5),\ (3,4),\ (4,3),\ (3,4),\ (5,2),\ (6,1)}$ $|Sample Space|$ = $36$. Hence, $P(E) = 1/6$ I have a doubt here. As the two dice are given identical, why do we have to consider ordered pairs? Shouldn't it be unordered consisting of only 3 possible pairs $\{(1,6),\ (2,5),\ (3,4)\} $? Hence, $|S| = 21$ and $P(E) = 3/21$.	Cuando dos dados son idénticos, ¿por qué se consideran pares ordenados para determinar la probabilidad de obtener la suma x?	En el caso de los dados de los dados, el resultado de la suma de los dados es el resultado de la suma de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los dados de los cuales los cuales se trata.	probability
A.344	Any collection of subsets of a set is a subbasis for a topology	Theorem Any collection of subsets $\mathcal{A}$ of a nonempty set $X$ forms the subbasis for a unique topology $\tau$ on $X$. This theorem is absolutely amazing to me. I really enjoy the idea of it as a powerful tool, but I have come up with a counterexample that I just can't get over. So the theorem states that any collection of subsets of a nonempty $X$ form a subbasis for a unique topology on $X$. The emphasis there is any. So, consider the following counterexample: Let $X= \{a,b,c,d,e\}$ and let $\mathcal{A}=\{\{a\}\}$. Clearly, this is a collection of subsets of $X$. Assume that, by our theorem, then $\mathcal{A}=\{\{a\}\}$ is a subbasis for some topology on $X$. Okay, so since $\mathcal{A}$ is a subbasis of some topology on $X$, let's try taking intersections of members of $\mathcal{A}$. Well, $\{a\}\cap\{a\}=\{a\}$. Then our basis for our topology is $\mathcal{B} = \{\{a\}\}$ This is problematic because this means that our basis $\mathcal{B}$ is just $\{a\}$, but note that $\displaystyle\bigcup \mathcal{B} = \{a\}$ and $\{a\} \neq X.$ Therefore, $X \not \in \tau.$ How do we get $X$ in $\tau$? Is my counterexample logically consistent?	Cualquier colección de subconjuntos de un conjunto es una subbase para una topología	Teorema Cualquier colección de subconjuntos $\mathcal{A}$ de un conjunto no vacío $X$ forma la subbase para una topología única $\tau$ en $X$. Este teorema es absolutamente increíble para mí. Realmente me gusta la idea de que sea una herramienta poderosa, pero he llegado con un contraejemplo que no puedo superar. Así que el teorema afirma que cualquier colección de subconjuntos de un no vacío $X$ forma una subbase para una topología única en $X$. El énfasis hay alguno. Así que, considere el siguiente contraejemplo: Vamos a $X= \{a,b,c,d,e\}$ y vamos a $\mathcal{A}=\{\{a\}\}$. Claramente, esto es una colección de subconjuntos de $X$. Supongamos que, por nuestro teorema, entonces $\mathcal{A}=\{\{a\}\}$ es una subbase para alguna topología en $X$. Bien, así que como $\mathcal{A}$ es una subbase de alguna topología en $X$, vamos a tratar de obtener las intersecciones de $\mathcal{A}$. Bueno, la base para $\{a\}\cap\{a\}=\{a\}$. Entonces, ¿cómo hacemos esto para nuestra contraejemplo, pero, ¿cómo es que $\mathcal{A}$1 y $\mathcal{A}$1 es nuestra base lógica?	general-topology
A.345	Elementary geometry question: How to calculate distance between two skew lines?	I am helping someone with highschool maths but I got stacked in a elementary geometry problem. I am given the equation of two straigh lines in the space $r\equiv \begin{cases} x=1 \\ y=1 \\z=\lambda -2 \end{cases}$ and $s\equiv\begin{cases} x=\mu \\ y=\mu -1 \\ z=-1\end{cases}$ and asked for some calculations. First I am asked the relative position of them so I get they are skew lines. After that I am asked for the distance between the two lines. In order to get the distance I have to calculate the line that is perpendicular to both of them in the "skewing" point, check the points where it touches the other two lines (sorry, not sure about the word in English) and calculate the module of this vector. Im having trouble calculating the perpendicular line. I know I can get the director vector using vectorial product, but  I'm not sure how to find a point so that I can build the line.	Pregunta de geometría elemental: ¿Cómo calcular la distancia entre dos líneas sesgadas?	Me han dado la ecuación de dos líneas rectas en el espacio $r\equiv \begin{cases} x=1 \\ y=1 \\z=\lambda -2 \end{cases}$ y $s\equiv\begin{cases} x=\mu \\ y=\mu -1 \\ z=-1\end{cases}$ y me han pedido algunos cálculos. Primero me preguntan la posición relativa de ellas para que entiendo que son líneas sesgadas. Después me preguntan por la distancia entre las dos líneas. Para obtener la distancia tengo que calcular la línea que es perpendicular a ambas en el punto de "desviación", comprobar los puntos donde toca las otras dos líneas (lo siento, no estoy seguro de la palabra en inglés) y calcular el módulo de este vector. Estoy teniendo que calcular la línea perpendicular. Sé que puedo obtener el vector vectorial producto director, pero no sé cómo encontrar un punto para que pueda construir la línea.	geometry
A.346	Greatest lower bound in Q	I have a set $$ \{ r \in \mathbb Q \mid r^2 >2, r>0 \}$$ I was wondering why it does not have the greatest lower bound. Isn't $0 \in \mathbb Q$ a greatest lower bound for this set in rational numbers?	El límite inferior más grande en Q	Tengo un conjunto $$ \{ r \in \mathbb Q \mid r^2 >2, r>0 \}$$ Me preguntaba por qué no tiene el límite inferior más grande. ¿No es $0 \in \mathbb Q$ un límite inferior más grande para este conjunto en números racionales?	supremum-and-infimum
A.347	GCD (a,b) =1 prove GCD ( (a+b), (a-b) ) = 1 or 2	if GCD of $(a, b) = 1$, prove that GCD $(a+b, a-b) = 1$ or $2 .$ The proof goes like: Let GCD $( a+b, a-b ) = d$ and let there exist integers m and n such that $ a+b =md$  and $ a-b = nd.$ By adding and subtracting these two equations we get: $2a = (m+n)d$ and $2b = (m-n)d$ , because $a, b$ are coprime then $2$ GCD $(a,b)$ = GCD $(2a, 2b),$ and so on. My question is, why do we have to add and subtract above equations? I need to understand the concept of this prove in some more details. Thanks!	GCD (a,b) =1 prueba GCD (a+b), (a-b) = 1 o 2	Si GCD de $(a, b) = 1$, prueba que GCD $(a+b, a-b) = 1$ o $2 .$ La prueba es como: Que GCD $( a+b, a-b ) = d$ y que existan enteros m y n tales que $ a+b =md$ y $ a-b = nd.$ Al sumar y restar estas dos ecuaciones obtenemos: $2a = (m+n)d$ y $2b = (m-n)d$ , porque $a, b$ son coprimos entonces $(a, b) = 1$0 GCD $(a, b) = 1$1 = GCD $(a, b) = 1$2 y así sucesivamente. Mi pregunta es, ¿por qué tenemos que sumar y restar por encima de ecuaciones? Necesito entender el concepto de esto probar en algunos detalles más. Gracias!	divisibility,gcd-and-lcm
A.348	Question about determinant of a block matrix	I was studying block matrices and suddenly this question came to my mind. Let $A, B \in \Bbb R^{n \times n}$. From this Wikipedia page, $$\det \begin{pmatrix} A & B\\ B & A\end{pmatrix} = \det(A-B)\det(A+B)$$ even if $A$ and $B$ do not commute. Does a similar condition hold for the following block matrix? $$\begin{pmatrix} A & -B\\  B & A \end{pmatrix}$$	Pregunta sobre determinante de una matriz de bloque	Estudiaba matrices de bloques y de repente esta pregunta vino a mi mente. Deje $A, B \in \Bbb R^{n \times n}$. De esta página de Wikipedia, $$\det \begin{pmatrix} A & B\\ B & A\end{pmatrix} = \det(A-B) \det(A+B) $$ incluso si $A$ y $B$ no se desplazan. ¿Es una condición similar aplicable para la siguiente matriz de bloques? $$\begin{pmatrix} A & -B\\ B & A \endpmatrix}$$	matrices,determinant,block-matrices
A.349	Inverse to Stirling's Approximation	The equation for Stirling's Approximation is the following: $$x! = \sqrt{2\pi x} * (\frac{x}{e})^x$$ Writing as a function for y gives us the following: $$y = \sqrt{2\pi x} * (\frac{x}{e})^x$$ Is there a way to solve this equation for x, effectively finding an inverse to this function?	El contrario de la aproximación de Stirling	La ecuación para la aproximación de Stirling es la siguiente: $$x! = \sqrt{2\pi x} * (\frac{x}{e})^x$$ Escribir como función para y nos da lo siguiente: $$y = \sqrt{2\pi x} * (\frac{x}{e})^x$$ ¿Hay una manera de resolver esta ecuación para x, encontrando efectivamente una inversa a esta función?	factorial,inverse-function
A.350	Induction proof for natural numbers in a division operation	I want to proove that 2 and 3 divide $x^3 - x, x \in \mathbb{N}$ and I'm stuck at the inductive step, here's where I'm at: For all $x \in \mathbb{N}$, let $P(x)$ be the  proposition: 2 and 3 divide $x^3 - x$ Basic step: the first term in $\mathbb{N}$ is $0$, then: $\frac{0^3 - 0}{2} = 0$ et $\frac{0^3 - 0}{3} = 0$, thus $P(0)$ is true. Inductive step: For the inductive hypothesis, we assume that $P(k)$ is true for an arbitrary nonnegative integer k bigger than 0. That is, we assume that 2 and 3 divide $k^3 - k$ To carry out the inductive step using this assumption, we must show that when we assume that $P(k)$ is true, then $P(k + 1)$ is also true. That is, we must show that 2 and 3 divide $(k+1)^3 - (k+1)$ Is the next step here is that we need to prove that $\frac{(k+1)^3-(k+1)}{2}$ and $\frac{(k+1)^3-(k+1)}{3}$ are integers? thus 2 and 3 divide $(k+1)^3 - (k+1)$?	Prueba de inducción de números naturales en una operación de división	Quiero probar que 2 y 3 dividen $x^3 - x, x \in \mathbb{N}$ y estoy atrapado en el paso inductivo, aquí es donde estoy: para todos los $x \in \mathbb{N}$, que $P(x)$ sea la proposición: 2 y 3 dividen $x^3 - x$ Paso básico: el primer término en $\mathbb{N}$ es $0$, entonces: $\frac{0^3 - 0}{2} = 0$ y $\frac{0^3 - 0}{3} = 0$, por lo que $P(0)$ es verdad. Paso inductivo: Para la hipótesis inductiva, suponemos que $x^3 - x, x \in \mathbb{N}$0 es verdad para un entero entero no negativo arbitrario k mayor que 0. Es decir, suponemos que 2 y 3 dividen $x^3 - x, x \in \mathbb{N}$1 Para llevar a cabo el paso inductivo usando esta suposición, debemos mostrar que cuando suponemos que $x^3 - x, x \in \mathbb{N}$0 es verdad, entonces $x^3 - x, x \in \mathbb{N}$2 también es verdad. Es decir, debemos mostrar que 2 y 3 dividen $x^3 - x, x \in \mathbb{N}$3 ¿El siguiente paso aquí es que necesitamos probar que $x^3 - x, x \in \mathbb{N}$4 y $x^3 - x, x \in \mathbb{N}$5 son enteros?	induction,divisibility,natural-numbers
A.351	Application of Fatou's Lemma but something simpler is better?	The question Let $(X,\mathcal{A},\mu)$ be a measure space. Let $A_n$ be a sequence of sets in $\mathcal{A}$. Define $A := \{ x \in X $ such that  for all but finitely many $n \in \mathbb{N}$ it holds that $x ∈ A_n$ $ \}$ Show that $\lim_{n\to\infty}\inf \mu (A_n) \geq \mu(A)$ My attempt $ \mu (A_n) = \int_X \chi_{A_n} d\mu$ and so by Fatou's lemma: $\lim_{n\to\infty}\inf \mu (A_n) = \lim_{n\to\infty}\inf \int_X \chi_{ A_n} \geq \int_X \lim_{n\to\infty}\inf \chi_{A_n} d\mu$ Now all I need to show is that $\lim_{n\to\infty}\inf \chi_{A_n}(x)  = \chi_A(x)$ a.e Consider $x\in A$ then eventually $x\in A_n \forall n $ eventually and so $\chi_{A_n}(x) = 1 \forall n $ and so $\lim_{n\to\infty}\inf \chi_{A_n}(x)  = \lim_{n\to\infty} 1 = 1= \chi_A(x)$ Now consider $x\not\in A$ then $\forall N \in \mathbb{N} \exists n >N$ such that $x \not\in A_n$ and so $\inf_{m \geq n} \chi_{A_n}(x) = 0 \forall n$ and hence $\lim_{n\to\infty}\inf \chi_{A_n}(x)  = \lim_{n\to\infty} 0 = 0= \chi_A(x)$ Ando so the required follows. However this feels awfully complicated and I was wondering if anyone has any tips for something simpler	¿La aplicación del Lemma de Fatou, pero algo más simple es mejor?	La pregunta Que $(X,\mathcal{A},\mu)$ sea un espacio de medida. Que $A_n$ sea una secuencia de conjuntos en $\mathcal{A}$. Definir $A := \{ x \in X $ de tal manera que para todos, pero finitos muchos $n \in \mathbb{N}$ tiene que $x ∈ A_n$ $ \}$ Muestre que $\lim_{n\to\infty}\inf \mu (A_n) \geq \mu(A)$ Mi intento $ \mu (A_n) = \int_X \chi_{A_n} d\mu$ y así por el lema de Fatou: $(X,\mathcal{A},\mu)$0 Ahora todo lo que necesito mostrar es que $(X,\mathcal{A},\mu)$1 a.e. Considerar $(X,\mathcal{A},\mu)$2 entonces finalmente $(X,\mathcal{A},\mu)$3 finalmente y así $(X,\mathcal{A},\mu)$4 y así $(X,\mathcal{A},\mu)$5 Ahora considerar $(X,\mathcal{A},\mu)$6 entonces $(X,\mathcal{A},\mu)$7 tal que $(X,\mathcal{A},\mu)$8 y así $(X,\mathcal{A},\mu)$9 y así $A_n$0 Ando así lo requerido sigue. Sin embargo, esto se siente terriblemente complicado y me preguntaba si alguien tiene algún consejo para algo más simple	measure-theory
A.352	find a positive continuous function with a finite area : $\int_0^\infty f(x) dx$ , but the $f(x)\rightarrow$ doesn't exist.	find a positive continuous function with a finite area : $\int_0^\infty f(x) dx$ , but the limit of $f(x)$ as $x$ goes to infinity doesn't exist. I tried finding such a function but I failed .	encontrar una función continua positiva con un área finita: $\int_0^\infty f(x) dx$, pero el $f(x)\rightarrow$ no existe.	encontrar una función continua positiva con un área finita: $\int_0^\infty f(x) dx$ , pero el límite de $f(x)$ como $x$ va al infinito no existe. traté de encontrar tal función pero no pude .	real-analysis,calculus,limits
A.353	Can someone explain why if two random variables, X and Y, are uncorrelated, it does not necessarily mean they are independent?	I understand that two independent random variables are by definition uncorrelated as their covariance is equivalent to 0: $Cov(x,y) = E(xy)- E(x)E(y)$ $E(x)*E(y) = E(xy)$, when x and y are two random independent variables. Therefore, $Cov(x,y) = 0$. However, I am having trouble understanding if two random variables, X and Y, are uncorrelated, it does not necessarily mean they are independent. Could someone also give me a real world example of when two random variables are neither independent nor casually connected? I believe it will help me understand this concept better.	¿Puede alguien explicar por qué si dos variables aleatorias, X y Y, no están correlacionadas, no significa necesariamente que sean independientes?	Entiendo que dos variables aleatorias independientes no están correlacionadas por definición ya que su covarianza es equivalente a 0: $Cov(x,y) = E(xy)- E(x)E(y)$ $E(x)*E(y) = E(xy)$, cuando x y y son dos variables independientes aleatorias. Por lo tanto, $Cov(x,y) = 0$. Sin embargo, tengo problemas para entender si dos variables aleatorias, X y Y, no están correlacionadas, no significa necesariamente que sean independientes. ¿Podría alguien también darme un ejemplo real de cuando dos variables aleatorias no son ni independientes ni casualmente conectadas? Creo que me ayudará a entender mejor este concepto.	probability,probability-theory,independence,covariance,causality
A.354	Prove that if $p_1\mid a$ and $p_2\mid a$ then $p_1p_2\mid a$	So I am supposed to be proving that if $p_1$ and $p_2$ are distinct primes and $p_1\mid a$ and $p_2\mid a$ then $p_1p_2\mid a$, and I need to use Euclid's Lemma except as far as I understand Euclid's lemma is the converse of this statement and I have tried for the last few hours to work with Euclid's and GCDs to figure this one out and I just don't know where to start since I can't wrap my head around this one. Can anyone help me out?	Demostrar que si $p_1\mid a$ y $p_2\mid a$ entonces $p_1p_2\mid a$	Así que se supone que estoy probando que si $p_1$ y $p_2$ son primos distintos y $p_1\mid a$ y $p_2\mid a$ entonces $p_1p_2\mid a$, y necesito usar el lema de Euclides excepto en la medida en que entiendo que el lema de Euclides es el opuesto de esta afirmación y he intentado durante las últimas horas para trabajar con Euclides y GCDs para averiguar esto y yo simplemente no sé por dónde empezar ya que no puedo envolver mi cabeza alrededor de este. ¿Puede alguien ayudarme?	elementary-number-theory
A.355	$f(f(x)^2+f(y))=xf(x)+y$	Find all functions $f:\mathbb{R}\rightarrow\mathbb{R}$ such that $$f(f(x)^2+f(y))=xf(x)+y$$ for all $x,y\in{\mathbb{R}}$.  Here is my approach to the problem:  We see that $f(x)=x$ is an obvious solution (Just trying easy linear equations). I think this would be the only solution to the problem.  Am I right? And how to prove that there is no other solution? (Note: I am a beginner at functional equations)	$f(f(x)^2+f(y))=xf(x)+y$	Encuentra todas las funciones $f:\mathbb{R}\rightarrow\mathbb{R}$ tales como $$f(f(x) ^ 2 + f(y)) = xf(x) + y$$ para todas las $x,y\in{\mathbb{R}}$. Aquí está mi enfoque del problema: vemos que $f(x)=x$ es una solución obvia (solo intentando ecuaciones lineales fáciles). Creo que esta sería la única solución al problema. ¿Tengo razón? ¿Y cómo demostrar que no hay otra solución? (Nota: soy principiante en ecuaciones funcionales)	linear-algebra,proof-writing,contest-math,functional-equations
A.356	How can I evaluate $ \sum_{n=0}^{\infty}{\frac{x^{kn}}{(kn)!}} $ where $k$ is a natural number?	I suddenly interested in the differential equation $$ f^{(k)}(x)=f(x) $$ So I tried to calculate for some $n$. When $ k=1 $, we know the solution $$ f(x)=A_0e^x=\sum_{n=0}^{\infty}{\frac{A_0x^n}{n!}} $$ Also, for $ k=2 $, $$ f(x)=Ae^x-Be^{-x}=\sum_{n=0}^{\infty}{(\frac{A_0x^{2n}}{(2n)!}+\frac{A_1x^{2n+1}}{(2n+1)!})} $$ where $ A_0=A+B $ and $ A_1=A-B $. Inductively, I could guess that the solution of the differential equation would be in the form $$ f(x)=\sum_{n=0}^{\infty}{\sum_{i=0}^{k-1}{\frac{A_ix^{kn+i}}{(kn+i)!}}} $$ But I could neither prove that it is the only solution nor get the explicit formula. How should I evaluate $ \sum_{n=0}^{\infty}{\frac{x^{kn}}{(kn)!}} $, cause if we know the answer for it, we can evaluate the original expression by differentiating it. Thanks to WolframAlpha, I know the answer for $ k=3 $, $$ \sum_{n=0}^{\infty}{\frac{x^{3n}}{(3n)!}}=\frac{1}{3}(2e^{-\frac {x}{2}}\cos{(\frac {\sqrt{3}}{2}x)}+e^{x}) $$ I think the answer might related to $ \sin $ and $ \cos $ of $ \frac {2\pi}{k} $.	¿Cómo puedo evaluar $ \sum_{n=0}^{\infty}{\frac{x^{kn}}{(kn)!}} $ donde $k$ es un número natural?	De repente me interesó la ecuación diferencial $$ f^{(k)}(x)=f(x) $$ Así que intenté calcular para algún $n$. Cuando $ k=1 $, sabemos la solución $$ f_x)=A_0e^x=\sum_{n=0}^{{\infty}{\frac{A_0x^n}{n!}}{{\infty}{\frac{A_0x^n}{n!}}{{1} También, para $ k=2 $, $$ f}x=Ae^x-Be^{x}=\sum_{n=0}{\infty}{\sum_{\infty}{\infty}{\frac{A_0x^n}{\in2}{\in}{\in}{a_1}{n1}{{n}{i}{i}{i}{i}{i}{i}{i}{i}{i}{i}{i}{i}{i}}{i}{i}}{i}{i}}{i}}{i}}{i}}{i}}{i}}{i}}{i}}{i}}{i}}{i}i}}{i}i}}{i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}i}	sequences-and-series,ordinary-differential-equations,power-series,functional-equations
A.357	How many functions can be used to describe to a finite series?	I was learning more about series today and would like to know if there are existing proofs I could look at about this problem. Basically, if you are given an infinite series representing a function f : $\Bbb N \Rightarrow \Bbb R$ but only shown the first n numbers, how many functions f, written in terms of n, could you write to represent that series. I'm not including piecewise functions, because I assume that would always be infinite. Take the series $(2, 4, ...)$ with 2 numbers given. $f(n)=2n$ , $f(n)=n^2-n+2$ , and $f(n)=2^n$ would all be functions that could fit this series, although they differ after the first two numbers. I believe there are more polynomials that fit this description but I'm not sure how many. My question is, essentially, are there an infinite number of functions for which $f(1) = 2$ and $f(2) = 4$, and if this is the case, does this also apply to any finite number of outputs? (e.g. the first n digits of pi written as $(3, 1, 4, 1, 5, 9...)$) If not, could you find out how many possible functions there are?	¿Cuántas funciones se pueden usar para describir una serie finita?	Hoy estaba aprendiendo más sobre series y me gustaría saber si hay pruebas existentes que podría mirar sobre este problema. Básicamente, si se te da una serie infinita que representa una función f: $\Bbb N \Rightarrow \Bbb R$ pero solo se muestran los primeros n números, ¿cuántas funciones f, escritas en términos de n, podrías escribir para representar esa serie. No estoy incluyendo funciones piezas, porque supongo que siempre sería infinito. Tomemos la serie $(2, 4, ...)$ con 2 números dados. $f(n)=2n$ , $f(n)=n^2-n+2$ , y $f(n)=2^n$ serían todas funciones que podrían encajar en esta serie, aunque difieren después de los dos primeros números. Creo que hay más polinomios que encajan en esta descripción pero no estoy seguro de cuántos. Mi pregunta es, esencialmente, ¿hay un número infinito de funciones para las cuales $f(1) = 2$ y $f(2) = 4$, y si este es el caso, ¿podría esta función también aplicar a cualquier número finito de pi? (p.g. de las funciones escritas como la primera, si no hay muchos números como XXg?	sequences-and-series,number-theory
A.358	Confusion about the formula of the area of a surface of revolution	Before I read the formula of the area of revolution which is $\int 2\pi y \,ds$, where $ds = \sqrt{1 + \frac{dy}{dx}^2}$, I thought of deriving it myself. I tried to apply the same logic used for calculating the volume of revolution (e.g., $\int \pi y^2 dx $). My idea is to use many tiny hollow cylinders (inspired from the shell method), each has a surface area of $(2\pi y) (dx)$:  $2\pi y$ is the circumference of the cylinder, and $dx$ is the height of the cylinder  Their product is the surface area of the hollow (e.g., empty from the inside) cylinder. With this logic, the area is $\int 2\pi y dx$. Where is my mistake? Also it's confusing why for the volume it was enough to partition the object using cylinders and for areas not.	Confusión sobre la fórmula del área de una superficie de revolución	Antes de leer la fórmula del área de revolución que es $\int 2\pi y \,ds$, donde $ds = \sqrt{1 + \frac{dy}{dx}^2}$, pensé en derivarla yo mismo. Traté de aplicar la misma lógica utilizada para calcular el volumen de revolución (por ejemplo, $\int \pi y^2 dx $). Mi idea es usar muchos pequeños cilindros huecos (inspirados en el método de la concha), cada uno tiene un área de superficie de $(2\pi y) (dx)$: $2\pi y$ es la circunferencia del cilindro, y $dx$ es la altura del cilindro.	calculus,area
A.359	Apparent inconsistencies in integration	In a problem, the substitution $$\tan\theta=\frac{x}{2}$$ was made. In the end, the answer was in terms of sines, and to convert back, $sin\theta$ was defined as $$\sin\theta=\frac{x}{\sqrt{4+x^2}}$$ This is a typical example of some stuff about integration I'm struggling to understand; (1) Why are the absolute values of square roots never taken? This is something I keep seeing in every situation involving an integral. (Here, if $\theta$ is in the third quadrant, sines would be negative and tans would be positive. So this definitely doesn't work for the third quadrant.) (2) Expanding upon the stuff in the parantheses up there, a possible explanation is that while doing trig substitutions, the angle is always a principal angle of the inverse trigonometric operation on whatever you're making the substitution. Is there such a rule?	Aparentes inconsistencias en la integración	En un problema, se hizo la sustitución $$\tan\theta=\frac{x}{2}$$ . Al final, la respuesta fue en términos de sinus, y para convertir de vuelta, $sin\theta$ se definió como $$\sin\theta=\frac{x}{\sqrt{4+x^2}}$$ Este es un ejemplo típico de algunas cosas sobre la integración que estoy luchando por entender; (1) ¿Por qué los valores absolutos de raíces cuadradas nunca se toman? Esto es algo que sigo viendo en todas las situaciones que involucran una integral. (Aquí, si $\theta$ está en el tercer cuadrante, los sinus sería negativo y sería positivo. Así que esto definitivamente no funciona para el tercer cuadrante.) (2) Expandir sobre las cosas en los trigones arriba, una explicación es que mientras que siempre es posible sustitución de ángulo, el ángulo de la sustitución del trigón principal es una regla que hace que la operación de los trigonometros tan tan tan buenos.	integration,trigonometry,roots,substitution,trigonometric-integrals
A.360	Fourier transform of function $1/ \vert x \vert$	What is the Fourier transform of function $$f(x) = \frac{1}{\vert x \vert}?$$ This is not a homework. I would also appreciate help for calculating it myself.	Transformación de Fourier de la función $1/ \vert x \vert$	¿Cuál es la transformación de Fourier de la función $$f(x) = \frac{1}{\vert x \vert}?$$ Esto no es una tarea. También agradecería la ayuda para calcularlo yo mismo.	fourier-transform
A.361	Is a Riemann-integrable function always differentiable?	Let $f:[a,b]\to\mathbb{R}$ be Riemann-integrable and $F(x)=\int_a^xf(t)dt$. Is this function $F$ always differentiable? Because the antiderivative is defined as $F'=f$ right, so you would think that it always holds.	¿Es una función integrable de Riemann siempre diferenciable?	Si la función $F$ es siempre diferenciable, entonces la diferenciación de la función $F$ es igual a la función $F'=f$.	real-analysis
A.362	Kuratowski's Theorem using Axiom of Choice	I can't seem to be able to prove Kuratowski's Theorem using the Axiom of Choice, although they are equivalent assertions. Kuratowski's Lemma: Every partial order has a maximal chain. Axiom of Choice: For every set X of disjoint nonempty sets there exists a set$Y $such that for every set $Z \in X, Y \cap Z$ is a singleton. My attempt: Consider any chain $C_0$ of the partial order. If $\exists x \in X \setminus C_0$ which is comparable with some element of $C_0$, let $C_1 := C_0 \cup \{ x \}$. Iterate this process . If at some point we cannot find such an x, then we have found a maximal chain. Suppose we can find such an $x$ infinitely, then the sets $i\geq 1 \Rightarrow X_i := C_{i+1} \setminus C_i$ are disjoint singletons. Hence by axiom of choice there exists $Y$ for which $X_i \subseteq Y$. Inorder to finish the proof, I need to prove something of the form "If a is comparable with some element of $C_0$, then $\exists j$ s.t. $a \in C_j$". I can't seem to prove this. P.S: x is comparable with y iff $x R y \lor y R x$.	Teorema de Kuratowski usando el axioma de la elección	No puedo probar el teorema de Kuratowski usando el axioma de la elección, aunque son afirmaciones equivalentes. La lemma de Kuratowski: Cada orden parcial tiene una cadena máxima. El axioma de la elección: Para cada conjunto X de conjuntos no vacíos desarticulados existe un conjunto$Y $ tal que para cada conjunto $Z \in X, Y \cap Z$ es un singleton. Mi intento: Considere cualquier cadena $C_0$ del orden parcial. Si $\exists x \in X \setminus C_0$ que es comparable con algún elemento de $C_0$, permítanme $C_1 := C_0 \cup \{ x \}$. Iterar este proceso. Si en algún momento no podemos probar tal x, entonces hemos encontrado una cadena máxima. Supongamos que podemos encontrar tal $x$ infinitamente, entonces los conjuntos $i\geq 1 \Rightarrow X_i := C_{i+1} \setminus C_i$ son singletones desarticulados. Por lo tanto, por el axioma de la elección $Y$9.	order-theory,axiom-of-choice
A.363	Non-negative martingale $X_n \rightarrow 0$ a.s. prove that $P[X^* \geq x | \mathcal{F}_0]= 1 \wedge X_0 / x$	I need to prove the following statement. Let $X$ be a non negative martingale such that $X_n\rightarrow 0$ a.s. when $n\rightarrow \infty$. Define $X^*=supX_n$. Prove that for all $x>0$ $$P[X^*  \geq x | \mathcal{F}_0]= 1 \wedge X_0 / x$$ I think I've got the easy case  if  $x\leq X_0$  Then necessarily $x\leq X^*$ for the sup property. Then it follows that for $1\leq X_0 /x$ we have that $P[X^*  \geq x | \mathcal{F}_0]= 1$. But I can't figure out the other case.	Martingales no negativos $X_n \rightarrow 0$ a.s. demuestran que $P[X^* \geq x | \mathcal{F}_0]= 1 \wedge X_0 / x$	Necesito probar la siguiente afirmación. Que $X$ sea un martingale no negativo de tal manera que $X_n\rightarrow 0$ a.s. cuando $n\rightarrow \infty$. Definir $X^*=supX_n$. Pruebe que para todos $x>0$ $$P [X^* \geq x ̊ \mathcal{F}_0]= 1 \wedge X_0 / x$$ Creo que tengo el caso fácil si $x\leq X_0$ Entonces necesariamente $x\leq X^*$ para la propiedad sup. Entonces se deduce que para $1\leq X_0 /x$ tenemos que $X$0. Pero no puedo averiguar el otro caso.	probability,martingales,stopping-times
A.364	Inequality in metric space	For a point $x$ and a non-empty subset $A$ of a metric space $(X, d)$, define $\begin{align}\inf\left\{ d(x,a):a\in A\right\}\end{align}$ Prove that if $y$ is another point in $X$ then $$d(x,A)\leqslant d(x,y)+d(y,A)$$	Desigualdad en el espacio métrico	Para un punto $x$ y un subconjunto $A$ no vacío de un espacio métrico $(X, d)$, definir $\begin{align}\inf\left\{ d(x,a):a\in A\right\}\end{align}$ Prueba que si $y$ es otro punto en $X$ entonces $$d(x,A)\leqslant d(x,y) +d(y,A)$$	general-topology,analysis,metric-spaces
A.365	Are Infinite ordinals and their successor equinumerous?	Ordinals in set theory are well-ordered by $\in$ or equivalently $\subset$. If we define all ordinals greater or equal to $\omega$ as infinite ordinals. Is it true that every infinite ordinal is equinumerous to its successors. Basically my question is the proof or refutation of the following statement: Given infinite ordinal $\alpha$. Does there exist an injection from $\alpha^+$ to $\alpha$.	¿Son los ordinarios infinitos y su sucesor equinumeros?	Los ordinarios en la teoría de conjuntos están bien ordenados por $\in$ o equivalentemente $\subset$. Si definimos todos los ordinarios mayores o iguales a $\omega$ como ordinarios infinitos. ¿Es cierto que cada ordinal infinito es equinumero para sus sucesores? Básicamente mi pregunta es la prueba o la refutación de la siguiente afirmación: Dado ordinal infinito $\alpha$.	set-theory
A.366	Show that if a normed space $X $ has a linearly independent subset of $n$ elements, so does the dual space $X'$	Show that if a normed space $X $ has a linearly independent subset of $n$ elements, so does the dual space $X'$ My attempt : $\text{Given that  a  normed space  $X$ has  a linearly indepenedent  susbset of  $n-$  element}\tag1$ let the subset be  $S=\{ e_1,e_2,e_3,....,e_n\}$ Define $e_i \in X$ by $f_j(e_i)= \delta_{ij} = \begin{cases} 1 & i=j \\0 , & i \neq j  \end{cases}$ where $1\le i\le n$ and $1\le j\le n$ From $(1)$ we have  $c_1e_1+...+c_ne_n=0\implies c_1f(e_1)+...+c_nf(e_n)=0$ After  that im not able to proceed further	Muestre que si un espacio normativo $X $ tiene un subconjunto linealmente independiente de elementos $n$, también lo hace el espacio dual $X'$	Muestre que si un espacio normativo $X $ tiene un subconjunto linealmente independiente de los elementos $n$, así lo hace el espacio dual $X'$ Mi intento: $\text{Given that  a  normed space  $X$ has  a linearly indepenedent  susbset of  $n-$  element}\tag1$ dejar que el subconjunto sea $S=\{ e_1,e_2,e_3,....,e_n\}$ Definir $e_i \in X$ por $f_j(e_i)= \delta_{ij} = \begin{cases} 1 & i=j \\0 , & i \neq j  \end{cases}$ donde $X $0 y $X $1 Desde $X $2 tenemos $X $3 Después de eso no podemos continuar	functional-analysis
A.367	Prove that $d(x,M)=\frac{|\langle f,x \rangle|}{||f||}$	I want to show that for $E$ a normed space, $f\in E^*$ and $M=\{x\in E\,:\, f(x)=0\}$:  Write $M^\perp$ Show that $d(x,M)=\frac{|\langle f,x\rangle|}{||f||}$.  This is my attempt: For the second part: We have that $f\in E^*$ and for $x\in E$ and $m\in M$ $$\ |\langle f,x-m|\rangle \leq ||f|| ||x-m|| \Rightarrow \frac{|\langle f,x\rangle|}{||f||} \leq ||x-m||. $$ Therefore, $$ \frac{|\langle f,x\rangle|}{||f||} \leq \inf_{m\in M}||x-m|| =d(x,M). $$ The second inequalyty is that I can't prove, I think that any corollary of Hanh-Banach could help me to prove that  $$d(x,M)\leq \frac{|\langle f,x\rangle|}{||f||} $$ Does anyone have any idea and could check my proof? Update I found the same question in this link Orthogonality Relations Exercise, Brezis' Book Functional Analysis	Prueba eso $d(x,M)=\frac{|\langle f,x \rangle|}{||f||}$	Quiero escribir $f\in E^*$ $M^\perp$ Show $M^\perp$ $M^\perp$ $f\in E^*$ $x\in E$ $m\in M$ $$\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\	functional-analysis,normed-spaces
A.368	Basel Problem approximation error bounded by $\mathcal O(1/x)$?	In this answer it is stated that $$ \sum_{n\geq1}\frac{1}{n^2}=\sum_{n\leq x}\frac1{n^2}+\mathcal O(1/x). $$ Is this statement true as $x\to\infty$? What I've done: If $x$ is fixed, then I think the answer is almost trivial, because we may set $C=\pi^2x/6$, so $$ \sum_{n=x}^\infty\frac1{n^2}\leq\sum_{n=1}^\infty\frac1{n^2}=\frac{\pi^2}{6}=\frac{C}{x}, $$ therefore $$ \sum_{n\geq1}\frac1{n^2}=\sum_{n\leq x}\frac{1}{n^2}+\sum_{n=x}^\infty\frac{1}{n^2}\leq\sum_{n\leq x}\frac{1}{n^2}+C/x=\sum_{n\leq x}\frac{1}{n^2}+\mathcal O(1/x). $$ But is there a constant independent of $x$ that makes this true?	¿El problema de aproximación de Basilea limitado por $\mathcal O(1/x)$?	En esta respuesta se afirma que $$ \sum_{n\geq1}\frac{1}{n\2}=\sum_{n\leq x}\frac1{n^2}+\mathcal O(1/x). $$ ¿Es esta afirmación verdadera como $x\to\infty$? Lo que he hecho: Si $x$ está fijo, entonces creo que la respuesta es casi trivial, porque podemos establecer $C=\pi^2x/6$, así que $$ \sum_{n\geq1}^\infty\frac1{n^2}\leq\sum_{n=1}^infty\frac1{n^2}=\frac1{n^2}{6}=\frac{c}{x}, $$ por lo tanto{1}{n\sum_{n\q1}\sum_{n}\frac1}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}{n}}{n}{n}{n}}{n}{n}{n}}{n}{n}{n}}{n}{n}}{n}{n}}{n}{n}{n}}{n}{n}}{n}{n}}{n}{n}{n}}{n}}{n}{n}}{n}{n}}{n}{n}}{n}{n}{n}}}{n}{n}}{n}}{n}{n}{n}}{n}}{n}{n}{n}{n}}{n}{n}}{n}{n}}{n}}{n}{n}}}{n}{n}{n}{n}}{n}}{n}}{n}{n}{n}{n}{n}}}{n}{n}{n}}}{n}{n}{n}{n}{n}}{n}{n}}}{n}{n}}}{n}{n}{n}{n}{n}{n}{n}{n}}{n}}}{n}{n}{n}{n}{n}}{n}{n}}{n}{n}n}n}}{n}n}{n}{n}n}{n}n}n}n}n}n}{n}n}n}{n}n}{n}n}n}n}n}n}{n}n}n}n}{n}n}n}n}n}n}n}n}n}n}n}{n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n}n	approximation
A.369	Recurrent integral	How to calculate integral $$J_n=\int_{-\pi}^\pi \frac{\sin{(nx)}}{(1+2^n) \sin{x}}\,\mathrm{d}x\:?$$ I tried partial integration but did not succeed in finding a recurrent relation? Also, tried Moivre formula for $I_n+iJ_n$, where $I_n=\int_{-\pi}^\pi \frac{\cos{(nx)}}{(1+2^n) \sin{x}} dx$, but also without success. Any help is welcome. Thanks in advance.	Integral recurrente	¿Cómo calcular la integral $$J_n=\int_{-\pi}^\pi \frac{\sin{(nx)}}{(1+2^n) \sin{x}}\,\mathrm{d}x\:$$ Intenté la integración parcial pero no pude encontrar una relación recurrente? También probé la fórmula de Moivre para $I_n+iJ_n$, donde $I_n=\int_{-\pi}^\pi \frac{\cos{(nx)}}{(1+2^n) \sin{x}} dx$, pero también sin éxito. Cualquier ayuda es bienvenida. Gracias por adelantado.	integration,definite-integrals,recurrence-relations
A.370	What if we take step functions instead of simple functions in the Lebesgue integral	When we define the Lebesgue integral, we first define it for simple functions $s(x) = \sum\limits_{j=1}^n c_j\chi_{A_j}(x)$ (where $A_j$ are measurable) as $\int sd\mu = \sum\limits_{i=j}^n c_j \mu(A_j)$ and then for $f\ge 0$ as $\int fd\mu = \sup\{\int sd\mu$ : s simple and $0\le s\le f\}$. But I was wondering what could go wrong if instead of taking simple functions in the supremum, we would take step functions, i.e. $s(x)=\sum\limits_{j=1}^nc_i\chi_{I_j}(x)$ where $I_j$ are intervals (any type, like $(a,b), (a,b], [a,b), [a,b])$).	¿Qué pasa si tomamos funciones de paso en lugar de funciones simples en la integral de Lebesgue	Cuando definimos la integral de Lebesgue, primero la definimos para funciones simples $s(x) = \sum\limits_{j=1}^n c_j\chi_{A_j}(x)$ (donde $A_j$ son medibles) como $\int sd\mu = \sum\limits_{i=j}^n c_j \mu(A_j)$ y luego para $f\ge 0$ como $\int fd\mu = \sup\{\int sd\mu$ : s simple y $0\le s\le f\}$. Pero me preguntaba qué podría ir mal si en lugar de tomar funciones simples en el supremo, tomáramos funciones de paso, es decir, $s(x)=\sum\limits_{j=1}^nc_i\chi_{I_j}(x)$ donde $I_j$ son intervalos (cualquier tipo, como $(a,b), (a,b], [a,b), [a,b])$).	measure-theory,lebesgue-integral,step-function,simple-functions
A.371	Can I say $|f(x)g(x)|=||fg||$	Let $f,g:[0,1]\to \Bbb{R}$ be continuous functions. Show that $$||fg||\le||f||\space||g||$$ What I have got so far : $|f(x)| \le\max|f(x)|=$ norm of $f$, $||f||$.$\forall x\in[0,1]$. (Note: I have replaced supremum with maximum.) $|f(x)||g(x)| =|f(x)g(x)|\le \max |f(x)|g(x)=||f|| \space\space |g|\le \max|f(x)|\space \max|g(x)|=|f||\space\space||g||$ $|f(x)g(x)|\le||f||\space\space||g||$ As I have to show that $||fg||\le||f||\space||g||$ : Can I say $|f(x) g(x)|=||fg||$? I'm not sure about that  Because $|f(x)g(x)| \le\max|f(x)g(x)|=\max|f(x)| \space \max|g(x)|$ I feel I am missing concept to prove $|f(x) g(x)|=||fg||$, through which I think I finally can prove $||fg||\le||f||\space||g||$ please If you guys could clarify.	¿Puedo decir $|f(x)g(x)|=||fg||$	Que $f,g:[0,1]\to \Bbb{R}$ sea una función continua. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ tiene funciones continuas. Muestre que $$ no tiene un concepto para probar $f,g:[0,1]\to \Bbb{R}$0 porque $f,g:[0,1]\to \Bbb{R}$1 me falta.	functional-analysis,analysis,norm
A.372	When did we move from $\mathbb{Z}\left[\sqrt{d}\right]$ to the ring of integers $\mathcal{O}_{\mathbb{Q}\left[\sqrt{d}\right]}$ and why?	Gauss made great progress in number theory in $\mathbb{Z}$ by working in $\mathbb{Z}[i]$ (or equivalently $\mathbb{Z}\left[\sqrt{-1}\right]$), so much so that we call $\mathbb{Z}[i]$ the Gaussian integers now. And it was even known to the old mathematicians that solutions to Pell's equation $x^2 - dy^2 = 1$ could be better analysed by working in $\mathbb{Z}\left[\sqrt{d}\right]$. But now in modern number theory we study much more the ring of integers $\mathcal{O}_{\mathbb{Q}\left[\sqrt{d}\right]}$. I find this confusing, as if we want to study Pell's equation with $d = 5$, we have that $\mathcal{O}_{\mathbb{Q}\left[\sqrt{5}\right]} = \mathbb{Z}\left[\frac{1 + \sqrt{5}}{2}\right]$ instead of $\mathbb{Z}\left[\sqrt{5}\right]$, which is not what we need. I was under the assumption that modern number theory usually tries to generalise its techniques but I don't see how this is a sensible generalisation and I don't see why the ring of integers is any more useful than just plain old $\mathbb{Z}\left[\sqrt{d}\right]$. So my question is: Why is the ring of integers defined the way it is?	¿Cuándo nos mudamos del $\mathbb{Z}\left[\sqrt{d}\right]$ al anillo de números enteros $\mathcal{O}_{\mathbb{Q}\left[\sqrt{d}\right]}$ y por qué?	Gauss hizo grandes progresos en la teoría de números en $\mathbb{Z}$ al trabajar en $\mathbb{Z}[i]$ (o equivalentemente $\mathbb{Z}\left[\sqrt{-1}\right]$), tanto que ahora llamamos a $\mathbb{Z}[i]$ los enteros gaussianos. Y incluso se sabía a los antiguos matemáticos que las soluciones a la ecuación de Pell $x^2 - dy^2 = 1$ podrían ser mejor analizadas trabajando en $\mathbb{Z}\left[\sqrt{d}\right]$. Pero ahora en la teoría de números modernos estudiamos mucho más el anillo de los enteros $\mathcal{O}_{\mathbb{Q}\left[\sqrt{d}\right]}$.	abstract-algebra,ring-theory,soft-question,definition
A.373	Show that $\sqrt n$ is irrational if $n$ is not a perfect square, using the method of infinite descent.	Show that $\sqrt n$ is irrational if $n$ is not$a $perfect square, using the method of infinite descent. I know how to prove this by doing a contradiction proof and using The Fundamental Theorem of Arithmetic, but now I'm asked to use infinite descent to prove it. Then the very next problem says "Why does the method of the text fail to show that $\sqrt n$ is irrational if $n$ is a perfect square?" I'm confused by this. Any hints or solutions are greatly appreciated. I was thinking of the standard argument, let $\sqrt n = {a\over b}$ where $gcd(a,b)=1$ and then through some algebra arrive at a common factor for both $a$ and $b$ which contradicts the fact that $gcd(a,b)=1$ and so we can apply this over and over again, but then I don't understand how the next problem says to explain why this method fails.	Muestre que $\sqrt n$ es irracional si $n$ no es un cuadrado perfecto, utilizando el método de descenso infinito.	Muestre que $\sqrt n$ es irracional si $n$ no es $a $ perfectos cuadrado, usando el método de descenso infinito. Sé cómo probar esto haciendo una prueba de contradicción y usando El Teorema Fundamental de la Aritmética, pero ahora me piden que use descenso infinito para probarlo. Entonces el siguiente problema dice "¿Por qué el método del texto no muestra que $\sqrt n$ es irracional si $n$ es un cuadrado perfecto?" Estoy confundido por esto. Cualquier sugerencia o solución son muy apreciadas. Estaba pensando en el argumento estándar, vamos a $\sqrt n = {a\over b}$ donde $gcd(a,b)=1$ y luego a través de algún álgebra llegar a un factor común para ambos $a$ y $b$ que contradice el hecho de que $gcd(a,b)=1$ y así podemos aplicar esto una y otra vez, pero entonces no entiendo cómo el problema no explica este método dice que el siguiente.	elementary-number-theory
A.374	Finding all monic complex polynomials $P(x)$ such that $P(x)|P(x^2)$	Find all monic complex polynomials $P(x)$ such that $P(x)|P(x^2)$.  My progress so far is that I have find that for degree 1, $P(x)=x, x^2$ are the only ones. For degree 2, they are $P(x)=x^2+x+1, x^2, x^2-1, x^2-x, x^2-2x+1$. I also prove that these are only solutions for degree 1 and 2. However I do not see how this generalizes. Any help please?	Encontrar todos los polinomios de complejo monico $P(x)$ tales que $P(x)|P(x^2)$	Encuentra todos los polinomios de complejo monico $P(x)$ tales como $P(x)|P(x^2)$. Mi progreso hasta ahora es que he encontrado que para el grado 1, $P(x)=x, x^2$ son los únicos. para el grado 2, son $P(x)=x^2+x+1, x^2, x^2-1, x^2-x, x^2-2x+1$. También demuestro que estas son solo soluciones para el grado 1 y 2. Sin embargo, no veo cómo esto generaliza. ¿Alguna ayuda por favor?	algebra-precalculus,polynomials,divisibility
A.375	Can anyone help me solve this diophantine equation?	Find all integer solutions to $x^2 + 7 = 2^n$. I've done the case where n is an even integer but now I'm a little lost. Could anyone walk me through the solution?	¿Puede alguien ayudarme a resolver esta ecuación diofantina?	Encontrar todas las soluciones de números enteros para $x^2 + 7 = 2^n$. He hecho el caso donde n es un número entero par pero ahora estoy un poco perdido. ¿Alguien podría guiarme a través de la solución?	elementary-number-theory
A.376	Evaluating the limit of a sqrt function using Riemann Sums	$\lim\limits_{n\to\infty}\dfrac{\sqrt1+\sqrt2+\sqrt3+\ldots+\sqrt n}{n\sqrt n}$ I am having trouble doing this problem. I have attempted to take the Riemann Sum but cannot get past the square root. I also tried to upper-bound and lower-bound it, but I got stuck doing this.	Evaluar el límite de una función sqrt utilizando Riemann Sumas	$\lim\limits_{n\to\infty}\dfrac{\sqrt1+\sqrt2+\sqrt3+\ldots+\sqrt n}{n\sqrt n}$ Tengo problemas para hacer este problema. he intentado tomar la suma de Riemann pero no puedo pasar por la raíz cuadrada. también he intentado la límite superior y la limitación inferior, pero me quedé atascado haciendo esto.	calculus,limits,riemann-sum
A.377	What is $\mathbb{R}^{n+1}-\mathbb{R}^n$?	In C.H. Edwards's Advanced Calculus of Several Variables he defines the ordinate set $\mathcal{O}_f$ of a function $f:\mathbb{R}^n\to\mathbb{R}$ as the set of points between $\mathbb{R}^n$ and the graph of $f,$ including the points of evaluation, $\mathbf{x}\in\mathbb{R}^n$ and the points in the graph $\left\{\mathbf{x},f\left(\mathbf{x}\right)\right\}\in\mathbb{R}^{n+1}$.  Later on he defines a set $\hat{\mathcal{G}}=\partial\mathcal{O}_f-\mathbb{R}^n,$ where $\partial\mathcal{O}_f$ is the boundary of $\mathcal{O}_f.$  The intent seems clear.  First $$\mathbb{R}^{n+1}-\mathbb{R}^n=\mathbb{R}^n\times\left(\mathbb{R}-\left\{0\right\}\right)$$ where $\times$ means Cartesian product.  Then $$\hat{\mathcal{G}}=\left(\mathbb{R}^{n+1}-\mathbb{R}^n\right)\cap\partial\mathcal{O}_f.$$ But long ago I learned that $\mathbb{R}^n$ is the set of all real number n-tuples, and $\mathbb{R}^{n+1}$ is the set of all (n+1)-tuples, so elements of $\mathbb{R}^{n}$ are not elements of $\mathbb{R}^{n+1}$ and $\mathbb{R}^{n}$ is not a subset of $\mathbb{R}^{n+1}.$ So am I correct in concluding that $\mathbb{R}^{n+1}-\mathbb{R}^n$ is not really the relative complement of the two sets?	¿Qué es $\mathbb{R}^{n+1}-\mathbb{R}^n$?	En el cálculo avanzado de varias variables de C.H. Edwards define el conjunto ordenado $\mathcal{O}_f$ de una función $f:\mathbb{R}^n\to\mathbb{R}$ como el conjunto de puntos entre $\mathbb{R}^n$ y el gráfico de $f,$ incluyendo los puntos de evaluación, $\mathbf{x}\in\mathbb{R}^n$ y los puntos en el gráfico $\left\{\mathbf{x},f\left(\mathbf{x}\right)\right\}\in\mathbb{R}^{n+1}$. Más tarde define un conjunto $\hat{\mathcal{G}}=\partial\mathcal{O}_f-\mathbb{R}^n,$ donde $\partial\mathcal{O}_f$ es el límite de $\mathcal{O}_f.$ La intención parece clara. Primero $\mathcal{O}_f$0\mathbb{R}^n{+1}\mathbb{R}^n=\mathbb{R}^n\times\bbleft(\mathbb{R}^n\\times\left\\\left}\right) $\mathcal{O}_f$0 donde $\mathcal{O}_f$1 es producto cartesiano. $\mathcal{O}_f$0\hat\mathbb{G}{Left}{R}^14}\n\mathbb{1}\n\n\n\n}{13} Pero, ¿cómo se sabe que el conjunto $\mathcal{O}_f$3 y el conjunto $\mathcal{O}_f$3 no es un conjunto de elementos n\n\n\n} que completan los subconjunto de los subconjunto de $\mathcal{O}_f$3 y $\mathcal{O}_f$3?	multivariable-calculus,elementary-set-theory,vector-spaces
A.378	Do exponent rules follow different rules from radicals	Does $\left(-3\right)^\frac{2}{2}$ not equal $\sqrt{\left(-3\right)^2}$?	¿Las reglas del exponente siguen reglas diferentes de las de los radicales?	¿No es $\left(-3\right)^\frac{2}{2}$ igual a $\sqrt{\left(-3\right)^2}$?	exponential-function
A.379	Properties of a set of all isomorphisms $ f: G \to G $	I'm kinda stuck with this task. Let $G$ be a group and $ S $ the set of all isomorphisms $ f: G \to G$. I first want to show that $ (S, \circ) $ is also a group. I believe I've shown that all the properties of a group is fulfilled with $ (S, \circ) $: i) Assume that $ x \in $ and $ f_1,f_2 \in S$. Then $f_2(x) = y \in G$, since $ f_1 $ is an ismorphism. $ f_2(y) = z \in G $ since $ f_2 $ is an ismorphism. Then $ f_1(f_2(x)) = f_1(y) = z = f_1 \circ f_2(x),$ hence $f_1, f_2 \in S \longrightarrow f_1 \circ f_2 \in S.$ ii) $id$ is an isomorphism $ \longrightarrow id \in S$. iii) $ f $ is an isomorphism $ \longrightarrow \exists f^{-1}$, one can show that $ f^{-1} $ is also an isomorphism, $ \longrightarrow f^{-1} \in S$. Now, assume that $ | S | = 1$, then I want to show that $ G $ is abelian and each element has an order of 1 or 2. Im kinda lost with that $ | S | = 1 $. If $ f \in S $ then $f^{-1} \in S $ due to previous result, should not $ | S | = 1 $ imply that $ f = f^{-1} = id$? And how do I move forward from this? Any hints is muy appreciated!	Propiedades de un conjunto de todos los isomorfismos $ f: G \to G $	Estoy un poco atrapado con esta tarea. Deja que $G$ sea un grupo y $ S $ el conjunto de todos los isomorfismos $ f: G \to G$. Primero quiero mostrar que $ (S, \circ) $ es también un grupo. Creo que he demostrado que todas las propiedades de un grupo se cumplen con $ (S, \circ) $: i) Supongamos que $ x \in $ y $ f_1,f_2 \in S$. Entonces $f_2(x) = y \in G$, ya que $ f_1 $ es un ismorfismo. $ f_2(y) = z \in G $ desde $G$0 es un ismorfismo. Entonces $G$1 por lo tanto $G$2 ii) $G$3 es un isomorfismo $G$4. iii) $G$5 es un isomorfismo $G$6, se puede mostrar que $G$7 es también un isomorfismo, $G$8. Ahora, supongamos que $G$9, entonces quiero mostrar que $ S $0 es abeliano y cada elemento tiene un orden de 1 o 2. ¡Y si se pierde con ese $ S $1.22 y $ S $3 debido a los resultados, entonces, ¿no debería implicar que $ S $1 se mueve de este hecho? Si se aprecia mucho adelante?	group-theory,elementary-number-theory,group-isomorphism,automorphism-group
A.380	If $\int_0^\pi f(t) \sin(t)dt =\int_0^\pi f(t) \cos(t)dt = 0$, then $f(x)=0$ admits two solutions	Let $f\colon [0,\pi]\to\mathbb{R}$ be a continuous function.  If $\int^{\pi}_{0}f (t) \sin(t)dt =\int^{\pi}_{0} f (t) \cos(t)dt = 0$, then $f(x)=0$ admits two solutions in $[0,\pi]$  I try to show if $f(x)>0$ and then get the contradiction but I failed to prove that, so maybe can someone help me with that? thanks in advance.	Si $\int_0^\pi f(t) \sin(t)dt =\int_0^\pi f(t) \cos(t)dt = 0$, entonces $f(x)=0$ admite dos soluciones	Si $f\colon [0,\pi]\to\mathbb{R}$ es una función continua. si $\int^{\pi}_{0}f (t) \sin(t)dt =\int^{\pi}_{0} f (t) \cos(t)dt = 0$, entonces $f(x)=0$ admite dos soluciones en $[0,\pi]$ intento mostrar si $f(x)>0$ y luego obtener la contradicción pero no pude probar eso, así que tal vez alguien puede ayudarme con eso? gracias por adelantado.	integration,analysis
A.381	$A_1 \times ... \times A_n$ is countable if $A_1, ..., A_n$ are countable	Suppose that $A_1, ..., A_n$ are countable sets. Show that the cartesian product $A := A_1 \times ... \times A_n$ is countable. My attempt: Sets are said to be countable if they are finite or if they have the same cardinality as some subset of $\mathbb{N}$ (i.e. we can find some bijection $f: A \rightarrow S$ or $f: S \rightarrow A$ where $S \subset \mathbb{N}$). Assume that $A_1, ..., A_n$ are countable sets. Then, there exists bijections $fi: \mathbb{N} \rightarrow A_i$ for $i = 1, ..., n$. Define $g: \mathbb{N} \rightarrow A$ as follows My issue arises here in finding such a bijective function without it being too complicated. How would I go about finding one? I am also open to any suggestions. Any assistance is welcomed.	$A_1 \times ... \times A_n$ es contable si $A_1, ..., A_n$ es contable	Supongamos que $A_1, ..., A_n$ son conjuntos contables. Muestre que el producto cartesiano $A := A_1 \times ... \times A_n$ es contable. Mi intento: Se dice que los conjuntos son contables si son finitos o si tienen la misma cardinalidad que algún subconjunto de $\mathbb{N}$ (es decir, podemos encontrar alguna bijección $f: A \rightarrow S$ o $f: S \rightarrow A$ donde $S \subset \mathbb{N}$). Supongamos que $A_1, ..., A_n$ son conjuntos contables. Luego, existen bijecciones $fi: \mathbb{N} \rightarrow A_i$ para $i = 1, ..., n$. Definir $g: \mathbb{N} \rightarrow A$ de la siguiente manera Mi problema surge aquí en encontrar tal función bijectiva sin que sea demasiado complicada. ¿Cómo voy a encontrar una? También estoy abierto a cualquier sugerencia. Cualquier ayuda es bienvenida.	elementary-set-theory,induction
A.382	Set of functions from $SS = \{ A_{1}, A_{2}, A_{3},...\}$ to $\{ \mathbf{T}, \mathbf{F} \} $ is countable?	Let $SS=\{ A_1,A_2,A_3,\ldots\}$, and let $V = \{ v \mid v: SS \to \{ \mathbf{T}, \mathbf{F} \} \}$ .Is the set  V countable?  Justify your answer. My instinct is to say that $V = \{ v \mid v: SS \to \{ \mathbf{T}, \mathbf{F} \} \}$ is uncountable, and to prove this using a diagonalization argument, i.e. create a table of values of the functions $v_{1}, v_{2},...$ for natural numbers $n_1, n_2,\ldots$ and define a function $v_{m} : SS \to \{ \mathbf{T}, \mathbf{F} \}$ where it takes all values in the diagonals of the table $T, F$ and flips them, and then show that $v_{m}$ cannot appear anywhere in the list. Is my guess correct, and if so would this be a reasonable approach to the problem?	¿El conjunto de funciones de $SS = \{ A_{1}, A_{2}, A_{3},...\}$ a $\{ \mathbf{T}, \mathbf{F} \} $ es contable?	¿Es el conjunto V contable? Justifica tu respuesta. Mi instinto es decir que $V = \{ v \mid v: SS \to \{ \mathbf{T}, \mathbf{F} \} \}$ es incontable, y para demostrar esto usando un argumento de diagonalización, es decir, crear una tabla de valores de las funciones $v_{1}, v_{2},...$ para los números naturales $n_1, n_2,\ldots$ y definir una función $v_{m} : SS \to \{ \mathbf{T}, \mathbf{F} \}$ donde toma todos los valores en las diagonales de la tabla $T, F$ y los vuelve, y luego mostrar que $v_{m}$ no puede aparecer en ninguna parte de la lista. ¿Es mi suposición correcta, y si es así, este sería un enfoque razonable al problema?	elementary-set-theory
A.383	Automorphisms of the disk without the maximum principle	For pedagogical purposes, I am looking for an elementary proof (i.e. without resorting to the maximum principle) that $f_a(z):=\frac{z-a}{1-\overline{a}z}$ maps the unit disk into itself when $|a|<1$. The usual argument (at least usual for me) is to look at $f_a(e^{it})$ and check that $|f_a(e^{it})|=1$. Then we are done by the maximum principle and the fact that $f_a(a)=0$. However, I cannot help but think that there should be an elementary way to do this, using only basic facts about complex numbers such as the triangle inequality. Unfortunately I am running into circles.	Automorfismos del disco sin el principio máximo	Para fines pedagógicos, estoy buscando una prueba elemental (es decir, sin recurrir al principio máximo) de que $f_a(z):=\frac{z-a}{1-\overline{a}z}$ mapea el disco unitario en sí mismo cuando $|a|<1$. El argumento habitual (al menos habitual para mí) es mirar a $f_a(e^{it})$ y comprobar que $|f_a(e^{it})|=1$. Entonces estamos terminados por el principio máximo y el hecho de que $f_a(a)=0$. Sin embargo, no puedo evitar pensar que debería haber una manera elemental de hacerlo, utilizando solo hechos básicos sobre números complejos como la desigualdad del triángulo. Desafortunadamente estoy corriendo en círculos.	complex-analysis,complex-numbers
A.384	What does this bracket notation mean?	I am currently taking MIT6.006 and I came across this problem on the problem set. Despite the fact I have learned Discrete Mathematics before, I have never seen such notation before, and I would like to know what it means and how it works, Thank you: $$ f_3(n) = \binom n2$$ (Transcribed from screenshot)	¿Qué significa esta notación de corchetes?	Actualmente estoy tomando MIT6.006 y me encontré con este problema en el conjunto de problemas. a pesar del hecho de que he aprendido Matemáticas Discreta antes, nunca había visto tal notación antes, y me gustaría saber lo que significa y cómo funciona, Gracias: $$ f_3(n) = \binom n2$$ (Transcripto de pantalla)	discrete-mathematics,algorithms
A.385	Properties of size function in a general Euclidean domain	In ring theory a given ring $R$ is called a Euclidean domain if there exists a function $\sigma:R -\{0\}\rightarrow \{0,1,2,3...\}   $ which satisfies the division algorithm i.e. $ $ if $a,b \in R$ then there exists $q,r \in R$ such that  $b=aq+r$ and either $r=0$ or $\sigma(r)\lt \sigma(a) $ Now I want to ask if we can prove, using just this definition that an element of larger degree won't divide an element of smaller degree. In specific rings such as (i) the integers we can say$$\sigma(a)=|a|$$ $$\sigma(ab)=\sigma(a)\sigma(b)$$ ii) polynomials where$$\sigma(f(x))=deg(f(x))$$$$\sigma(ab)=\sigma(a)+\sigma(b)$$ So in both the above cases the size of product of two elements will always be greater than or equal to the size of individual elements and hence the larger element can never divide the smaller element. But is this true in general for all Euclidean domains ? And how will we prove that	Propiedades de la función de tamaño en un dominio euclidiano general	En la teoría de anillos un anillo dado $R$ se llama dominio euclidiano si existe una función $\sigma:R -\{0\}\rightarrow \{0,1,2,3...\}   $ que satisface el algoritmo de división es decir, $ $ si $a,b \in R$ entonces existe $q,r \in R$ tal que $b=aq+r$ y ya sea $r=0$ o $\sigma(r)\lt \sigma(a) $ Ahora quiero preguntar si podemos probar, usando sólo esta definición que un elemento de mayor grado no dividirá un elemento de menor grado. En anillos específicos como (i) los enteros podemos decir $$\sigma (a) y (a) =a$R$0\sigma (a)  (a)  (a)  (b)  (b)  (b) )  (b)  (b) )  (b)  (b)  (b)  (b)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c) )  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c) )  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c)  (c) )  (c)  (c) )  (c)  (c)  (c)  (c) )  (c)  (c)  (c) )  (c)  (c)  () )  ()  ()  () )  ()  () )  ()  () )  ()  () )  () )  () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ()	ring-theory,factoring,euclidean-domain
A.386	Prove that $\sum _{n=-\infty }^{\infty } e^{-n^2 \pi x}=\frac{1}{\sqrt{x}}\sum _{n=-\infty }^{\infty } e^{-\frac{n^2 \pi }{x}}$	In Wikipedia's proof of Riemann's functional equation for the zeta function (here, and click "Show Proof"), I find the assertion that $$\sum _{n=-\infty }^{\infty } e^{-n^2 \pi x} = \frac{1}{\sqrt{x}}\sum _{n=-\infty }^{\infty } e^{-\frac{n^2 \pi }{x}}$$ I can't work out how this works. Is it to do with Jacobi theta functions? Mathematica (which seems to use Jacobi's original notation) simplifies the expression on the left hand side above to the Jacobi elliptic theta function (Wikipedia here, plus the 'Auxiliary Functions' section that follows) $$ \begin{aligned} \sum _{n=-\infty }^{\infty } e^{-n^2 \pi x} &= \vartheta_{3}(0,e^{-\pi  x}) \\&= \vartheta_{00}(0,e^{-\pi  x}) \\&= \vartheta(0,e^{-\pi  x}) \end{aligned} $$ Wikipedia defines $$\vartheta(z;\tau) := \sum _{n=-\infty }^{\infty } e^{\pi i n^2 \tau+2 \pi i n z}$$ But setting $z = 0$ and $\tau = e^{-\pi  x}$ then gives $$\vartheta(0,e^{-\pi  x}) = \sum _{n=-\infty }^{\infty } e^{\pi i n^2 e^{-\pi  x}}$$ which is clearly not equivalent to the original expression. I suspect that this may have something to do with nomes, which Wikipedia mentions but I cannot get my head around. So, my two questions are:  How do I prove the original equivalence? What am I doing wrong in relation to the Jacobi theta function?	Prueba eso $\sum _{n=-\infty }^{\infty } e^{-n^2 \pi x}=\frac{1}{\sqrt{x}}\sum _{n=-\infty }^{\infty } e^{-\frac{n^2 \pi }{x}}$	En la prueba de la ecuación funcional de Riemann de la función zeta (aquí, y haga clic en "Mostrar prueba") encontré la afirmación de que $$\suma _{n=-\infty }^{\infty } e^{n^2 \pi x} = \frac{1}{\sqrt{x}}\suma _{n=-\infty }^{\infty } e^{-\frac{n^2 \pi }{$$} no puedo determinar cómo funciona esto. ¿Tiene que ver con las funciones de Jacobi theta? Mathematica (que parece utilizar la notación original de Jacobi) simplifica la expresión en el lado izquierdo de la función Jacobi elíptica: Así que en Wikipedia, ¿cómo podemos obtener las funciones de la misma que siguen la función de la función de la misma, pero entonces podemos probar que las dos funciones de la misma se encuentran en la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la que se refiere a la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la que se refiere a las secciones que se refiere a las secciones que se exáterales, pero que no se puede que no se exácuento, pero que no se puede que se exácuento, pero que no se puede que se exácuento, pero que se exátres de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la que se exárea de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la sección de la se ex ex ex ex ex ex ex ex ex ex en el que se ex en el que se ex en el en el que se ex en el en el que se ex en el en el en el en el en el en el en el que se ex en el en el que se ex en el en el en el que se ex en el en el que se ex en el en el en el en el en el en el en el que se ex en el que se ex ex en el en el que se ex	proof-explanation,riemann-zeta,theta-functions
A.387	Any positive integer greater than $11$ is a nonnegative linear combination of $5$ and $4$. My solution	Let $n\in\mathbb{Z}^{+}$, then there exists $k\in\mathbb{Z}_0^+$, such that $n=5k + i, i\in\{0,1,2,3,4\}$. Now analyzing by cases we have:  If $i=0$, then $\begin{align*}         n = 5k \Rightarrow n = 5k + 4(0). \end{align*}$ If $ i = 1 $, then $\begin{align*}        n & = 5k + 1 \\          & = 5k-5(3) +5(3) +1 \\          & = 5(k-3) + 15 + 1 \\          & = 5(k-3) +16 \Rightarrow n = 5(k-3) +4(4). \end{align*}$ If $ i = 2 $, then $\begin{align*}    n & = 5k + 2 \\      & = 5k-5(2) +5(2) +2 \\      & = 5(k-2) + 10 + 2 \\      & = 5(k-2) +12 \Rightarrow n = 5(k-2) +4(3). \end{align*}$ If $i=3$, then $\begin{align*}    n & = 5k + 3 \\      & = 5k-5 + 5 + 3 \\      & = 5(k-1) +8 \Rightarrow n = 5(k-1) +4(2). \end{align*}$ If $i=4$, then $\begin{align*}     n = 5k + 4 \Rightarrow n = 5k + 4(1). \end{align*}$  Thus, every positive number can be expressed as a linear combination of $5$ and $4$. Now using that $n>11$, so we have: $\begin{align*} n       &> 11 \\ 5k + i  &> 5(2) +1 \\ 5k-5(2) &> 1-i \\ 5 (k-2) &> 1-i \\ k-2     &> \frac{1-i}{5} \\ k       &> 2+\frac{1-i}{5}. \end{align*}$ So by increasing over the values ​​that $ i $ takes, we have: $\begin{align*} k &> 2+ \frac{1-i}{5} \geq 2+ \frac{1-0}{5}\\ k &> 2 + 0.2 = 2.2 \end{align*}$ But $k\in\mathbb{Z}_0^+ \Rightarrow k \geq 3 \Rightarrow n \geq 15 $. Thus we have that every positive integer greater than or equal to $15$ is a non-negative linear combination of $5$ and $4$. Finally, let's look at the cases that are still unverified, which are $12$, $13$ and $14$. $\begin{align*} 12 &= 5(0) +4(3) \\ 13 &= 5(1) +4(2) \\ 14 &= 5(2) +4(1). \end{align*}$ Therefore, any positive integer greater than $11$ is a nonnegative linear combination of $5$ and $4$. I think this is the correct solution, I await your comments. If anyone has a different solution or correction of my work I will be grateful.	Cualquier número entero positivo mayor que $11$ es una combinación lineal no negativa de $5$ y $4$. Mi solución	Así que, cada número positivo puede expresarse como una combinación lineal de $n\in\mathbb{Z}^{+}$4 y $n\in\mathbb{Z}^{+}$5. Así que usando ese $n\in\mathbb{Z}^{+}$6, tenemos: $n\in\mathbb{Z}^{+}$7 Así que aumentando los valores que $n\in\mathbb{Z}^{+}$8 toma, tenemos: $n\in\mathbb{Z}^{+}$9 Pero $k\in\mathbb{Z}_0^+$0. Así que tenemos que cada número positivo igual o mayor a $k\in\mathbb{Z}_0^+$1 es una combinación lineal no negativa de $n\in\mathbb{Z}^{+}$4 y $n\in\mathbb{Z}^{+}$5. Por último, veamos los casos que aún no se han verificado, que son $k\in\mathbb{Z}_0^+$2, $k\in\mathbb{Z}_0^+$3 y $k\in\mathbb{Z}_0^+$4.	elementary-number-theory
A.388	Linear algebra find $k$	Given the linear system: $$\begin{cases}  x_1 + kx_2 − x_3 = 2\\  2x_1 − x_2 + kx_3 = 5 \\ x_1 +10x_2 −6x_3 =1 \end{cases}$$ for which values of $k$ has the system (2): (a) No solutions (b) A unique solution. (c) Infinitely many solutions. I've been trying echelon form where i switched $R_1$ with $R_3$ and then i switched $R_2$ with $R_3$ So I have $\left[\begin{array}{ccc|c}1&10&-6&1\\1&k&-1&2\\2&-1&k&5\end{array}\right]$ but then I'm stuck and don't know how to get any further.	Algebra lineal encuentra $k$	Dado el sistema lineal: $$\begin{cases} x_1 + kx_2 − x_3 = 2\\ 2x_1 − x_2 + kx_3 = 5 \\ x_1 + x_2 −6x_3 = 1 \end{cases}$$ para el cual los valores de $k$ tiene el sistema (2): (a) No hay soluciones (b) Una solución única. (c) Infinitamente muchas soluciones. He estado intentando la forma de escala donde cambié $R_1$ con $R_3$ y luego cambié $R_2$ con $R_3$ Así que tengo $\left[\begin{array}{ccc|c}1&10&-6&1\\1&k&-1&2\\2&-1&k&5\end{array}\right]$ pero luego estoy atascado y no sé cómo seguir adelante.	linear-algebra
A.389	Convergence of a Special Series as N is large	I'm trying to find a general formula for the series and x is a constant: $$\sum\limits_{i=1}^N  \frac{i}{(1+r)^i}$$ I have deduced the general formula for the sum. $$\frac{(1+r)^{N+1}-(1+r)-rN}{r^2(1+r)^N}$$ Will this sum converge to some value when N is very large? Could someone explain how to deal with it?	Convergencia de una serie especial como N es grande	Estoy tratando de encontrar una fórmula general para la serie y x es una constante: $$\sum\limits_{i=1}^N \frac{i}{(1+r)^i}$$ He deducido la fórmula general para la suma. $$\frac{(1+r)^{N+1}-(1+r)-rN}{r2(1+r)^N}$$ ¿Convergirá esta suma a algún valor cuando N es muy grande? ¿Puede alguien explicar cómo lidiar con él?	summation
A.390	Prove that if $x_n$ converges to $\omega$, $t_n$ converges to $\omega$ too	By the sequence $(x_n)_{n\in\Bbb{N}}$, define a new sequence $(t_n)_{n\in\Bbb{N}}$ such that $t_n:=\frac {x_1+x_2+...+x_n}{n}$. If $\lim_{n\rightarrow\infty}t_n=\omega$, how can I show that $\lim_{t\rightarrow\infty}x_n=\omega$? Original post had ``If $\lim_{n\rightarrow\infty}x_n=\omega$, ..."	Demostrar que si $x_n$ converge a $\omega$, $t_n$ converge a $\omega$ también	Por la secuencia $(x_n)_{n\in\Bbb{N}}$, definir una nueva secuencia $(t_n)_{n\in\Bbb{N}}$ tal que $t_n:=\frac {x_1+x_2+...+x_n}{n}$. Si $\lim_{n\rightarrow\infty}t_n=\omega$, ¿cómo puedo mostrar que $\lim_{t\rightarrow\infty}x_n=\omega$?	sequences-and-series,convergence-divergence
A.391	$C_r $ inequality	Show that for each $r> 0$ $$\mathbb{E} |X+Y|^r \leq c_r (\mathbb{E} |X|^r + \mathbb{E} |Y|^r),$$ where $c_r$ is a constant given by $\begin{equation}    c_r = \left\{         \begin{array}{ll}    1 & \mathrm{if\ } 0 < r \le 1 \\    2^{r-1}     & \mathrm{if\ } 1 < r         \end{array}       \right. \end{equation}$ I've tried to use other inequalities for the proof of this one but I still get stuck for the case of $2^{r-1}$.	$C_r $ desigualdad	Muestre que para cada $r> 0$ $$\mathbb{E}\X+Y^r \leq c_r (\mathbb{E} \X bb\r + \mathbb{E} \Y r),$$ donde $c_r$ es una constante dada por $\begin{equation}    c_r = \left\{         \begin{array}{ll}    1 & \mathrm{if\ } 0 < r \le 1 \\    2^{r-1}     & \mathrm{if\ } 1 < r         \end{array}       \right. \end{equation}$ He intentado usar otras desigualdades para la prueba de esta pero todavía me queda atascado para el caso de $2^{r-1}$.	probability-theory,probability-distributions
A.392	How to compute inverse polynomials modulo an integer	I am working with polynomials in the ring $\mathbb{Z}[X]/(X^n-1)$, so only polynomials with degree at most $n-1$ are allowed, and multiplications must be reduced modulo $X^n-1$. The thing is that I have a polynomial $f(X)$ and I want to compute its inverse modulo an integer $p$, $f_p(X)$, such that $$ f * f_p \equiv 1 \bmod p $$ How could I do that? Any known algorithm? I have heard about the extended Euclidean algorithm, but I'm not quite sure how to use it, for example, given $f(X) = -1+X+X^2-X^4+X^6+X^9-X^{10}$.	Cómo calcular polinomios inversos modulo un número entero	Estoy trabajando con polinomios en el anillo $\mathbb{Z}[X]/(X^n-1)$, por lo que sólo polinomios con grado máximo $n-1$ son permitidos, y las multiplicaciones deben ser reducidas modulo $X^n-1$. La cosa es que tengo un polinomio $f(X)$ y quiero calcular su modulo inverso un número entero $p$, $f_p(X)$, de tal manera que $$ f * f_p \equiv 1 \bmod p $$ ¿Cómo podría hacer eso? Cualquier algoritmo conocido?	polynomials,ring-theory,euclidean-algorithm
A.393	Prove an entire function is a constant under an inequality	f is an entire function, suppose $|f(z^{2})| \leq  2|f(z)|$ for all C, then f is a constant. I 'm trying to use Liouville's theorem, but it seems that it isn't helpful.	Prove una función entera es una constante bajo una desigualdad	f es una función entera, supongamos que $|f(z^{2})| \leq  2|f(z)|$ para todo C, entonces f es una constante. Estoy tratando de usar el teorema de Liouville, pero parece que no es útil.	complex-analysis
A.394	Trying to find the $\delta$ in epsilon-delta continuity proof.	I am trying to prove the following function is continuous for all irrationals: $f(x) = \begin{cases} 0,  & \text{if $x$ is irrational} \\ 1/n, & \text{if $x = m/n$} \end{cases}$ The question assumes $m/n$ is in lowest terms. I have shown that it is discontinuous for all rationals, and now I believe I have to either use the $\epsilon-\delta$ definition of continuity or sequential continuity to show the function is continuous for when $x$ is irrational. I split my attempt into two cases: Our value of $x$ is irrational, then I want: $$\forall \epsilon > 0, \exists \delta > 0, |x-a| $a$ is irrational here. Using that $x$ is irrational I get that $f(x) = 0$ as does $f(a)$ so no matter the $\delta$ we have our condition for continuity  satisfied as $0 < \epsilon$ for all $\delta$ Our value of $x$ is rational i.e. $x = \frac{m}{n}$ subbing in we want: $$\forall \epsilon > 0, \exists \delta > 0, |\frac{m}{n}-a| I am struggling to find the $\delta$ necessary. I am able to bound $|\frac{m}{n}-a|$ by $1+2|a|$ if I say that $\delta \le 1$. However I do not know how to find a $\delta$ to yield the second inequality. Should I change my approach to sequential continuity?	Intentando encontrar el $\delta$ en la prueba de continuidad epsilon-delta.	Estoy tratando de demostrar que la siguiente función es continua para todos los irracionales: $f(x) = \begin{cases} 0,  & \text{if $x$ is irrational} \\ 1/n, & \text{if $x = m/n$} \end{cases}$ La pregunta asume que $m/n$ es en términos más bajos. He demostrado que es discontinuo para todos los racionales, y ahora creo que tengo que usar la definición $\epsilon-\delta$ de continuidad o continuidad secuencial para mostrar que la función es continua cuando $x$ es irracional. Divido mi intento en dos casos: Nuestro valor de $x$ es irracional, entonces quiero: $$ para todos los \epsilon > 0, \delists \delta > 0, \x-a $a$ es irracional. Usando aquí que $x$ es irracional obtengo que $f(x) = 0$ como hace $f(x) = \begin{cases} 0,  & \text{if $0 así que no importa la $f(x) = \begin{cases} 0,  & \text{if $1 tenemos condición de continuidad satisfecha como $f(x) = \begin{cases} 0,  & \text{if $2 para todos los suta11 de $x$ es racional.	continuity,epsilon-delta
A.395	Why we have to check both additivity and homogenity for linearity?	$f: V \to W $ over $K$ with $a,b \in V$ and $k \in K$. Additivity: $f(a+b) = f(a) + f(b)$ Homogenity: $k*f(b) =f(k * b)$ I have a visual understanding that a function is linear if the structure is kept while projecting it with $f$ but why it is not enough to check if the function is additive? I would be glad to have some easy examples and an intuition why we would have to check both conditions.	¿Por qué tenemos que comprobar tanto la aditividad como la homogeneidad para la linealidad?	$f: V \to W $ sobre $K$ con $a,b \in V$ y $k \in K$. Adictividad: $f(a+b) = f(a) + f(b)$ Homogeneidad: $k*f(b) =f(k * b)$ Tengo una comprensión visual de que una función es lineal si se mantiene la estructura mientras se proyecta con $f$ pero por qué no es suficiente para comprobar si la función es aditiva? Me encantaría tener algunos ejemplos fáciles e intuición por qué deberíamos comprobar ambas condiciones.	linear-algebra
A.396	What is the MLE $\theta^*$ of $\theta$?	I have that $x_1, x_2,...,x_n$ are from a rv $X$ that has the density function $f_X(x)=\frac{2x}{\theta^2} \quad$ for $0 \le x \le \theta  \quad$ and $f_X(x)=0 \quad$ otherwise. Ihave to determine the MLE of $\theta^*$ of $\theta$  Here is how I have done it:  $L(\theta)= \frac{2}{\theta^{2n}}\prod_{i=1}^nx_i$  $\frac{\partial L(\theta)}{\partial \theta} =...=\frac{-4n}{\theta^{2n+1}}\prod_{i=1}^nx_i + \frac{2}{\theta^{2n}}\frac{\partial(\prod_{i=1}^nx_i)}{\partial \theta}$  Is this correct? and also how do I calculate the CDF $F_{\theta^*}$, the pdf $f_{\theta^*}$ and the expectation $E[\theta^*]$ of the maximum likelihood estimator $\theta^*$?	¿Cuál es el MLE $\theta^*$ de $\theta$?	Tengo que $x_1, x_2,...,x_n$ son de un rv $X$ que tiene la función de densidad $f_X(x)=\frac{2x}{\theta^2} \quad$ para $0 \le x \le \theta  \quad$ y $f_X(x)=0 \quad$ de lo contrario. Tengo que determinar el MLE de $\theta^*$ de $\theta$ Aquí es como lo he hecho: $L(\theta)= \frac{2}{\theta^{2n}}\prod_{i=1}^nx_i$ $\frac{\partial L(\theta)}{\partial \theta} =...=\frac{-4n}{\theta^{2n+1}}\prod_{i=1}^nx_i + \frac{2}{\theta^{2n}}\frac{\partial(\prod_{i=1}^nx_i)}{\partial \theta}$ ¿Es esto correcto? y también cómo calcular el CDF $x_1, x_2,...,x_n$0, el pdf $x_1, x_2,...,x_n$1 y la expectativa $x_1, x_2,...,x_n$2 del estimador de probabilidad máxima $\theta^*$?	statistics,statistical-inference,maximum-likelihood,cumulative-distribution-functions,robust-statistics
A.397	If the limit does not converge, can the sum? Or, how could the sum converge?	Alright, I thought I had seen everything but last night I saw this identity (`twas attributed to Ramanujan), $$ 1 + 2 + 3 + 4 + \cdots = -\frac{1}{12} $$ Then I saw a proof that was seemingly correct. So alright, I believe it, hey it is no crazier than having infinities of different sizes and I finally have some closure with that fact. But then, I recalled the benchmark induction proof everyone learns, $$ \sum_{i=1}^{n} i = \frac{n(n+1)}{2} $$ Then kicks in the remains of all those calculus courses I once took, making me thing that, hey wait! We have this, $$ \lim_{n\rightarrow\infty} \frac{n(n+1)}{2} = \infty $$ I think in this case we said the limit does not exist or the function diverges (correct me if I am wrong!) But... but... according to the identity above, $$ \sum_{i=1}^{n=\infty} i = -\frac{1}{12} $$ But then shouldn't, $$ \lim_{n\rightarrow\infty} \frac{n(n+1)}{2} \stackrel{?}{=} -\frac{1}{12} $$ So what I am seeing here is that even if the limit does not converge, the sum does. Also, a long time ago I remember being told that the sum of two positive integers is always positive. Furthermore, addition is suppose to be closed under integers right? Here we not only have a negative number as a result of the sum of positive integers but a negative non-integer at that.	Si el límite no converge, ¿puede la suma?	Bueno, pensé que había visto todo pero anoche recordé la prueba de inducción de referencia. Aquí se aprende, $$ 1 + 2 + 3 + 4 + \cdots = -\frac{1}{12} $$ Entonces vi una prueba que parecía correcta. Así que está bien, lo creo, hey no es más loco que tener infinidades de diferentes tamaños y finalmente tengo algún cierre con ese hecho. Pero luego, recordé la prueba de inducción de referencia.	limits,summation
A.398	A question on differentiability at a point	Is a continuous function differentiable at $x=c$ if the limit of its derivative has a value at that point? That is, if $$\lim_{x \rightarrow c} f'(x) = L = \lim_{x \rightarrow c^+} f'(x) =\lim_{x \rightarrow c^-} f'(x)$$ Intuitively, the slopes of the tangents approach the same value and since the function is continuous a jump-discontinuity isn't possible so it appears the slope at the point should be $L$ too. However, I cannot seem to locate such a theorem, so I suspect my intuition is wrong. Is it?	Una pregunta sobre la diferenciabilidad en un punto	¿Es una función continua diferenciable en $x=c$ si el límite de su derivada tiene un valor en ese punto? Es decir, si $$\lim_{x \rightarrow c} f'(x) = L = \lim_{x \rightarrow c^+} f'(x) =\lim_{x \rightarrow c^-} f'(x) $$ Intuitivamente, las pendientes de las tangentes se acercan al mismo valor y ya que la función es continua una descontinuidad de salto no es posible por lo que parece que la pendiente en el punto debe ser $L$ también. Sin embargo, no puedo encontrar tal teorema, así que sospecho que mi intuición está equivocada. ¿Es así?	real-analysis,calculus
A.399	Disjoint axis-aligned rectangles in the plane	Let $A$ be some set of axis-aligned rectangles in the plane, each pair of which has empty intersection. Prove that $A$ is a countable set. (An axis-aligned rectangle is a set of the form $$M = {\{\langle x,y \rangle \in \mathbb{R^2} | a \leq x \leq b , c \leq y \leq d}\}$$ for $a,b,c,d$ such that $a < b$ and $ c < d$.) Attempt: I tried using the density of the $\mathbb{Q}$ in $(\mathbb{R},\leq)$, but without any success.	Rectángulos desarticulados alineados en el eje del avión	Que $A$ sea un conjunto de rectángulos alineados con eje en el plano, cada par de los cuales tiene una intersección vacía. Pruebe que $A$ es un conjunto contable. (Un rectángulo alineado con eje es un conjunto de la forma $$M = {\{\langle x,y \rangle \in \mathbb{R^2}\ a \leq x \leq b , c \leq y \leq d}\}$$ para $a,b,c,d$ tales como $a < b$ y $ c < d$.) Intento: Intenté usar la densidad del $\mathbb{Q}$ en $(\mathbb{R},\leq)$, pero sin éxito.	real-analysis,combinatorics
A.400	What is the probability hat two particular players verse in Wimbledon if it begins with $16$ players?	Sixteen people play in the quarter-finals at Wimbledon. The winner of the quarter-finals play again in the semi-final to decide who enters the finals. What is the probability that two particular people will play each other if the tournament begins with 16 players? So I have so far (case 1 + case 2) = verse player in quarter OR verse player in semi = $\frac{1}{15} + \frac{14}{15}...$ I'm not sure what else to include in the second case Also the third part of the question asks What is the probability when $2^n$ players begin? The worked solutions show $\frac{1}{2^n-1}+\frac{2^n-2}{2^n-1}\left(\frac{1}{2^{n-2}}\right)^2\:=\:\frac{1}{2^{n-1}}$ which I cannot get. Even symbolab doesn't show the same simplification. As with the previous question, I do not understand the $\left(\frac{1}{2^{n-2}}\right)^2$	¿Cuál es la probabilidad de que dos jugadores particulares vayan a Wimbledon si comienza con jugadores $16$?	Seis personas juegan en los cuartos de final en Wimbledon. El ganador de los cuartos de final juega de nuevo en la semifinales para decidir quién entra en las finales. ¿Cuál es la probabilidad de que dos personas particulares jueguen entre sí si el torneo comienza con 16 jugadores? Así que hasta ahora tengo (casos 1 + caso 2) = jugador de verso en el cuartos O jugador de verso en el semifinales = $\frac{1}{15} + \frac{14}{15}...$ No estoy seguro de qué más incluir en el segundo caso También la tercera parte de la pregunta pregunta ¿Cuál es la probabilidad cuando comienzan los jugadores $2^n$? Las soluciones trabajadas muestran $\frac{1}{2^n-1}+\frac{2^n-2}{2^n-1}\left(\frac{1}{2^{n-2}}\right)^2\:=\:\frac{1}{2^{n-1}}$ que no puedo obtener. Incluso simbólab no muestra la misma simplificación. Como con la pregunta anterior, no entiendo el $\left(\frac{1}{2^{n-2}}\right)^2$	probability,combinatorics,algebra-precalculus
